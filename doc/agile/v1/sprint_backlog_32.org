#+title: Sprint Backlog 32
#+options: date:nil toc:nil author:nil num:nil
#+todo: STARTED | COMPLETED CANCELLED POSTPONED
#+tags: { story(s) epic(e) spike(p) }

* Sprint Goals

- Finish restoring support for CI/CD.
-

* Stories

** Active

#+begin: clocktable :maxlevel 3 :scope subtree :indent nil :emphasize nil :scope file :narrow 75 :formula %
#+CAPTION: Clock summary at [2022-09-25 Sun 09:12]
| <75>                                                      |         |       |       |       |
| Headline                                                  | Time    |       |       |     % |
|-----------------------------------------------------------+---------+-------+-------+-------|
| *Total time*                                              | *28:02* |       |       | 100.0 |
|-----------------------------------------------------------+---------+-------+-------+-------|
| Stories                                                   | 28:02   |       |       | 100.0 |
| Active                                                    |         | 28:02 |       | 100.0 |
| Edit release notes for previous sprint                    |         |       | 10:13 |  36.4 |
| Create a demo and presentation for previous sprint        |         |       |  2:06 |   7.5 |
| Update boost to latest in vcpg                            |         |       |  0:20 |   1.2 |
| Improve diffing output in tests                           |         |       |  0:19 |   1.1 |
| Sprint and product backlog grooming                       |         |       |  1:44 |   6.2 |
| Nightly builds are failing due to missing environment var |         |       |  1:07 |   4.0 |
| Remove deprecated uses of boost bind                      |         |       |  0:09 |   0.5 |
| Full generation support in tests is incorrect             |         |       |  3:18 |  11.8 |
| Tests failing with filesystem errors                      |         |       |  2:10 |   7.7 |
| Remove uses of mock configuration factory                 |         |       |  0:54 |   3.2 |
| Gitter notifications for builds are not showing up        |         |       |  0:38 |   2.3 |
| Windows package is broken                                 |         |       |  0:20 |   1.2 |
| Create a mock configuration builder                       |         |       |  1:58 |   7.0 |
| Add PlantUML relationships to diagrams                    |         |       |  0:04 |   0.2 |
| Add continuous builds to C++ reference product            |         |       |  1:57 |   7.0 |
| Remove ODB support from Dogen                             |         |       |  0:45 |   2.7 |
#+end:

Agenda:

#+begin_src emacs-lisp
(org-agenda-file-to-front)
#+end_src

*** COMPLETED Edit release notes for previous sprint                  :story:
    :LOGBOOK:
    CLOCK: [2022-09-23 Fri 08:53]--[2022-09-23 Fri 09:02] =>  0:09
    CLOCK: [2022-09-23 Fri 07:58]--[2022-09-23 Fri 08:18] =>  0:20
    CLOCK: [2022-09-16 Fri 09:35]--[2022-09-16 Fri 11:06] =>  1:31
    CLOCK: [2022-09-14 Wed 18:00]--[2022-09-14 Wed 18:41] =>  0:41
    CLOCK: [2022-09-13 Tue 17:47]--[2022-09-13 Tue 18:20] =>  0:33
    CLOCK: [2022-09-13 Tue 08:18]--[2022-09-13 Tue 09:02] =>  0:44
    CLOCK: [2022-09-12 Mon 22:00]--[2022-09-12 Mon 22:41] =>  0:41
    CLOCK: [2022-09-11 Sun 22:25]--[2022-09-11 Sun 23:35] =>  1:10
    CLOCK: [2022-09-11 Sun 11:58]--[2022-09-11 Sun 12:33] =>  0:35
    CLOCK: [2022-09-10 Sat 22:44]--[2022-09-10 Sat 23:40] =>  0:56
    CLOCK: [2022-09-10 Sat 20:21]--[2022-09-10 Sat 20:35] =>  0:14
    CLOCK: [2022-09-10 Sat 19:02]--[2022-09-10 Sat 20:20] =>  1:18
    CLOCK: [2022-09-10 Sat 15:49]--[2022-09-10 Sat 17:10] =>  1:21
    :END:

Add github release notes for previous sprint.

Release announcements:

- [[https://twitter.com/MarcoCraveiro/status/1570851700893941760][twitter]]
- [[https://www.linkedin.com/posts/marco-craveiro-phd-%F0%9F%87%A6%F0%9F%87%B4%F0%9F%87%B5%F0%9F%87%B9-31558919_release-dogen-v1031-exeunt-academia-activity-6976618358418886656-FRBE][linkedin]]
- [[https://gitter.im/MASD-Project/Lobby][Gitter]]

#+begin_src markdown
![Graduation](https://github.com/MASD-Project/dogen/releases/download/v1.0.31/phd_graduation.jpg)
_Graduation day for the PhD programme of Computer Science at the University of Hertfordshire, UK. (C) 2022 Shahinara Craveiro._

# Introduction

After an hiatus of almost ten months, we've finally managed to get another Dogen release out. When looked at purely from a software engineering perspective, this wasn't exactly the most compelling of releases since almost all our stories are infrastructural. More specifically, the majority of resourcing was shifted towards getting Continuous Integration (CI) to work again, in the wake of the carnage left by Travis CI's decommission. However, the _true_ focus of the last few months lays outside the bounds of software engineering; our time was spent mainly on completing the PhD thesis, getting it past a myriad of red-tape processes and, perhaps most significantly of all, on passing the final exam called _the viva_. And so we did. Given it has taken some eight years to complete the PhD programme, you'll forgive us for the break with the tradition in naming releases after Angolan places or events; regular service will resume on the next release, for this as well as in the engineering front ```<knocks on wood, nervously>```. So grab a cupper, sit back, relax, and get ready for the release notes that mark the end of academic life in the Dogen project.

# User visible changes

This section covers stories that affect end users, with the video providing a quick demonstration of the new features, and the sections below describing them in more detail. However, as we've only had a couple of those - and even then, as these are fairly minor - the demo spends some time reflecting on the PhD programme overall.

[![Sprint 1.0.31 Demo](https://img.youtube.com/vi/ei8B1Pine34/0.jpg)](https://youtu.be/ei8B1Pine34)
_Video 1_: Sprint 31 Demo.

## Deprecate support for dumping tracing to a relational database

It wasn't _that_ long ago Dogen was extended to dump tracing information into relational databases such as [PostgreSQL](https://www.postgresql.org/) and their ilk. In fact, [v1.0.20](https://github.com/MASD-Project/dogen/releases/tag/v1.0.20)'s release notes announced this new feature with great fanfare, and we genuinely had high hopes for its future. You are of course forgiven if you fail to recall what the fuss was all about, so it is perhaps worthwhile doing a quick recap. Tracing - or _probing_ as it was known then - was introduced in the long forgotten days of [Dogen v1.0.05](https://github.com/MASD-Project/dogen/releases/tag/v1.0.05), the idea being that it would be useful to inspect model state as the transform graph went through its motions. Together with log files, this treasure trove of information enabled us to understand where things went wrong quickly, more often than not without necessitating a debugger. And it was indeed incredibly useful to begin with, but we soon got bored of manually inspecting trace files. You see, the trouble with these crazy critters is that they are rather plump blobs of JSON, thus making it difficult to understand "before" and "after" diffs for the state of a given model transform - even when allowing for [json-diff](https://github.com/andreyvit/json-diff) and the like. To address the problem we doubled-down on our usage of [JQ](https://stedolan.github.io/jq/), but the more we did so, the clearer it became that JQ queries competed in the readability space with computer science classics like regular expressions and perl. A few choice data points should give a flavour of our troubles:

```bash
# JQ query to obtain file paths:
$ jq .models[0].physical.regions_by_logical_id[0][1].data.artefacts_by_archetype[][1].data.data.file_path
# JQ query to sort models by elements:
$ jq '.elements|=sort_by(.name.qualified)'
# JQ query for element names in generated model:
$ jq ."elements"[]."data"."__parent_0__"."name"."qualified"."dot"
```

It is of course deeply unfair to blame JQ for all our problems, since "meaningful" names such as ```__parent_0__``` fall squarely within Dogen's sphere of influence. Moreover, as a tool JQ is extremely useful for what it is _meant_ to do, as well as being incredibly fast at it. Nonetheless, we begun to accumulate more and more of these query fragments, glued them up with complex UNIX shell pipelines that dumped information from trace files into text files, and then dumped diffs of said information to other text files which where then... - well, you get the drift. These scripts were extremely brittle and mostly "one-off" solutions, but at least the direction of travel was obvious: what was needed was a way to build up a number of queries targeting the "before" and "after" state of any given transform, such that we could ask a series of canned questions like "has object X gone missing in transform T0?" or "did we update field Y incorrectly in transform T1?",  and so on. One can easily conceive that a large library of these queries would accumulate over time, allowing us to see at a glance what changed between transforms and, in so doing, make routine investigations several orders of magnitude faster. Thus far, thus logical. We then investigated PostgreSQL's JSON support and, at first blush, found it to be [very comprehensive](https://www.postgresql.org/docs/current/functions-json.html). Furthermore, given that Dogen always had basic support for [ODB](https://www.codesynthesis.com/products/odb/), it was "easy enough" to teach it to dump trace information into a relational database - which we did in the [aforementioned release](https://github.com/MASD-Project/dogen/releases/tag/v1.0.20).

Alas, after the initial enthusiasm, we soon realised that expressing our desired questions as database queries was _far_ more difficult than anticipated. Part of it is related to the complex graph that we have on our JSON documents, which could be helped by creating a more relational-database-friendly model; and part of it is the inexperience with PostgreSQL's JSON query extensions. Sadly, we do not have sufficient time address either question properly, given the required engineering effort. To make matters worse, even though it was not being used in anger, the maintenance of this code was become increasingly expensive due to two factors:

- its reliance on a beta version of ODB ([v2.5](https://www.codesynthesis.com/pipermail/odb-users/2021-October/004696.html)), for which there are no DEBs readily available; instead, one is expected to build it from source using [Build2](https://build2.org/), an extremely interesting but rather _suis generis_ build tool; and
- its reliance on either manual install of the ODB C++ libraries or a patched version of [vcpkg](https://vcpkg.io/en/getting-started.html) with support for v2.5. As vcpkg undergoes constant change, this means that every time we update it, we then need to spend ages porting our code to the new world.

Now, one of the rules we've had for the longest time in Dogen is that, if something is not adding value (or worse, _subtracting_ value) then it should be deprecated and removed until such time it can be proven to add value. As with any spare time project, time is extremely scarce, so we barely have enough of it to be confused with the real issues at hand - let alone speculative features that may provide a pay-off one day. So it was that, with great sadness, we removed all support for the relational backend on this release. Not all is lost though. We use [MongoDB](https://www.mongodb.com/) a fair bit at work, and got the hang of its query language. A much simpler alternative is to dump the JSON documents into MongoDB - a shell script would do, at least initially - and then write Mongo queries to process the data. This is an approach we shall explore next time we get stuck investigating an issue using trace dumps.

## Add "verbatim" PlantUML extension

Since we moved away from [Dia](https://wiki.gnome.org/Apps/Dia), the quality of our diagrams degraded considerably. This is to be expected; when we originally added PlantUML support in the [previous release](https://github.com/MASD-Project/dogen/releases/tag/v1.0.30), it was as much a feasibility study as it was the implementation of a new feature. So the understanding was that we'd spend a number of sprints adding improvements to this new codec, until it got to the point where the diagrams where of comparable quality to the Dia ones. However, this sprint it dawned on us just how much machinery would be required to properly model relations in the rich way we had in Dia. Worse: it is not necessarily possible to merely record relations between entities in the input codec and then map those to a UML diagram, the reason being that, in Dia, we cleverly choose which relations are of significance and ignore those we deemed to be less interesting when conveying meaning on a diagram. To make matters more concrete, imagine a [vocabulary type](https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2020/p2125r0.pdf) such as ```entities::name``` in model ```dogen::identification```. It is used throughout the whole of Dogen, and any entity with a representation in the LPS (Logical-Physical Space) will use it. A blind approach of modeling each and every relation to a core type such as this would result in a mess of inter-crossing lines, removing any meaning from the resulting diagram.

After a great deal of pondering, we decided that the PlantUML output needs two kinds of data sources: _automated_, where the relationship is obvious and uncontroversial, such as say the attributes that make up a class; and _manual_, where the relationship requires hand-holding by a human. This is useful for example in the above case, where one would like to suppress the relationships with a basic vocabulary type. This feature was implemented by means of adding a  PlantUML  _verbatim_  attribute to models. It is called "verbatim" because we merely add **exactly** what you put in there into the final PlantUML output. By convention, these statements are placed straight after the entity they were added to. It is perhaps easier to understand this feature by means of an example. Say in the ```dogen.codec``` model one wishes to add a relationship between ```model``` and ```element```. One could go about it as follows:

![Dogen.Codec model](https://github.com/MASD-Project/dogen/releases/download/v1.0.31/add_plantuml_relationships_via_verbatim.png)
_Figure 1_: Use of the verbatim PlantUML property in the ```dogen.codec``` model.

As you can see, the property ```masd.codec.plantuml``` is extremely simple: it merely allows one to enter valid PlantUML statements, which are subsequently transported into the generated source code without modification, _e.g._:

![PlantUML generated source](https://github.com/MASD-Project/dogen/releases/download/v1.0.31/plantuml_source_with_verbatim_attribute.png)
_Figure 2_: PlantUML source code for ```dogen.codec``` model.

For good measure, we can observe the final (graphical) output produced by PlantUML, with the two relations. Its worth highlighting a couple of things here. The first is that we added a relationship with the object template ```Element```. Now, it is not entirely clear this is the correct way in UML to model relationships with object templates - the last expert I consulted was not entirely pleased with this approach - but no matter. The salient point is not whether this specific representation is correct or incorrect, but that one can choose to use this or any other representation quite easily, as desired. Secondly and similarly, the aggregation between ```model_set```, ```model``` and ```element``` is something that one would like to highlight in this model, and it is possible to do so trivially by means of this feature. Each of these classes is composed of a number of attributes which are not  particularly interesting from a relationship perspective, and adding relations for all of those would greatly increase the amount of noise in the diagram.

![PlantUML output](https://github.com/MASD-Project/dogen/releases/download/v1.0.31/graphical_representation_of_plantuml_model.png)
_Figure 3_: Graphical output produced by PlantUML from Dogen-generated sources.

This feature is a great example of how often one needs to think of a problem from many different perspectives before arriving at a solution; and that, even though the problem may appear extremely complex at the start, sometimes all it takes is to view it from a completely different angle. All and all, the feature was implemented in just over two hours; we had originally envisioned lots of invasive changes at the lowers levels of Dogen just to propagate this information, and likely an entire sprint dedicated to it. To be fair, the jury is not out yet on whether this is really the correct approach. Firstly, because we now need to go through each and every model and compare the relations we had in Dia to those we see in PlantUML, and implement them if required. Secondly, we have no way of knowing if the PlantUML input is correct or not, short of writing a parser for their syntax - which we won't consider. This means the user will only find out about syntax errors after running PlantUML - and given it will be within generated code, it is entirely likely the error messages will be less than obvious as to what is causing the problem. Finally and somewhat related:  the _verbatim_ nature of this attribute entails bypassing the Dogen type system entirely, by design. This means that  if this information is useful for purposes other than PlantUML generation - say for example for regular source code generation - we would have no access to it.

A possibly better way of modeling this property is to add a non-verbatim attribute such as "significant relationship" or "user important relationship" or some such. Whatever its name, said attribute would model the notion of there being an important relationship between some types within the Dogen type system, and it could then be used by the PlantUML codec to output it in its syntax. However, before we get too carried away, its important to remember that we always take the simplest possible approach first and wait until use cases arrive, so all of this analysis has been farmed off to the backlog for some future use.

## Video series on MDE and MASD

In general, we tend to place our YouTube videos under the Development Matters section of the release notes because these tend to be about coding within the narrow confines of Dogen. As with so many items within this release, an exception was made for one of the series because it is likely to be of interest to Dogen developers and users alike. The series in question is called "MASD: An introduction to Model Assisted Software Development", and it is composed of 10 parts as of this writing. Its main objective was to prepare us for the _viva_, so the long arc of the series builds up to why one would want to create a new methodology and ends with an explanation of what that methodology might be. However, as we were unsure as to whether we could use material directly from [the thesis](https://uhra.herts.ac.uk/handle/2299/25708), and given our shortness of time to create new material specifically for the series, we opted for a high-level description of the methodology which is somewhat unsatisfactory due to a lack of visuals. We are therefore considering an additional 11th part which reviews a couple of key chapters from the thesis, namely Chapters 5 and 6.

At any rate, the individual videos are listed on Table 1, with a short description. They are also available as a playlist, as per link below.

![MASD: An introduction to Model Assisted Software Development](https://img.youtube.com/vi/yRFjSegsC_s/0.jpg)
_Video 2_: Playlist "MASD: An introduction to Model Assisted Software Development".

|Video | Description |
|---------|-----------------|
| [Part 1](https://www.youtube.com/watch?v=yRFjSegsC_s) | This lecture is the start of an overview of Model Driven Engineering (MDE), the approach that underlies MASD.|
| [Part 2](https://www.youtube.com/watch?v=Q-5Ic_gOd0Y)|In this lecture we conclude our overview of MDE by discussing Platforms and Technical Spaces, and we start to look at the field in more detail, critiquing its foundations.|
| [Part 3](https://www.youtube.com/watch?v=P20uEmc0wtc)|In this lecture we discuss the two fundamental concepts of MDE: Models and Transformations.|
| [Part 4](https://www.youtube.com/watch?v=_x5Wnab8Ipk)|In this lecture we take a large detour to think about the philosophical implications of modeling. In the detour we discuss Russell, Whitehead, Wittgenstein and Meyers amongst others.|
| [Part 5](https://www.youtube.com/watch?v=w1ZH4v8UiJU)|In this lecture we finish our excursion into the philosophy of modeling and discuss two core topics: Technical Spaces (TS) and Platforms.|
|[Part 6](https://www.youtube.com/watch?v=TcCNNpH4EfM)|In this video we take a detour and talk about research, and how our programme in particular was carried out - including all the bumps and bruises we faced along the way.|
|[Part 7](https://www.youtube.com/watch?v=r33MbmOv2ag)|In this lecture we discuss Variability and Variability Management in the context of Model Driven Engineering (MDE).|
|[Part 8](https://www.youtube.com/watch?v=AAvopzFQm9Q)|In this lecture we start a presentation of the material of the thesis itself, covering state of the art in code generation, and the requirements for a new approach.|
|[Part 9](https://www.youtube.com/watch?v=EFPMWq5SNGQ)|In this lecture we outline the MASD methodology: its philosophy, processes, actors and modeling language. We also discuss the domain architecture in more detail.|
|[Part 10](https://www.youtube.com/watch?v=EFPMWq5SNGQ)|In this final lecture we discuss Dogen, introducing its architecture.|

_Table 1_: Video series for "MASD: An introduction to Model Assisted Software Development".

# Development Matters

In this section we cover topics that are mainly of interest if you follow Dogen development, such as details on internal stories that consumed significant resources, important events, etc. As usual, for all the gory details of the work carried out this sprint, see the sprint log. As usual, for all the gory details of the work carried out this sprint, see [the sprint log](https://github.com/MASD-Project/dogen/blob/master/doc/agile/v1/sprint_backlog_31.org).

## Milestones and Éphémérides

This sprint marks the end of the PhD programme that started in 2014.

![PhD Thesis](https://github.com/MASD-Project/dogen/releases/download/v1.0.31/phd_thesis_in_uh_archive.png)
_Figure 3_: PhD thesis within the University of Hertfordshire archives.

## Significant Internal Stories

From an engineering perspective, this sprint had one goal which was to restore our CI environment. Other smaller stories were also carried out.

### Move CI to GitHub actions

A great number of stories this sprint (listed below) were connected with returning to a sane world of continuous integration, which we had lost with the demise of the open source support for [Travis CI](https://www.travis-ci.org). First and foremost, I'd like to give a huge shout out to Travis CI for all the years of supporting open source projects, even when perhaps it did not make huge financial sense. Prior to this decision, we had relied on Travis CI quite a lot, and in general it just worked. To my knowledge, they were the first ones to introduce the simple YAML markup for their IaC language, and it still supports features that we could not map to in our new approach (_e.g._  the infamous issue [#399](https://github.com/actions/toolkit/issues/399)). So it was not without sadness that we lost Travis CI support and found ourselves needing to move on to a new, hopefully stable, home. As we have support for [GitHub](https://github.com/MASD-Project/dogen), [BitBucket](https://bitbucket.org/MASD-Project/dogen/src/master/) and [GitLab](https://gitlab.com/DomainDrivenConsulting/dogen) as Git clones, we considered these three providers. In the end, we settled on GitHub actions, mainly because of the wealth of example projects using C++. All things considered, the move was remarkably easy, though not without its challenges. At present we seem to have all Dogen builds across Linux, Windows and OSX working reliably - though, as always, much work still remains such as porting all of our reference products.

![GitHub Actions](https://github.com/MASD-Project/dogen/releases/download/v1.0.31/github_actions_for_dogen.png)
_Figure 4_: GitHub actions for the Dogen project.

,**Related Stories**: "Move build to GitHub", "Can't see build info in github builds", "Update the test package scripts for the GitHub CI", "Remove deprecated travis and appveyor config files", "Create clang build using libc++", "Add packaging step to github actions", "Setup MSVC Windows build for debug and release", "Update build instructions in readme", "Update the test package scripts for the GitHub CI", "Comment out clang-cl windows build", "Setup the laptop for development", "Windows package is broken", "Rewrite CTest script to use github actions".

### Improvements to vcpkg setup

As part of the move to GitHub actions, we decided to greatly simplify our builds. In the past we had relied on a hack: we built all our third party dependencies and placed them, as a zip, on DropBox. This worked, but it meant that updating these dependencies was a major pain. In particular, we often forgot how exactly those builds had been done and where we had sourced all of the libraries. As part of the research on GitHub actions, it became apparent that all the cool kids had moved on to using [vcpkg](https://vcpkg.io/en/getting-started.html) within the CI itself, with a set of supporting actions that made this use case much easier than before. This is highly advantageous because it means that updating the third party dependencies means merely having to update a git submodule. We took this opportunity and simplified all of our dependencies, which meant that sadly we had to remove our support for ODB since v2.5 is not available on vcpkg (see above). Nonetheless, the new setup is an improvement of several orders of magnitude, especially because in the past we had to have our own OSX and Windows Physicals/VM's to build the dependencies whereas now we rely only on vcpkg.

,**Related Stories**:  "Update vcpkg to latest", "Remove third-party dependencies outside vcpkg",  "Update nightly builds to use new vcpkg setup".

### Improvements to CTest and CMake scripts

Closely related to the work on vcpkg and GitHub actions was a number of fundamental changes to our CMake and CTest setup. First and foremost, we like to point out the move to use CMake Presets. This is a great little feature in CMake that enables one to pack all of the CMake configuration into a preset file, removing the need for the old ```build.*``` scripts that had littered our build directory. It also means that building from Emacs - as well as other editors and IDEs which support presets, of course - is now really easy. In the past we had to supply a number o environment variables and other swuch incantations to the build script in order to setup the required environment. With presets all of that is encapsulated into a self comntained ```CMakePresets.json``` file, making the build much simpler:


```
cmake --preset linux-clang-release
cmake --build --preset linux-clang-release
```

You can also list the available presets very easily:

```
$ cmake --list-presets
Available configure presets:

  "linux-clang-debug"             - Linux clang debug
  "linux-clang-release"           - Linux clang release
  "linux-gcc-debug"               - Linux gcc debug
  "linux-gcc-release"             - Linux gcc release
  "windows-msvc-debug"            - Windows x64 Debug
  "windows-msvc-release"          - Windows x64 Release
  "windows-msvc-clang-cl-debug"   - Windows x64 Debug
  "windows-msvc-clang-cl-release" - Windows x64 Release
  "macos-clang-debug"             - Mac OSX Debug
  "macos-clang-release"           - Mac OSX Release
```

This ensures a high degree of regularity of Dogen builds if you wish to stick to the defaults, which is the case for almost all our use cases. The exception had been nightlies, but as we explain elsewhere, with this release we also managed to make those builds conform to the same overall approach.

The release also saw a general clean up of the CTest script, now called ```CTest.cmake```, which supports both continuous as well as nighly builds with minimal complexity. Sadly, the integration of presets with CTest is not exactly perfect, so it took us a fair amount of time to work out how to best get these two to talk to each other.

,**Related Stories**: "Rewrite CTest script to use github actions", "Assorted improvements to CMake files"

### Smaller stories

In addition to the big ticket items, a number of smaller stories was also worked om.

- **Fix broken org-mode tests**: due to the _ad-hoc_ nature of our org-mode parser, we keep finding weird and wonderful problems with code generation, mainly related to the introduction of spurious whitelines. This sprint we fixed yet another group of these issues. Going forward, the right solution is to remove org-mode support from within Dogen, since we can't find a third party library that is rock solid, and add instead an XMI-based codec. We can then extend Emacs to generate this XMI output. There are downsides to this approach - for example, the loss of support to non-Emacs based editors such as VI and VS Code.
- **Generate doxygen docs and add to site**: Every so often we update manually the Doxygen docs available [on our site](https://mcraveiro.github.io/dogen/doxygen/index.html). This time we also added a badge linking back to the documentation. Once the main bulk of work is finished with GitHub actions, we need to consider adding an action to regenerate documentation.
- **Update build instructions in README***: This sprint saw a raft of updates to our [REAMDE file](https://github.com/MASD-Project/dogen/blob/master/README.md), mostly connected with the end of the tesis as well as all the build changes related to GitHub actions.
- **Replace Dia IDs with UUIDs**: Now that we have removed Dia models from within Dogen, it seemed appropriate to get rid of some of its vestiges such as Object IDs based on Dia object names. This is yet another small step towards making the org-mode models closer to their native representation. We also begun work on supporting proper capitalisation of org-mode headings ("Capitalise titles in models correctly"), but sadly this proved to be much more complex than expected and has since been returned to the product backlog for further analysis.
- **Tests should take full generation into account**: Since time immemorial, our nightly builds have been, welll, _different_, from regular CI builds. This is because we make use of a feature called "full generation". Full generation forces the instantiation of model elements across all facets of physical space regardless of the requested configuration within the user model. This is done so that we exercise generated code to the fullest, and also has the great benefit of valgrinding the generated tests, hopefully pointing out any leaks we may have missed. One major down side of this approach was the need to somehow "fake" the contents of the Dogen directory, to esnure the generated tests did not break. We did this via the "pristine" hack: we kept two checkouts of Dogen, and pointed the tests of the main build towards this printine directory, so that the code geneation tests did not fail. It was ugly but just about worked. That is, until we introduced CMake Presets. Then, it caused all sorts of very annoying issues. In this sprint, after the longest time of trying to extend the hack, we finally saw the obvious: the easiest way to address this issue is to extend the tests to also use full generation. This was very easy to implement and made the nightlies regular with respect to the continuous builds.

### Video series of Dogen coding

This sprint we recorded a series of videos titled "MASD - Dogen Coding: Move to GitHub CI". It is somewhat more generic than the name implies, because it includes a lot of the side-tasks needed to make GitHub actions work such as removing third party dependencies, fixing CTest scripts, _etc._ The video series is available as a playlist, in the link below.

[![Move to GitHub CI](https://img.youtube.com/vi/l13FwDpvcA8/0.jpg)](https://youtu.be/ei8B1Pine34)
_Video 3_: Playlist for  "MASD - Dogen Coding: Move to GitHub CI".

The next table shows the individual parts of the video series.

|Video | Description |
|---------|-----------------|
| [Part 1](https://www.youtube.com/watch?v=l13FwDpvcA8)|In this part we start by getting all unit tests to pass.|
| [Part 2](https://www.youtube.com/watch?v=v7ebzs6XIf4)|In this video we update our vcpkg fork with the required libraries, including ODB. However, we bump into problems getting Dogen to build with the new version of ODB.|
| [Part 3](https://www.youtube.com/watch?v=JOQPzueENB0)|In this video we decide to remove the relational model altogether as a way to simplify the building of Dogen. It is a bittersweet decision as it took us a long time to code the relational model, but in truth it never lived up to its original promise.|
| [Part 4](https://www.youtube.com/watch?v=zu-YeZ6akcM)|In this short video we remove all uses of Boost DI. Originally, we saw Boost DI as a solution for our dependency injection needs, which are mainly rooted in the registration of M2T (Model to Text) transforms.|
| [Part 5](https://www.youtube.com/watch?v=OdDDQlV72BA)|In this video we update vcpkg to use latest and greatest and start to make use of the new standard machinery for CMake and vcpkg integration such as CMake presets. However, ninja misbehaves at the end.|
| [Part 6](https://www.youtube.com/watch?v=aY_OLBtkEHY)|In this part we get the core of the workflow to work, and iron out a lot of the kinks across all platforms.|
| [Part 7](https://www.youtube.com/watch?v=gtV9frKFZTw)|In this video we review the work done so far, and continue adding support for nightly builds using the new CMake infrastructure.|
| [Part 8](https://www.youtube.com/watch?v=Pf-nD5UpLT8)|This video concludes the series. In it, we sort out the few remaining problems with nightly builds, by making them behave more like the regular CI builds.|

_Table 2_: Video series for "MASD - Dogen Coding: Move to GitHub CI".

## Resourcing

At over ten months duration, this sprint was characterised mainly by its irregularity, rendering metrics such as utilisation rate rather meaningless. It would of course be an unfair comment if we stopped at that - given how much was achieved on the PhD front -  but alas these are not resourcing concerns, given its sole focus on engineering effort. Looking at the sprint as a whole, it must be classified was very productive, weighing in at just over 85 hours and haing largely achieved our sprint goals. It is of course very disappointing to spend this much effort just to get back to where we were in terms of CI/CD in the Travis CI golden days, but it is what it is, and if anything our new setup is certainly a step up in terms of functionality when compared to the Travis/AppVeyor approach.

The most expensive story, by far, was the rewrite of the CTest scripts, at almost 16% of total effort, and it was closely followed by our series of lectures on MDE and MASD (11%). We also spent an uncharacteristic large amount of time refining our sprint and product backlogs: 10% versus the 7% of sprint 30 and the 3.5% of sprint 29. Of course, in the context of ten months with very little coding, it does make sense that we spent a lot of time having ideas about coding. All told, just under 60% of the sprint's total resourcing was directly related to its missing

![Sprint 31 stories](https://github.com/MASD-Project/dogen/releases/download/v1.0.31/sprint_31_pie_chart.jpg)
_Figure 5_: Cost of stories for sprint 31.

## Roadmap

![Project plan](https://github.com/MASD-Project/dogen/releases/download/v1.0.31/sprint_31_project_plan.png)


![Resource allocation](https://github.com/MASD-Project/dogen/releases/download/v1.0.31/sprint_31_resource_allocation_graph.png)

# Binaries

You can download binaries from either [Bintray](https://bintray.com/masd-project/main/dogen/1.0.30) or [GitHub](https://github.com/MASD-Project/dogen/releases/tag/v1.0.30), as per Table 3. All binaries are 64-bit. For all other architectures and/or operative systems, you will need to build Dogen from source. Source downloads are available in [zip](https://github.com/MASD-Project/dogen/archive/v1.0.30.zip) or [tar.gz](https://github.com/MASD-Project/dogen/archive/v1.0.30.tar.gz) format.

| Operative System | Debug | Release |
|--------------------------|------------|-----------|
| Linux Debian/Ubuntu (Deb) | [linux-clang-debug](https://github.com/MASD-Project/dogen/suites/8228081571/artifacts/359021758) | [linux-clang-release](https://github.com/MASD-Project/dogen/suites/8228081571/artifacts/359021759) |
| Linux Debian/Ubuntu (Deb) | [linux-gcc-debug](https://github.com/MASD-Project/dogen/suites/8228081571/artifacts/359021760) | [linux-gcc-release](https://github.com/MASD-Project/dogen/suites/8228081571/artifacts/359021761) |
| Windows (MSI) | [windows-msvc-debug](https://github.com/MASD-Project/dogen/suites/8228081572/artifacts/359031416) | [windows-msvc-release](https://github.com/MASD-Project/dogen/suites/8228081572/artifacts/359031417) |
| Mac OSX (DMG) | [macos-clang-debug](https://github.com/MASD-Project/dogen/suites/8228081569/artifacts/359027762) | [macos-clang-release](https://github.com/MASD-Project/dogen/suites/8228081569/artifacts/359027763) |

_Table 3_: Binary packages for Dogen.

,**Note 1:** The Linux binaries are not stripped at present and so are larger than they should be. We have [an outstanding story](https://github.com/MASD-Project/dogen/blob/master/doc/agile/product_backlog.org#linux-and-osx-binaries-are-not-stripped) to address this issue, but sadly CMake does not make this a trivial undertaking.

,**Note 2:** Due to issues with Travis CI, we did not manage to get OSX to build, so and we could not produce a final build for this sprint. The situation with Travis CI is rather uncertain at present so we may remove support for OSX builds altogether next sprint.

# Next Sprint

That's all for this release. Happy Modeling!
#+end_src

*** COMPLETED Create a demo and presentation for previous sprint      :story:
    :LOGBOOK:
    CLOCK: [2022-09-16 Fri 19:15]--[2022-09-16 Fri 20:13] =>  0:58
    CLOCK: [2022-09-16 Fri 13:55]--[2022-09-16 Fri 14:53] =>  0:58
    CLOCK: [2022-09-14 Wed 18:42]--[2022-09-14 Wed 18:52] =>  0:10
    :END:

Time spent creating the demo and presentation.

**** Presentation

***** Dogen v1.0.31, "Exeunt Academia"

    Marco Craveiro
    Domain Driven Development
    Released on 4th September 2022

*** COMPLETED Update boost to latest in vcpg                          :story:
    :LOGBOOK:
    CLOCK: [2022-09-17 Sat 13:00]--[2022-09-17 Sat 13:20] =>  0:20
    :END:

Boost 1.80 is now available.

*** COMPLETED Improve diffing output in tests                         :story:
    :LOGBOOK:
    CLOCK: [2022-09-19 Mon 08:04]--[2022-09-19 Mon 08:23] =>  0:19
    :END:

When a test fails with differences, we get the following output:

#+begin_example
Differences found. Outputting head of first 5 diffs.
diff -u include/dogen.identification/io/entities/name_io.hpp include/dogen.identification/io/entities/name_io.hpp
Reason: Changed generated file.
---  include/dogen.identification/io/entities/name_io.hpp
+++  include/dogen.identification/io/entities/name_io.hpp
@@ -1,11 +1,5 @@
 /* -*- mode: c++; tab-width: 4; indent-tabs-mode: nil; c-basic-offset: 4 -*-
  *
- * These files are code-generated via overrides to test dogen. Do not commit them.
- *
- * Generation timestamp: 2022-09-19T00:04:25
- * WARNING: do not edit this file manually.
- * Generated by MASD Dogen v1.0.32
- *
  * Copyright (C) 2012-2015 Marco Craveiro <marco.craveiro@gmail.com>
  *
  * This program is free software; you can redistribute it and/or modify
#+end_example

There are problems with this:

- it appears as if the generated files are missing these lines. However, when we
  look at the filesystem, they are absent from the original files. So it may be
  the generated files are generating this and shouldn't. We should always check
  from the perspective of the files in the filesystem.
- the =---= and =+++= should say what they mean.
- actually upon investigation, the test files did contain the output:

#+begin_example
 * These files are code-generated via overrides to test dogen. Do not commit them.
 *
 * Generation timestamp: 2022-09-19T00:04:25
 * WARNING: do not edit this file manually.
 * Generated by MASD Dogen v1.0.32
 *
 * Copyright (C) 2012-2015 Marco Craveiro <marco.craveiro@gmail.com>
#+end_example

Something went wrong with full generation. The problem appears to be that full
generation overrides the decoration settings.

*** STARTED Sprint and product backlog grooming                       :story:
    :LOGBOOK:
    CLOCK: [2022-09-23 Fri 14:54]--[2022-09-23 Fri 14:59] =>  0:05
    CLOCK: [2022-09-23 Fri 14:42]--[2022-09-23 Fri 14:53] =>  0:11
    CLOCK: [2022-09-23 Fri 10:29]--[2022-09-23 Fri 10:33] =>  0:04
    CLOCK: [2022-09-22 Thu 08:47]--[2022-09-22 Thu 08:56] =>  0:09
    CLOCK: [2022-09-20 Tue 08:15]--[2022-09-20 Tue 08:21] =>  0:06
    CLOCK: [2022-09-19 Mon 11:42]--[2022-09-19 Mon 11:50] =>  0:08
    CLOCK: [2022-09-19 Mon 08:29]--[2022-09-19 Mon 08:29] =>  0:00
    CLOCK: [2022-09-19 Mon 08:24]--[2022-09-19 Mon 08:28] =>  0:04
    CLOCK: [2022-09-18 Sun 07:37]--[2022-09-18 Sun 07:39] =>  0:02
    CLOCK: [2022-09-17 Sat 21:24]--[2022-09-17 Sat 21:27] =>  0:03
    CLOCK: [2022-09-14 Wed 18:53]--[2022-09-14 Wed 19:02] =>  0:09
    CLOCK: [2022-09-06 Tue 12:07]--[2022-09-06 Tue 12:24] =>  0:17
    CLOCK: [2022-09-06 Tue 11:40]--[2022-09-06 Tue 12:06] =>  0:26
    :END:

Updates to sprint and product backlog.

*** COMPLETED Nightly builds are failing due to missing environment var :story:
    :LOGBOOK:
    CLOCK: [2022-09-19 Mon 07:35]--[2022-09-19 Mon 08:02] =>  0:27
    CLOCK: [2022-09-18 Sun 18:21]--[2022-09-18 Sun 18:40] =>  0:19
    CLOCK: [2022-09-18 Sun 07:29]--[2022-09-18 Sun 07:34] =>  0:05
    CLOCK: [2022-09-17 Sat 20:55]--[2022-09-17 Sat 21:11] =>  0:16
    :END:

We have a few tests failing with the following error:

#+begin_example
/home/marco/nightly/dogen/master/projects/dogen.utility/src/types/environment/variable_reader.cpp(96): Throw in function strict_read_environment_variable
Dynamic exception type: boost::wrapexcept<dogen::utility::environment::environment_exception>
std::exception::what: Environment variable is empty or not defined: DOGEN_PROJECTS_DIRECTORY
unknown location(0): fatal error: in "Test setup": std::runtime_error: Error during test
/home/marco/nightly/dogen/master/projects/dogen.codec/tests/main.cpp(35): last checkpoint: initializer
Running 1 test case...

 *** No errors detected
Test setup error:
#+end_example

We do not seem to be using presets in the nightly for some reason.

Notes:

- this is due to a bug on the CTest script which is resetting the CMake
  arguments for nightlies.
- it appears we are not using parallel builds during nightly, we are taking over
  8h for a single build. This has now been fixed.
- one of the tests is now timing out:

  : dogen.logical.generated_tests/entities_input_model_set_tests/xml_roundtrip_produces_the_same_entity	Failed	10m 10ms	Completed (Timeout)

  We need to find out how to increase the timeout.
- clang builds have the wrong DWARF2 format:

  : unhandled dwarf2 abbrev form code 0x25

Links:

- [[https://cmake.org/cmake/help/latest/command/ctest_build.html][ctest_build]]
- [[https://bugzilla.mozilla.org/show_bug.cgi?id=1758782][FireFox: Valgrind run fails when building with clang 14]]
- [[https://bugs.kde.org/show_bug.cgi?id=452758][kde: Valgrind does not read properly DWARF5 as generated by Clang14]]
- [[https://stackoverflow.com/questions/45009595/how-to-overwrite-ctest-default-timeout-1500-in-cmakelists-txt][SO: How to overwrite Ctest default timeout 1500 in CMakeLists.txt]]

Merged stories:

*Nightly builds are failing due to missing variable*

At present we are getting the following error:

: /home/marco/nightly/dogen/master/projects/dogen.utility/src/types/environment/variable_reader.cpp(96): Throw in function static std::string dogen::utility::environment::variable_reader::strict_read_environment_variable(const std::string&)
: Dynamic exception type: boost::wrapexcept<dogen::utility::environment::environment_exception>
: std::exception::what: Environment variable is empty or not defined: DOGEN_PROJECTS_DIRECTORY
: unknown location(0): fatal error: in "Test setup": std::runtime_error: Error during test
: /home/marco/nightly/dogen/master/projects/dogen.codec/tests/main.cpp(35): last checkpoint: initializer
: Running 1 test case...

*Fix errors in nightly builds*

*** COMPLETED Remove deprecated uses of boost bind                    :story:
   :LOGBOOK:
   CLOCK: [2022-09-17 Sat 21:14]--[2022-09-17 Sat 21:23] =>  0:09
   :END:

#+begin_example
[56/2312] Building CXX object projects/dogen/generated_tests/CMakeFiles/dogen.generated_tests.dir/spec_category_tests.cpp.o
In file included from /usr/include/boost/smart_ptr/detail/sp_thread_sleep.hpp:22,
                 from /usr/include/boost/smart_ptr/detail/yield_k.hpp:23,
                 from /usr/include/boost/smart_ptr/detail/spinlock_gcc_atomic.hpp:14,
                 from /usr/include/boost/smart_ptr/detail/spinlock.hpp:42,
                 from /usr/include/boost/smart_ptr/detail/spinlock_pool.hpp:25,
                 from /usr/include/boost/smart_ptr/shared_ptr.hpp:29,
                 from /usr/include/boost/shared_ptr.hpp:17,
                 from /usr/include/boost/test/tools/assertion_result.hpp:21,
                 from /usr/include/boost/test/tools/old/impl.hpp:20,
                 from /usr/include/boost/test/test_tools.hpp:46,
                 from /usr/include/boost/test/unit_test.hpp:18,
                 from /home/marco/nightly/dogen/master/projects/dogen/generated_tests/spec_category_tests.cpp:29:
/usr/include/boost/bind.hpp:36:1: note: ‘#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS
#+end_example

Links:

- [[https://stackoverflow.com/questions/63084695/note-when-building-cgal-code-the-practice-of-declaring-the-bind-placeholders][SO: Note when building CGAL code: The practice of declaring the Bind
  placeholders (_1, _2, ...) in the global namespace is deprecated]]

*** COMPLETED Full generation support in tests is incorrect           :story:
    :LOGBOOK:
    CLOCK: [2022-09-25 Sun 08:57]--[2022-09-25 Sun 09:12] =>  0:15
    CLOCK: [2022-09-23 Fri 07:50]--[2022-09-23 Fri 08:01] =>  0:11
    CLOCK: [2022-09-22 Thu 07:30]--[2022-09-22 Thu 07:39] =>  0:09
    CLOCK: [2022-09-21 Wed 23:20]--[2022-09-21 Wed 23:53] =>  0:33
    CLOCK: [2022-09-21 Wed 08:24]--[2022-09-21 Wed 08:48] =>  0:24
    CLOCK: [2022-09-21 Wed 07:40]--[2022-09-21 Wed 07:47] =>  0:07
    CLOCK: [2022-09-20 Tue 18:51]--[2022-09-20 Tue 19:05] =>  0:14
    CLOCK: [2022-09-20 Tue 08:34]--[2022-09-20 Tue 08:59] =>  0:25
    CLOCK: [2022-09-19 Mon 11:18]--[2022-09-19 Mon 11:28] =>  0:10
    CLOCK: [2022-09-19 Mon 08:29]--[2022-09-19 Mon 09:19] =>  0:50
    :END:

Nightly build now uses full generation for tests. The problem is that full
generation expresses decoration as well:

#+begin_example
 * These files are code-generated via overrides to test dogen. Do not commit them.
 *
 * Generation timestamp: 2022-09-19T00:04:25
 * WARNING: do not edit this file manually.
 * Generated by MASD Dogen v1.0.32
 *
 * Copyright (C) 2012-2015 Marco Craveiro <marco.craveiro@gmail.com>
#+end_example

We need a way to set decoration to false in the model and respect that somehow.
Actually, it seems the problem is we are not honouring the variability overrides
in the tests.

The issue was we were supplying the command line incorrectly:

: --variability-override masd.variability.profile,masd.variability.profile,"

The command line argument =--variability-override= is not necessary. However,
when we fixed this we then created a whole raft of problems:

- we are now fully generating *everything*, including all reference products.
- for some reason the profile cannot be found for the c++ reference product:

  : std::exception::what: Configuration references a profile that could not be found: dogen.profiles.base.test_all_facets

- not clear why we do not throw on an invalid variability override. One for the
  backlog.

The quick hack is to only use the overrides on Dogen tests somehow.

With the builder changes we now get the following error:

#+begin_example
Running 1 test case...
Differences found. Outputting head of first 5 diffs.
/home/marco/nightly/dogen/master/projects/dogen.orchestration/tests/dogen_org_product_tests.cpp(83): error: in "dogen_product_org_tests/dogen_cli_org_produces_expected_model": check mg::check_for_differences(od, m) has failed

 *** 1 failure is detected in the test module "dogen.orchestration.tests"
#+end_example

This appears to reveal some bug in the diffing logic given that we do not see
any differences.

Notes:

- its not obvious what is causing this difference but it seems there is some
  logic error in the check for differences method. We must be falling through
  the cracks on some unforeseen case.

The problem is we had disabled diffing. Enabling diffing we now see:

#+begin_src diff
Unexpected write: dogen.identification/include/dogen.identification/types/entities/name_fwd.hpp
Reason: { "__type__": "operation_reason", "value": "changed_generated" }
diff -u include/dogen.identification/types/entities/name_fwd.hpp include/dogen.identification/types/entities/name_fwd.hpp
Reason: Changed generated file.
---  include/dogen.identification/types/entities/name_fwd.hpp
+++  include/dogen.identification/types/entities/name_fwd.hpp
@@ -2,7 +2,7 @@
  *
  * These files are code-generated via overrides to test dogen. Do not commit them.
  *
- * Generation timestamp: 2022-09-21T00:04:26
+ * Generation timestamp: not-a-date-time
  * WARNING: do not edit this file manually.
  * Generated by MASD Dogen v1.0.32
  *
/home/marco/nightly/dogen/master/projects/dogen.orchestration/tests/dogen_org_product_tests.cpp(204): error: in "dogen_product_org_tests/dogen_identification_org_produces_expected_model": check mg::check_for_differences(od, m) has failed
#+end_src

There are now two problems:

- why are we not generating a timestamp?
- if we did, we would still have a diff. We need a way to force the timestamp to
  a known value.

Links:

- [[https://github.com/MASD-Project/dogen/releases/tag/v1.0.19][v1.0.19]]: "Add support for variability overrides in Dogen"

*** COMPLETED Tests failing with filesystem errors                    :story:
    :LOGBOOK:
    CLOCK: [2022-09-24 Sat 08:35]--[2022-09-24 Sat 08:49] =>  0:14
    CLOCK: [2022-09-23 Fri 09:03]--[2022-09-23 Fri 10:13] =>  1:10
    CLOCK: [2022-09-22 Thu 19:40]--[2022-09-22 Thu 20:00] =>  0:20
    CLOCK: [2022-09-22 Thu 08:20]--[2022-09-22 Thu 08:46] =>  0:26
    :END:

The next batch of test failures is related to filesystem errors:

#+begin_example
Running 1 test case...
/home/marco/nightly/dogen/master/projects/dogen.orchestration/tests/code_generation_chain_tests.cpp(222): error: in "code_generation_chain_tests/empty_folders_are_not_deleted_when_delete_empty_folders_flag_is_off": check exists(first_empty_folders) has failed
/home/marco/nightly/dogen/master/projects/dogen.orchestration/tests/code_generation_chain_tests.cpp(223): error: in "code_generation_chain_tests/empty_folders_are_not_deleted_when_delete_empty_folders_flag_is_off": check exists(second_empty_folders) has failed
#+end_example

#+begin_example
/home/marco/nightly/dogen/master/projects/dogen.utility/src/types/test_data/dogen_product.cpp(125): Throw in function initialize
Dynamic exception type: boost::wrapexcept<dogen::utility::test_data::test_data_exception>
std::exception::what: Failed to delete output directory.
unknown location(0): fatal error: in "Test setup": std::runtime_error: Error during test
/home/marco/nightly/dogen/master/projects/dogen.orchestration/tests/main.cpp(39): last checkpoint: initializer
Running 1 test case...
#+end_example

#+begin_example
D:\a\dogen\dogen\projects\dogen.utility\src\types\test_data\dogen_product.cpp(125): Throw in function initialize
Dynamic exception type: struct boost::wrapexcept<class dogen::utility::test_data::test_data_exception>
std::exception::what: Failed to delete output directory.
unknown location(0): fatal error: in "Test setup": class std::runtime_error: Error during test
D:\a\dogen\dogen\projects\dogen.codec\tests\main.cpp(35): last checkpoint: initializer
Running 1 test case...
#+end_example

The problem is a race condition on how we are using the filesystem. The product
initialisers are recreating the top-level product directories, and this causes a
race condition between the tests generating code and the initialiser. We need to
have a way to setup / clean each test so that they do not affect each other.

We only seem to have three tests that actually write to the filesystem. So to
fix this:

- remove the recreation of directories from the product classes. Add it to
  utilities.
- add a unique prefix to each test's output directory and recreate that
  directory.
- add comments on the tests where we do not write to the filesystem to make it
  more obvious.

*** COMPLETED Remove uses of mock configuration factory               :story:
    :LOGBOOK:
    CLOCK: [2022-09-23 Fri 10:33]--[2022-09-23 Fri 11:27] =>  0:54
    :END:

We don't really need a builder and a factory. Also remove the various flags we
left scattered to handle diffing, reporting etc.

*** STARTED Gitter notifications for builds are not showing up        :story:
    :LOGBOOK:
    CLOCK: [2022-09-18 Sun 08:05]--[2022-09-18 Sun 08:15] =>  0:10
    CLOCK: [2022-09-18 Sun 07:20]--[2022-09-18 Sun 07:29] =>  0:09
    CLOCK: [2022-09-17 Sat 21:29]--[2022-09-17 Sat 21:48] =>  0:19
    :END:

We used to see travis and appveyor build notifications. We stopped seeing them
after moving to github actions. This is useful because we can see them from
Emacs in IRC.

Notes:

- it seems the settings have an option for this in webhooks. Redo the hook to
  see if it helps.

Links:

- [[https://gitlab.com/gitterHQ/webapp/-/blob/develop/docs/integrations.md][Gitter: github integrations]]
- [[https://github.com/juztcode/gitter-github-action][Gitter notify - Github action]]
- [[https://developer.gitter.im/docs/authentication][GitHub Developer - Authentication]]

*** STARTED Windows package is broken                                 :story:
    :LOGBOOK:
    CLOCK: [2022-09-20 Tue 08:21]--[2022-09-20 Tue 08:33] =>  0:12
    CLOCK: [2022-09-18 Sun 07:39]--[2022-09-18 Sun 07:47] =>  0:08
    :END:

When we install the windows package under wine, it fails with:

: E0fc:err:module:import_dll Library boost_log-vc143-mt-x64-1_78.dll (which is needed by L"C:\\Program Files\\DOGEN\\bin\\dogen.cli.exe") not found
: 00fc:err:module:import_dll Library boost_filesystem-vc143-mt-x64-1_78.dll (which is needed by L"C:\\Program Files\\DOGEN\\bin\\dogen.cli.exe") not found
: 00fc:err:module:import_dll Library boost_program_options-vc143-mt-x64-1_78.dll (which is needed by L"C:\\Program Files\\DOGEN\\bin\\dogen.cli.exe") not found
: 00fc:err:module:import_dll Library libxml2.dll (which is needed by L"C:\\Program Files\\DOGEN\\bin\\dogen.cli.exe") not found
: 00fc:err:module:import_dll Library boost_thread-vc143-mt-x64-1_78.dll (which is needed by L"C:\\Program Files\\DOGEN\\bin\\dogen.cli.exe") not found
: 00fc:err:module:LdrInitializeThunk Importing dlls for L"C:\\Program Files\\DOGEN\\bin\\dogen.cli.exe" failed, status c0000135

This will probably be fixed when we move over to the new way of specifying
dependencies in CMake. Do that first and revisit this problem.

Actually, this did not help. We then used the new VCPKG macro (see links) which
now includes all of boost. We are failing on:

: 00fc:err:module:import_dll Library MSVCP140_CODECVT_IDS.dll (which is needed by L"C:\\Program Files\\DOGEN\\bin\\boost_log-vc143-mt-x64-1_78.dll") not found
: 00fc:err:module:import_dll Library boost_log-vc143-mt-x64-1_78.dll (which is needed by L"C:\\Program Files\\DOGEN\\bin\\dogen.cli.exe") not found

Notes:

- Check if we are on latest MSVC.

Links:

- [[https://github.com/microsoft/vcpkg/issues/1653][CMake: provide option to deploy DLLs on install() like VCPKG_APPLOCAL_DEPS
  #1653]]
- [[https://gitlab.kitware.com/cmake/cmake/-/issues/22623][InstallRequiredSystemLibraries MSVCP140.dll is missing]]
- [[https://stackoverflow.com/questions/4134725/installrequiredsystemlibraries-purpose][InstallRequiredSystemLibraries purpose]]
- [[https://gitlab.kitware.com/cmake/cmake/-/issues/20228][IRSL should install MSVCP140_CODECVT_IDS.dll]]: CMake versions after 3.16 should
  install this DLL.

*** STARTED Create a mock configuration builder                       :story:
    :LOGBOOK:
    CLOCK: [2022-09-20 Tue 19:06]--[2022-09-20 Tue 19:15] =>  0:09
    CLOCK: [2022-09-19 Mon 18:19]--[2022-09-19 Mon 18:40] =>  0:21
    CLOCK: [2022-09-19 Mon 16:31]--[2022-09-19 Mon 17:50] =>  1:19
    CLOCK: [2022-09-19 Mon 11:28]--[2022-09-19 Mon 11:37] =>  0:09
    :END:

At present we are using a factory for creating mock configurations. This was
fine because we only had one or two variations, so it was easy enough to
construct the configuration in one call. However, with variability overrides we
now have several different scenarios. It would be easier to have a builder, with
sensible defaults, that returns a full configuration which is then supplied to
the model generator.

Notes:

- consider adding all variables to the result of the builder, to make the code a
  bit less repetitive.

*** STARTED Add PlantUML relationships to diagrams                    :story:
    :LOGBOOK:
    CLOCK: [2022-09-19 Mon 11:38]--[2022-09-19 Mon 11:42] =>  0:04
    :END:

We need to go through each and every model and add the relations we add in Dia
to make diagrams more readable. Models done:

- dogen

*** STARTED Add continuous builds to C++ reference product            :story:
    :LOGBOOK:
    CLOCK: [2022-09-23 Fri 16:54]--[2022-09-23 Fri 18:51] =>  1:57
    :END:

Since we list travis we lost support for CI.

*** STARTED Remove ODB support from Dogen                             :story:
    :LOGBOOK:
    CLOCK: [2022-09-23 Fri 15:49]--[2022-09-23 Fri 16:34] =>  0:45
    :END:

Last sprint we removed the relational model from Dogen. This sprint we need to g
one step further and remove ODB support. Now, we may not need to remove it
entirely: the headers Dogen generates are simple C++ headers that do not require
ODB libraries to compile, /e.g./:

#+begin_src c++
#ifdef ODB_COMPILER

#pragma db object(categories) schema("NORTHWIND")

#pragma db member(categories::category_id_) id
#pragma db member(categories::description_) null
#pragma db member(categories::picture_) null

#endif
#+end_src

We could conceivably continue to generate these, but we must not add the
associated ODB files (generated by ODB) because then we pull in the ODB C++
libraries and these are not supported by vcpkg. If we leave the pragmas we at
least know we are not making ODB support any worse. This is still useful as we
may return to it in the future. It also ensure some variation in the logical
model (in particular in the cartridges domain).

*** Add nightly builds to C++ reference product                       :story:

Since we list travis we lost support for nightlies.

*** Add continuous builds to C# reference product                     :story:

Since we list travis we lost support for CI.

*** Add nightly builds to C# reference product                        :story:

Since we list travis we lost support for nightlies.

*** Consider adding PlantUML verbatim inside element                  :story:

One simple way of adding operations is to extend verbatim to support inside
class. This can easily be achieved via =.before=, =.inside= and =.after= fields.
The =.inside= can be replaced by operations later.

*** Ignore vcpkg path length warning                                  :story:

#+begin_example
Building boost-system[core]:x64-windows...
CMake Warning at scripts/cmake/vcpkg_buildpath_length_warning.cmake:4 (message):
  boost-system's buildsystem uses very long paths and may fail on your
  system.

  We recommend moving vcpkg to a short path such as 'C:\src\vcpkg' or using
  the subst command.
Call Stack (most recent call first):
  ports/boost-system/portfile.cmake:3 (vcpkg_buildpath_length_warning)
  scripts/ports.cmake:147 (include)
#+end_example

Clues about path length:

#+begin_example
-- Downloading https://github.com/boostorg/system/archive/boost-1.80.0.tar.gz -> boostorg-system-boost-1.80.0.tar.gz...
-- Extracting source D:/a/dogen/dogen/vcpkg/downloads/boostorg-system-boost-1.80.0.tar.gz
#+end_example

Links:

- [[https://github.com/microsoft/vcpkg/issues/11119][[vcpkg_buildpath_length_warning] Please add advice to enable long paths on
  Windows 10 #11119]]
- [[https://learn.microsoft.com/en-gb/windows/win32/fileio/maximum-file-path-limitation?tabs=registry][Maximum Path Length Limitation]]

*** Cannot access binaries from release notes                         :story:

At present the URLs for the binaries are 404ing. We need to upload binaries
manually to the release.

- [[https://github.com/MASD-Project/dogen/releases/download/v1.0.31/DOGEN-1.0.31-Darwin-x86_64.dmg][DOGEN-1.0.31-Darwin-x86_64.dmg]]
- [[https://github.com/MASD-Project/dogen/releases/download/v1.0.31/DOGEN-1.0.31-Windows-AMD64.msi][DOGEN-1.0.31-Windows-AMD64.msi]]
- [[https://github.com/MASD-Project/dogen/releases/download/v1.0.31/dogen_1.0.31_amd64-applications.deb][dogen_1.0.31_amd64-applications.deb]]

Release notes have been updated:

- https://github.com/MASD-Project/dogen/releases/tag/v1.0.31

*** Enable CodeQL                                                     :story:

GitHub seems to have new security tooling.

Links:

- [[https://github.com/MASD-Project/dogen/security/code-scanning][code-scanning]]

*** Add operations to PlantUML diagrams                               :story:

At present its not possible to add operations to PlantUML diagrams. This means
the diagrams are not as useful as the Dia representation. We could add basic
support for operations and then dump these in PlantUML.

*** CI error: Failed to delete output directory                       :story:

We are experiencing a strange CI error:

#+begin_example
D:\a\dogen\dogen\projects\dogen.utility\src\types\test_data\dogen_product.cpp(125): Throw in function initialize
Dynamic exception type: struct boost::wrapexcept<class dogen::utility::test_data::test_data_exception>
std::exception::what: Failed to delete output directory.
unknown location(0): fatal error: in "Test setup": class std::runtime_error: Error during test
D:\a\dogen\dogen\projects\dogen.orchestration\tests\main.cpp(39): last checkpoint: initializer
Running 1 test case...

 *** No errors detected
Test setup error:
#+end_example

We also have this related error:

#+begin_example
Running 1 test case...
/home/runner/work/dogen/dogen/projects/dogen.orchestration/tests/code_generation_chain_tests.cpp(169): fatal error: in "code_generation_chain_tests/empty_folders_are_deleted_when_delete_empty_folders_flag_is_on": critical check are_generated_files_healthy(od, t, 60 ) has failed

 *** 1 failure is detected in the test module "dogen.orchestration.tests"
#+end_example

*** PlantUML Verbatim considered harmful                              :story:

Last sprint we added the PlantUML verbatim property, /i.e./:

:   :masd.codec.plantuml: model o-- element : composed of
:   :masd.codec.plantuml: Element <|.. model

This was meant to allow us to add the missing relations in the PlantUML
diagrams. However, there are issues with this approach:

- we may enter invalid PlantUML syntax, and will only find out at diagram
  generation time. The error will probably be very hard to figure out as well.
- we need to know the exact element name. Given the "spaces for underscores"
  approach, this is not very nice (/e.g./ we replace "a model type" with
  "a_model_type").
- if you rename a type, this will fail.

Seems like a better approach is to name the relations and add them as codec
attributes:

:   :masd.codec.annotation.abstraction: 294DC761-8784-3D74-824B-48E7BCC2CFB2, description
:   :masd.codec.annotation.aggregation: 294DC761-8784-3D74-824B-48E7BCC2CFB2, another description
:   :masd.codec.annotation.association: 294DC761-8784-3D74-824B-48E7BCC2CFB2, yet another description

These relations then give rise to a mapping to the element name during
resolution. This copes with renames.

Links:

- [[https://www.ibm.com/docs/en/rational-soft-arch/9.5?topic=diagrams-relationships-in-class][UML: Relationships in class diagrams]]

*** Consider renaming plantuml property                               :story:

In the previous sprint we introduced =masd.codec.plantuml=. this name is
questionable, given that the codec name is =plantum=. Consider renaming it.
Suggestions:

: masd.codec.plantuml.verbatim

*** Add full and relative path processing to PM                       :story:

We need to be able to generate full paths in the PM. This will require access to
the file extensions. For this we will need new decoration elements. This must be
done as part of the logical model to physical model conversion. While we're at
it, we should also generate the relative paths. Once we have relative paths we
should compute the header guards from them. These could be generalised to
"unique identifiers" or some such general name perhaps. That should be a
separate transform.

Notes:

- we are not yet populating the archetype kind in archetypes so we cannot locate
  the extensions. Also we did not create all of the required archetype kinds in
  the text models. The populating should be done via profiles.
- we must first figure out the number of enabled backends. The meta-model
  properties will always contain all backends, but not all of them are enabled.
- we need to populate the part directories. For this we need to know what parts
  are available for each backend (PMM), and then ensure the part properties have
  been created. We also need a directory for the part in variability. It is not
  clear we have support for this in the template instantiation domains - we
  probably only have backend, facet, archetype.
- guiding principle: there should be a direct mapping between the two
  hierarchical spaces: the definition meta-model of the physical space and its
  instances in the file-system.

Merged stories:

*Map archetypes to labels*

We need to add support in the PMM for mapping archetypes to labels. We may need
to treat certain labels more specially than others - its not clear. We need a
container with:

- logical model element ID
- archetype ID
- labels

*Implement locator in physical model*

Use PMM entities to generate artefact paths, within =m2t=.

*Create a archetypes locator*

We need to move all functionality which is not kernel specific into yarn for the
locator. This will exist in the helpers namespace. We then need to implement the
C++ locator as a composite of yarn locator.

*Other Notes*

At present we have multiple calls in locator, which are a bit ad-hoc. We could
potentially create a pattern. Say for C++, we have the following parameters:

- relative or full path
- include or implementation: this is simultaneously used to determine the
  placement (below) and the extension.
- meta-model element:
- "placement": top-level project directory, source directory or "natural"
  location inside of facet.
- archetype location: used to determine the facet and archetype postfixes.

E.g.:

: make_full_path_for_enumeration_implementation

Interestingly, the "placement" is a function of the archetype location (a given
artefact has a fixed placement). So a naive approach to this seems to imply one
could create a data driven locator, that works for all languages if supplied
suitable configuration data. To generalise:

- project directory is common to all languages.
- source or include directories become "project sub-directories". There is a
  mapping between the artefact location and a project sub-directory.
- there is a mapping between the artefact location and the facet and artefact
  postfixes.
- extensions are a slight complication: a) we want to allow users to override
  header/implementation extensions, but to do it so for the entire project
  (except maybe for ODB files). However, what yarn's locator needs is a mapping
  of artefact location to extension. It would be a tad cumbersome to have to
  specify extensions one artefact location at a time. So someone has to read a
  kernel level configuration parameter with the artefact extensions and expand
  it to the required mappings. Whilst dealing with this we also have the issue
  of elements which have extension in their names such as visual studio projects
  and solutions. The correct solution is to implement these using element
  extensions, and to remove the extension from the element name.
- each kernel can supply its configuration to yarn's locator via the kernel
  interface. This is fairly static so it can be supplied early on during
  initialisation.
- there is still something not quite right. We are performing a mapping between
  some logical space (the modeling space) and the physical space (paths in the
  filesystem). Some modeling elements such as the various CMakeLists.txt do not
  have enough information at the logical level to tell us about their location;
  at present the formatter itself gives us this hint ("include cmakelists" or
  "source cmakelists"?). It would be annoying to have to split these into
  multiple archetypes just so we can have a function between the archetype
  location and the physical space. Although, if this is the only case of a
  modeling element not mapping uniquely, perhaps we should do exactly this.
- However, we still have inclusion paths to worry about. As we done with the
  source/include directories, we need to somehow create a concept of inclusion
  path which is not language specific; "relative path" and "requires relative
  path" perhaps? These could be a function of archetype location.

Merged stories:

*Generate file paths as a transform*

We need to understand how file paths are being generated at present; they should
be a transform inside generation.

*Create the notion of project destinations*

At present we have conflated the notion of a facet, which is a logical concept,
with the notion of the folders in which files are placed - a physical concept.
We started thinking about addressing this problem by adding the "intra-backend
segment properties", but as the name indicates, we were not thinking about this
the right way. In truth, what we really need is to map facets (better: archetype
locations) to "destinations".

For example, we could define a few project destinations:

: masd.generation.destination.name="types_headers"
: masd.generation.destination.folder="include/masd.cpp_ref_impl.northwind/types"
: masd.generation.destination.name=top_level (global?)
: masd.generation.destination.folder=""
: masd.generation.destination.name="types_src"
: masd.generation.destination.folder="src/types"
: masd.generation.destination.name="tests"
: masd.generation.destination.folder="tests"

And so on. Then we can associate each formatter with a destination:

: masd.generation.cpp.types.class_header.destination=types_headers

Notes:

- these should be in archetypes models.
- with this we can now map any formatter to any folder, particularly if this is
  done at the element level. That is, you can easily define a global mapping for
  all formatters, and then override it locally. This solves the long standing
  problem of creating say types in tests and so forth. With this approach you
  can create anything anywhere.
- we need to have some tests that ensure we don't end up with multiple files
  with the same name at the same destination. This is a particular problem for
  CMake. One alternative is to allow the merging of CMake files, but we don't
  yet have a use case for this. The solution would be to have a "merged file
  flag" and then disable all other facets.
- this will work very nicely with profiles: we can create a few out of the box
  profiles for users such as flat project, common facets and so on. Users can
  simply apply the stereotype to their models. These are akin to "destination
  themes". However, we will also need some kind of "variable replacement" so we
  can support cases like =include/masd.cpp_ref_impl.northwind/types=. In fact,
  we also have the same problem when it comes to modules. A proper path is
  something like:
  - =include/${model_modules_as_dots}/types/${internal_modules_as_folders}=
  - =include/${model_modules_as_dots}/types/${internal_modules_as_dots}.=
  - =include/${model_modules_as_dots}/types/${internal_modules_as_underscores}_=

  This is *extremely* flexible. The user can now create a folder structure that
  depends on package names etc or choose to flatten it and can do so for one or
  all facets. This means for example that we could use nested folders for
  =include=, not use model modules for =src= and then flatten it all for
  =tests=.
- actually it is a bit of a mistake to think of these destinations as purely
  physical. In reality, we may also need them to contribute to namespaces. For
  example, in java the folders and namespaces must match. We could solve this by
  having a "module contribution" in the destination. These would then be used to
  construct the namespace for a given facet. Look for java story on backlog for
  this.
- this also addresses the issue of having multiple serialisation formats and
  choosing one, but having sensible folder names. For example, we could have
  boost serialisation mapped to a destination called =serialisation=. Or we
  could map it to say RapidJSON serialisation. Or we could support two methods
  of serialisation for the same project. The user chooses where to place them.

*** Update github actions to build from tags                          :story:

At present it seems we only build from master. We need to build from tags for
releases.

*** Assorted improvements to CMake files                               :epic:

#+begin_src cmake
include(CheckIPOSupported)
check_ipo_supported(RESULT result)
if(result)
  set_target_properties(foo PROPERTIES INTERPROCEDURAL_OPTIMIZATION TRUE)
endif()

LINK_WHAT_YOU_USE
set(CMAKE_CXX_CLANG_TIDY "clang-tidy" "-checks=*")
<LANG>_CLANG_TIDY: CMake 3.6+
<LANG>_CPPCHECK
<LANG>_CPPLINT
<LANG>_INCLUDE_WHAT_YOU_USE

install(TARGETS MyLib
        EXPORT MyLibTargets
        LIBRARY DESTINATION lib
        ARCHIVE DESTINATION lib
        RUNTIME DESTINATION bin
        INCLUDES DESTINATION include
        )
#+end_src

*Previous understanding*

It seems we are not using proper CMake idioms to pick up compiler features, as
explained here:

- [[http://unclejimbo.github.io/2018/06/08/Modern-CMake-for-Library-Developers/][Modern CMake for Library Developers]]
- [[https://cliutils.gitlab.io/modern-cmake/][An Introduction to Modern CMake]]
- [[http://www.slideshare.net/DanielPfeifer1/cmake-48475415][CMake - Introduction and best practices]]
- [[https://datascience.dsscale.org/wp-content/uploads/2016/06/151208-LANL-Hoffman-Science.pdf][Building Science with CMake]]
- [[https://github.com/crezefire/cxp][CXP: C++ Cross Platform]]: A template project for creating a cross
  platform C++ CMake project using modern CMake syntax and transitive
  dependencies.
- [[https://cgold.readthedocs.io/en/latest/][CGold: The Hitchhiker’s Guide to the CMake]]
- [[https://polly.readthedocs.io/en/latest/index.html][Polly: Collection of CMake toolchains]]
- [[https://github.com/sblumentritt/cmake_modules][GH cmake_modules]]: "This repository provides a wide range of CMake
  helper files."

We need to implement this using proper CMake idioms.

Notes:

- Add version and language to project.
- start using [[https://cmake.org/cmake/help/v3.3/command/target_compile_options.html][target compile options]] for each target. We will have to repeat the
  same flags; this could be avoided by passing in a variable. See also [[http://stackoverflow.com/questions/23995019/what-is-the-modern-method-for-setting-general-compile-flags-in-cmake][What is
  the modern method for setting general compile flags in CMake?]]
- define qualified aliases for all libraries, including nested aliasing for
  =dogen::test_models=. Ensure all linking is done against qualified names.
- use target include directories for each target and only add the required
  include directories to each target. Mark them with the appropriate visibility,
  including using =interface=. We should then remove all duplication of
  libraries in the specs.
- try replacing calls to =-std=c++-14= with compiler feature detection. We need
  to create a list of all C++-14 features we're using.
- remove all of the debug/release compilation options and start using
  =CMAKE_BUILD_TYPE= instead. See [[http://pastebin.com/jCDW5Aa9][this]] example. We added build type support to
  our builds, but as a result, the binaries moved from =stage/bin= to =bin=.
  There is no obvious explanation for this.
- remove =STATIC= on all libraries and let users specify which linkage to use.
  We already have a story to capture this work.
- remove the stage folder and use the traditional CMake directories. This will
  also fix the problems we have with BUILD_TYPE.
- consider buying the CMake book: https://crascit.com/professional-cmake/.

Merged stories:

*Usage of external module path in cmakelists*                       :story:

It seems like we are not populating the target names
properly. Originally the target name for test model all built-ins was:

: dogen_all_builtins

When we moved the test models into =test_models= the target name did
not change. It should have changed to:

: dogen_test_models_all_builtins

*** Capitalise titles in models correctly                             :story:

We still have models with lower case titles:

: * initializer                                                       :element:

Capitalise these correctly.

When we tried to do this to the dogen model, generation failed with the
following error:

: Error: Object has attribute with undefined type: spec_category

We are probably not normalising to lower case.

In addition

Merged stories:

*Capitalise model headers correctly*

At present most models still use the "all lower case" notation, copied from Dia.
We need to capitalise headers correctly so that when we generate documentation
they come out correctly.

*** Consider creating a small paper summarising MASD                  :story:

At present we have the thesis, that explains the entire methodology and its
rationale in great detail. This is not suitable for new users. We should have a
small paper, 3 or 4 pages long, that summarises the argument.

*** Add support for relations in codec model                          :story:
    :PROPERTIES:
    :CUSTOM_ID: 1ECCD69A-EE17-BAE4-7FE3-DA5F2E6E01FB
    :END:

One very simple way to improve diagrams is to allow users to associate a
fragment of PlantUML code with a class, for example:

: masd.codec.plantuml: myclass <>-- other_class : test

This fragments are added after the class, verbatim. Its up to the users to
annotate diagrams as they see fit, we merely copy and paste these annotations.

In the future, we may spot patterns of usage that can be derived from meta-data,
but for now we just need the diagrams to be usable like they were in Dia.

Notes:

- notes are not indented at present.
- we are not leaving a space after inheritance.
- empty classes still have brackets.
- no top-level namespace for model. We didn't have this in Dia either.

 Tasks:

- add new feature in codec model.
- add properties in model and element to store the data.
- when converting into PlantUML, output the new properties after dumping the
  class.
- move codec to codec tests from orchestration to codec component.
- codec needs to have a way to bootstrap its context without requiring
  orchestration.

*** Consider standardising all templates as mustache templates        :story:

At present we have a somewhat complex story with regards to templating:

1. we use a mustache-like approach called wale, built in-house. It is used for
   some header files such as the M2T transforms.
2. we use a t4-like approach called stitch, also in-house. It is used for the
   implementation of the M2T transforms.

What would be really nice is if we could use the same approach for both, and if
that approach was not part of Dogen. The purpose of this story is to explore the
possibility of replacing both with a standard implementation of mustache,
ideally available on vcpkg. We already have a story for replacing wale with
mustache in the backlog, so see that for the choice of implementation. This
story concerns itself mainly with the second item in the above list; that is,
can we replace stitch with mustache.

In order to answer this question we first must try to figure out what the
differences between T4 and mustache are. T4 is a "generator generator". That is,
the text template generates C# code that generates the ultimate target of the
template. This means it is possible to embed any logic within the T4 template as
required, to do complex processing. It also means the processing is "fast"
because we generate C# code rather than try to introspect at run time. Stitch
uses the same approach. However, after many years of using both T4 and Stitch,
the general conclusion has been that the templates should be kept as simple as
possible. The main reason is that "debugging" through the templates is
non-trivial, even though it is simple C++ code (in the case of stitch).

Mustache on the other hand puts forward an approach of logic-less templates.
That is, the templates are evaluated dynamically by the templating engine, and
the engine only allows for a very limited number of constructs. In some
implementations, the so called "template hash", that is the input to the
template, is a JSON object. All the template can do is refer to entries in the
JSON object and replace tokens with the values of those entries.

Until recently we deemed mustache to be too simple for our needs because Dogen
templates were very complex. However, several things have changed:

- we do not want the templates to have any indentation at all; this should be
  left to clang-format as a subsequent T2T transform. This removes a lot of
  functionality we had in Stitch.
- we do not want the logical model objects to be processed any further in the
  template. As explained above this leads to a lot of complications. We want the
  object to be in its final form.
- we want all relationships etc to be encoded in the logical model object prior
  to M2T transformation.

In other words, we have slowly been converging towards logic-less templates,
though we are not yet there. The main stumbling blocks are:

- epilogue and prologue are at present handled by assistants:

#+begin_src
    text::formatters::assistant ast(lps, e, a, true/*requires_header_guard*/);
    const auto& o(ast.as<logical::entities::structural::object>(e));

    {
        auto sbf(ast.make_scoped_boilerplate_formatter(o));
        {
            const auto ns(ast.make_namespaces(o.name()));
            auto snf(ast.make_scoped_namespace_formatter(ns));
#>

class <#= o.name().simple() #>;

<#+
        } // snf
#>

<#+
    } // sbf

#+end_src

   Ideally we should just have a way to ask for the values of these fields.
- we need to investigate all templates and see if a JSON representation of a
  logical model element is sufficient to capture all required information.
  However the best way to do this is to have an incremental approach: provide a
  mustache based M2T and then incrementally move each M2T at a time.

If we do move to mustache, there are lots of advantages:

- remove all of templating code.
- we could allow users to supply their own mustache templates in a model. We can
  even allow for the dynamic creation of PMM elements and then the association
  of those elements with templates. End users cannot of course extend the LMM,
  but even just extending the LMM gives them a lot of power.
- we could create a stand alone tool that allows users to play with templates.
  All they need is a dump of the JSON representation of the objects in their
  model (this could be an option in Dogen). Then the tool can take the template
  and the JSON and render it to =std::out=. This makes template development much
  easier. If we integrate it with Emacs, we could even have a view where we
  do: 1) JSON 2) template 3) output. Users can then change 1) and 2) and see the
  results in 3). We don't even have to extend emacs for this, we could just use
  the compilation command.

Notes:

- if we could create JSON schemas for the LMM, we could then allow users to
  create their own JSON representations. Not sure how useful this would be.
- we need JSON support in Dogen for this.
- we need to measure how much slower Dogen would be with this approach.
  Presumably mustache is a lot slower that Stitch.
- from this perspective, the PMM is fixed but the PM then becomes a dynamic
  entity. We can supply a PM model with Dogen but that is just Dogen's
  interpretation of the physical space; users could supply their own PM's as
  required. The PMs need to bind to the PMM: either the user supplies its own
  TS, part etc or it must bind (via meta-data) to existing parts, TS etc. We
  also need to support two styles of declaring PM entities: inline (e.g. nested)
  or outline (e.g. we want to bind a given facet, part etc to an already
  existing TS, etc).
- we could hash both the mustache template and the JSON object used as input,
  and save those two hashes in the generated file. If the hashes match, don't
  bother regenerating.

Links:

- [[https://en.wikipedia.org/wiki/Text_Template_Transformation_Toolkit][wikipedia: Text Template Transformation Toolkit]]

Merged stories:

*Implement wale in terms of existing template libraries*

Originally we implemented wale as a quick hack, but we stated:

#+begin_quote
A second point is the use of [[https://github.com/jamboree/bustache][bustache]] vs rolling our own trivial mustache-like
implementation:

- if we use bustache we can, in the future, start to make use of
  complex mustache templates. We don't have a use case for this now,
  but there is no reason to preclude it either.
- however, with bustache as a third-party dependency we now have to
  worry about generating OSX and windows binaries for the
  library. Until we do, the builds will break.

For now, to make life easier we will roll our own. As soon as we have
a stable windows environment we will move to bustache.
#+end_quote

We should really move to one of these mustache implementations. Inja
seems to be the most sensible one, even though it depends on a JSON
library. We will need JSON internally anyway, so it may be the time to
add a dependency. We should also have a way to associate an arbitrary
JSON document with a formatter so that users can create their own
templates with their own parameters and the model is merely used for
pass-through.

We should also start to create a standard set of variables that dogen
exports into inja such as object name, namespaces, etc. These are
"system variables" and do not require any action from the user. In
fact, if we use the JSON based approach, we could define a JSON schema
for meta-model elements which is MASD specific. These are used by the
templates.

Note that stitch only makes sense when we are creating a code
generator (at least given the use cases we have so far) whereas inja
makes sense even for regular models and can be applied to items in any
technical space.

Links:

- [[https://github.com/cierelabs/boostache/tree/develop][boostache]]
- [[https://github.com/no1msd/mstch][mstch]]
- [[https://github.com/mrtazz/plustache][plustache]] (in vcpkg)
- [[https://github.com/melpon/ginger][ginger]]
- [[https://github.com/qicosmos/render][render]]
- [[https://github.com/pantor/inja][inja]]: in vcpkg, needs JSON library. [[https://github.com/paradoxxxzero/jinja2-mode][Emacs mode]]. "Inja is a template engine for
  modern C++, loosely inspired by jinja for python. It has an easy and yet
  powerful template syntax with all variables, loops, conditions, includes,
  callbacks, and comments you need, nested and combined as you like. Inja uses
  the wonderful json library by nlohmann for data input."
- [[https://github.com/jrziviani/amps][amps]]
- [[https://github.com/OlafvdSpek/ctemplate][ctemplate]]: This library provides an easy to use and lightning fast
  text templating system to use with C++ programs. It was originally
  called Google Templates, due to its origin as the template system
  used for Google search result pages.
- [[https://github.com/moneymanagerex/ctpp][ctpp GH]]: See also [[http://ctpp.havoc.ru/en/][homepage]]. Seems a bit unmaintained but may have
  some good ideas. See [[http://ctpp.havoc.ru/en/whatis.html][What is CTPP?]]
- [[https://github.com/blockspacer/CXXCTP][CXXCTP GH]]: "Add custom features to C++ language, like metaclasses,
  Rust-like traits, reflection and many more. A fully open source,
  powerful solution for modification and generation of C++ source
  code. Reduce the amount of boilerplate code in your C++ projects."
- [[https://github.com/flexferrum/autoprogrammer][autoprogrammer GH]]: "Welcome to Autoprogrammer, the C++ code
  generation tool! This tool helps you dramatically reduce the amount
  of boilerplate code in your C++ projects. Based on clang frontend,
  the 'autoprogrammer' parses your C++ source files and generates new
  set C++ sources. For instance, it generates enum-to-string
  converting functions for you. Instead of you."
- [[https://github.com/TheLongRunSmoke/utility-boilerplate-qt][utility-boilerplate-qt GH]]: "Template for creating simple
  cross-platform application with GUI based on Qt."

*Consider renaming =wale= to =mustache=*

We need to rename all of the wale templates to mustache.

*Consider renaming =wale= to =tangle=*

Wale and stitch are remnant from the sewing days. Whilst stitch is
still vaguely appropriate, we can't even remember what wale stands
for. We should use a more domain-specific term such as weave or
tangle. In fact, we probably should rename =stitch= to =weave= given
it weaves text with code, and find a better name for wale. Its not
"tangling" (given tangling, as we understand it from org-mode, is just
another name for weaving). We need to look into logic-less templates
terminology.

Actually this is a mistake. Wale is just a poor-person's mustache and
will be replaced by a proper implementation of mustache as soon as we
can. We should instead start calling it mustache and explain this is
just a temporary fix.

*Consider renaming logic-less templates*

Originally we though this was a good name because it was used by some
domain experts, but it seems it generates more confusion than
anything. It may just be a term used by mustache and other niche
template groups. We should probably rename it to text templates given
most domain experts know what that means.

In addition, the templates should be specific to their types; we need
to know if its a mustache template or a stitch template because the
processing will be very different. The templates should be named after
their type in the logical model. Rename these to wale templates.

Actually its not yet clear if the existing logic could not be extended
to other template types. We should wait until we implement it front to
back and then make a decision.

The most obvious thing is just to call the templates after their
actual name: mustache.

** Deprecated
