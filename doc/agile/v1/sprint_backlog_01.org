#+title: Sprint Backlog 01
#+options: date:nil toc:nil author:nil num:nil
#+todo: STARTED | COMPLETED CANCELLED POSTPONED
#+tags: { story(s) epic(e) }

* Mission Statement

- Start work on the theoretical side of Dogen.
- Start moving common kernel infrastructure into yarn.

* Stories

** Active

#+begin: clocktable :maxlevel 3 :scope subtree :indent nil :emphasize nil :scope file :narrow 75 :formula %
#+CAPTION: Clock summary at [2017-07-01 Sat 22:17]
| <75>                                                                        |         |       |       |       |
| Headline                                                                    | Time    |       |       |     % |
|-----------------------------------------------------------------------------+---------+-------+-------+-------|
| *Total time*                                                                | *48:20* |       |       | 100.0 |
|-----------------------------------------------------------------------------+---------+-------+-------+-------|
| Stories                                                                     | 48:20   |       |       | 100.0 |
| Active                                                                      |         | 48:20 |       | 100.0 |
| STARTED Sprint and product backlog grooming                                 |         |       |  7:02 |  14.6 |
| COMPLETED Edit release notes for previous sprint                            |         |       |  0:49 |   1.7 |
| COMPLETED Create a simple Emacs mode for stitch                             |         |       |  4:25 |   9.1 |
| COMPLETED WIX Path has changed on appveyor                                  |         |       |  0:09 |   0.3 |
| COMPLETED Move decoration into yarn                                         |         |       |  8:38 |  17.9 |
| COMPLETED Fix broken builds due to disk space                               |         |       |  1:32 |   3.2 |
| COMPLETED Remove =is_target= from frontends                                 |         |       |  1:14 |   2.6 |
| COMPLETED Analysis: major yarn clean-up                                     |         |       |  9:04 |  18.8 |
| STARTED Add support for proper JSON serialisation in C++                    |         |       |  2:18 |   4.8 |
| STARTED Start documenting the theoretical aspects of Dogen                  |         |       | 10:49 |  22.4 |
| STARTED Move element segmentation into yarn                                 |         |       |  1:32 |   3.2 |
| STARTED Implement the context class                                         |         |       |  0:48 |   1.7 |
#+TBLFM: $5='(org-clock-time% @3$2 $2..$4);%.1f
#+end:

*** STARTED Sprint and product backlog grooming                       :story:
    CLOCK: [2017-07-01 Sat 17:00]--[2017-07-01 Sat 17:20] =>  0:20
    CLOCK: [2017-05-26 Fri 15:32]--[2017-05-26 Fri 15:38] =>  0:06
    CLOCK: [2017-05-26 Fri 14:02]--[2017-05-26 Fri 15:21] =>  1:19
    CLOCK: [2017-04-14 Fri 11:31]--[2017-04-14 Fri 13:05] =>  1:34
    CLOCK: [2017-04-13 Thu 06:29]--[2017-04-13 Thu 07:21] =>  0:52
    CLOCK: [2017-04-04 Tue 22:26]--[2017-04-04 Tue 23:33] =>  1:07
    CLOCK: [2017-04-06 Thu 20:12]--[2017-04-06 Thu 20:57] =>  0:45
    CLOCK: [2017-04-04 Tue 18:35]--[2017-04-04 Tue 19:26] =>  0:51
    CLOCK: [2017-04-03 Mon 10:21]--[2017-04-03 Mon 10:29] =>  0:08

Updates to sprint and product backlog.

*** COMPLETED Edit release notes for previous sprint                  :story:
    CLOSED: [2017-04-03 Mon 11:07]
    CLOCK: [2017-04-04 Tue 22:12]--[2017-04-04 Tue 22:25] =>  0:13
    CLOCK: [2017-04-03 Mon 10:48]--[2017-04-03 Mon 11:07] =>  0:19
    CLOCK: [2017-04-03 Mon 10:30]--[2017-04-03 Mon 10:47] =>  0:17

Add github release notes for previous sprint.

Title: Dogen v1.0.0, "Dunes"

#+begin_src markdown
![Dunas](https://travelgest.co.ao/wp-content/uploads/2016/09/Dunas-Ba%C3%ADa-dos-Tigres-Namibe-1.jpg)
_Dunes from the Namib Desert, by Baia dos Tigres. (C) 2016, Travelgest Angola._

Overview
=======
This was yet another sprint with a focus on ODB/ORM improvements. As part of this work, we have finally completed our series of blog posts on Dogen and ORM:

- [Nerd Food: Northwind, or Using Dogen with ODB - Part IV](http://mcraveiro.blogspot.co.uk/2017/03/nerd-food-northwind-or-using-dogen-with_25.html)

Also, you won't fail to notice we labelled this release _v1.0_. In truth, we continue with our approach of slow and incremental releases, and as such this release is no different from any other. The main reason we have decided to call it v1.0 is because the sprint numbers were becoming a bit too unwieldy - adding an extra zero the 100th sprint just seemed a tad much. And when we looked at our [Definition of Done for v1.0](https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/v0/definition_of_done.org), we noticed that we are ticking pretty much all the boxes we had originally defined, so its not entirely unfair to call it v1.0.

User visible changes
===============
In this sprint, a number of user visible changes were made, but all mainly bug-fixes:

- **Fixes for split directory mode**: Files in the header directory were being ignored by housekeeping.
- **Concept improvements**: You can now place concepts inside of namespaces.
- **Use distinct ODB extension**: We are now using ```cxx``` as the extension for ODB files, allowing one to distinguish between ODB and Dogen files quite easily.
- **Changes to ORM stereotypes**: We no longer use underscores in stereotypes. This is a breaking change. You need to replace ```orm_object```, ```orm_value``` and so forth with ```orm object```, ```orm value``` etc.
- **ODB now has MSBuild targets**: For Windows users, you can now create a very simple wrapper script to call ```msbuild``` and execute ODB.

For more details of the work carried out this sprint, see the [sprint log](https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/v1/sprint_backlog_00.org).

Next Sprint
===========
In the next sprint we'll mop up more ODB issues and continue improving our Visual Studio support.

Binaries
======
You can download experimental binaries from [Bintray](https://bintray.com/domaindrivenconsulting/Dogen) for OSX, Linux and Windows (all 64-bit):

- [dogen_1.0.0_amd64-applications.deb](https://dl.bintray.com/domaindrivenconsulting/Dogen/1.0.0/dogen_1.0.0_amd64-applications.deb)
- [dogen-1.0.0-Darwin-x86_64.dmg](https://dl.bintray.com/domaindrivenconsulting/Dogen/1.0.0/dogen-1.0.0-Darwin-x86_64.dmg)
- [dogen-1.0.0-Windows-AMD64.msi](https://dl.bintray.com/domaindrivenconsulting/Dogen/dogen-1.0.0-Windows-AMD64.msi)

**Note**: They are produced by CI so they may not yet be ready.

For all other architectures and/or operative systems, you will need to build Dogen from source. Source downloads are available below.
#+end_src

- [[https://twitter.com/MarcoCraveiro/status/849371311789019138][Tweet]]
- [[https://www.linkedin.com/hp/update/6255137468270542848/][LinkedIn]]

*** COMPLETED Replace the database model with the northwind model     :story:
    CLOSED: [2017-04-04 Tue 18:53]

*Rationale*: we more or less completed this. We probably need more
tests, but its sufficient for now.

As part of the [[https://github.com/DomainDrivenConsulting/zango][zango]] project we are creating a model that exercises
Dogen and ODB. It is largely based on the database model, minus the
basic types we had added a while ago. We should just drop the database
model and adopt the northwind model from zango.

*** CANCELLED Windows package has element mappings                    :story:
    CLOSED: [2017-04-06 Thu 20:26]

*Rationale*: seems like a random installation problem.

For some reason even after renaming the mappings file it is still on
windows. This could also be a bug of the installer; after a uninstall
and reinstall the problem went away. Double check with a clean
install.

*** CANCELLED Comments in C# appear to be the attribute name          :story:
    CLOSED: [2017-04-06 Thu 20:28]

*Rationale*: checked Zeta model and CSharp model, both look fine.

It seems we are copying across the attribute name rather than a
comment. This could also be a problem with the input. Check the Zeta
model.

*** COMPLETED Create a simple Emacs mode for stitch                   :story:
    CLOSED: [2017-05-12 Fri 14:31]
    CLOCK: [2017-04-26 Wed 21:51]--[2017-04-26 Wed 22:31] =>  0:40
    CLOCK: [2017-04-26 Wed 18:05]--[2017-04-26 Wed 21:50] =>  3:45

Create a really simple emacs mode that just has different visual
representations for the stitch code and the template itself.

Links:

- [[https://github.com/vspinu/polymode/issues/133][Request for a review/comments on a new mode derived from polymode]]

Merged stories:

*Try creating a mode with generic mode*

Tried with generic mode:

 #+begin_src emacs-lisp
(require 'generic-x) ;; we need this

(define-generic-mode 'stitch-mode
  () ;; comments not supported
  '("licence_name" "copyright_notice" "modeline_group_name"
    "stream_variable_name" "inclusion_dependency"
    "containing_namespaces") ;; keywords
  '(("<#@" "<#+" "<#=" "#>" . 'font-lock-operator)) ;; operator
  '("\\.stitch$") ;; extension
  nil
  "Major mode for editing Dogen's Stitch template files."
  )

;;; stitch-mode.el ends here
#+end_src

*Consider creating an Emacs mode for stitch*

It would be nice to have syntax highlighting for stitch templates. We
have a [[https://github.com/mcraveiro/cunene/blob/master/lisp/other/utils/t4-mode.el][mumamo-based version]] in cunene - originally done for t4 - but
which is rather unusable.

See also [[https://github.com/fxbois/web-mode][web-mode]].

*Investigate adding polymode support for stitch templates*

We need a way to visualise stitch templates that is a bit more
readable than fundamental mode. One option is [[https://github.com/vspinu/polymode/tree/master/modes][polymode]].

*** COMPLETED WIX Path has changed on appveyor                        :story:
    CLOSED: [2017-06-03 Sat 16:08]
    CLOCK: [2017-05-26 Fri 15:22]--[2017-05-26 Fri 15:31] =>  0:09

At present we have hard-coded the path to WIX:

#+begin_example
  - ps: if ($build_type -eq "Release") {
            cd $project_dir\build\output\$env:compiler\$build_type;
            $env:Path += ";C:\Program Files (x86)\WiX Toolset v3.10\bin";
            $env:WIX = "C:\Program Files (x86)\WiX Toolset v3.10\bin";
            cpack -G WIX -C Release;
        }
#+end_example

This means that every time WIX has a minor upgrade, our scripts break:

#+begin_example
CPack: Create package
cpack : CMake Error at C:/Program Files (x86)/CMake/share/cmake-3.4/Modules/CPackWIX.cmake:261 (message):
At line:1 char:211
+ ... rogram Files (x86)\WiX Toolset v3.10\bin"; cpack -G WIX -C Release; }
+                                                ~~~~~~~~~~~~~~~~~~~~~~~
    + CategoryInfo          : NotSpecified: (CMake Error at ...:261 (message)::String) [], RemoteException
    + FullyQualifiedErrorId : NativeCommandError

  Could not find the WiX candle executable.
CPack Error: Error while executing CPackWIX.cmake
#+end_example

The right way to do this is to use the WIX environment variable:

- [[https://github.com/appveyor/ci/issues/1267][Add WiX toolset to PATH]]

*** COMPLETED Move decoration into yarn                               :story:
    CLOSED: [2017-06-04 Sun 17:55]
    CLOCK: [2017-06-04 Sun 20:45]--[2017-06-04 Sun 20:56] =>  0:11
    CLOCK: [2017-06-04 Sun 18:20]--[2017-06-04 Sun 18:23] =>  0:03
    CLOCK: [2017-06-04 Sun 17:56]--[2017-06-04 Sun 18:19] =>  0:23
    CLOCK: [2017-06-04 Sun 17:46]--[2017-06-04 Sun 17:55] =>  0:09
    CLOCK: [2017-06-04 Sun 17:35]--[2017-06-04 Sun 17:45] =>  0:10
    CLOCK: [2017-06-04 Sun 17:23]--[2017-06-04 Sun 17:34] =>  0:11
    CLOCK: [2017-06-04 Sun 17:04]--[2017-06-04 Sun 17:23] =>  0:19
    CLOCK: [2017-06-04 Sun 16:55]--[2017-06-04 Sun 17:03] =>  0:08
    CLOCK: [2017-06-04 Sun 15:20]--[2017-06-04 Sun 16:54] =>  1:34
    CLOCK: [2017-06-04 Sun 15:12]--[2017-06-04 Sun 15:19] =>  0:07
    CLOCK: [2017-06-04 Sun 14:41]--[2017-06-04 Sun 15:11] =>  0:30
    CLOCK: [2017-06-04 Sun 08:43]--[2017-06-04 Sun 08:58] =>  0:15
    CLOCK: [2017-06-03 Sat 16:36]--[2017-06-03 Sat 16:54] =>  0:18
    CLOCK: [2017-06-03 Sat 16:28]--[2017-06-03 Sat 16:35] =>  0:07
    CLOCK: [2017-06-03 Sat 16:09]--[2017-06-03 Sat 16:27] =>  0:18
    CLOCK: [2017-06-03 Sat 15:02]--[2017-06-03 Sat 16:08] =>  1:06
    CLOCK: [2017-06-02 Fri 15:04]--[2017-06-02 Fri 16:02] =>  0:58
    CLOCK: [2017-06-02 Fri 14:12]--[2017-06-02 Fri 15:03] =>  0:51
    CLOCK: [2017-06-02 Fri 13:11]--[2017-06-02 Fri 14:11] =>  1:00

We need to handle decorations from yarn, since its common to all
kernels.

Done:

- move injection to last in second stage expansion. This proves there
  are no dependencies with other expansion steps.
- rename injection to external expansion. Ensure there are no injector
  remnants in terms of terminology in yarn. Use expansion error
  instead of injection error.
- add parameters required for decoration expansion. Drill across the
  APIs to supply those parameters.
- move creation of drp and dpf into yarn workflow.
- revert all changes to knit and quilt. We'll just recreate drp/dpf in
  quilt for now.
- add element properties and decoration properties to yarn.
- create a kernel based top-level expander that includes other
  expanders.
- create a decoration expander based on external expansion
  interface. Populate decoration properties.
- update assistant to read decoration properties from yarn.
- remove decoration properties from quilt cpp and csharp.

*** COMPLETED Fix broken builds due to disk space                     :story:
    CLOSED: [2017-07-01 Sat 15:17]
    CLOCK: [2017-07-01 Sat 15:12]--[2017-07-01 Sat 15:17] =>  0:05
    CLOCK: [2017-07-01 Sat 13:44]--[2017-07-01 Sat 15:11] =>  1:27

The linux travis builds are failing because we do not seem to have
enough disk space:

#+begin_example
License: GPLv3 - GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>.
Error: boost::filesystem::create_directory: No space left on device: "/tmp/log"
terminate called after throwing an instance of 'boost::filesystem::filesystem_error'
  what():  boost::filesystem::create_directory: No space left on device: "/tmp/log"
/home/travis/build/DomainDrivenConsulting/dogen/build/scripts/test_package.linux.sh: line 84: 14428 Aborted                 (core dumped) /usr/bin/dogen.knitter -t hello_world.dia
#+end_example

We need to start removing some files to create some space.

*** COMPLETED Remove =is_target= from frontends                       :story:
    CLOSED: [2017-07-01 Sat 16:34]
    CLOCK: [2017-07-01 Sat 16:13]--[2017-07-01 Sat 16:33] =>  0:20
    CLOCK: [2017-07-01 Sat 15:18]--[2017-07-01 Sat 16:12] =>  0:54

At present we seem to be supplying the =is_target= flag to the
frontends, but its not clear why that is. Ideally, we should not care
at this point who the target is. Try removing it and see what happens.

- remove is target from the frontends
- remove is target from descriptor
- remove is not yet determined from origin types

*** COMPLETED Analysis: major yarn clean-up                           :story:
    CLOSED: [2017-07-01 Sat 16:59]
    CLOCK: [2017-07-01 Sat 16:34]--[2017-07-01 Sat 16:59] =>  0:25
    CLOCK: [2017-06-30 Fri 09:10]--[2017-06-30 Fri 13:33] =>  4:23
    CLOCK: [2017-06-07 Wed 18:25]--[2017-06-07 Wed 22:41] =>  4:16

It seems we have reached the need to perform yet another clean up in
yarn. The merging of the code in quilt provides us with a good reason
to do this clean up. The objectives of the clean up are as follows:

- use domain terminology where possible. Examples: model to model
  transform, model to text transform, etc.
- make yarn the core model and get rid of "modelets" such as knit and
  parts of quilt. In reality, yarn should perform a complete workflow
  from knitting options to generated files. The remaining models
  should just hook up into this workflow.

In effect, yarn is made up of a set of transformations, themselves
composed of transformations and so forth. We should follow the
[[http://www.morganclaypool.com/doi/abs/10.2200/S00751ED2V01Y201701SWE004][Brambilia]] approach and name all of these classes according to the
vocabulary of the domain experts.

Sample code:

#+begin_src
transforms::model_to_model_transform:

const auto context(context_source(ko));
auto target(model_source(context));
pre_process(context, target);
auto expanded(expand(context, target));
map(expanded);

for(auto& m : expanded) {
    auto refs(model_source(context, m));
    pre_process(refs);
    map(refs);
    auto combined(combine(m, refs))
    post_process(combined);
    r.push_back(convert(combined));
}
#+end_src

The objective of this story is just to clean up the design. We will
raise individual stories for the implementation.

*** STARTED Add support for proper JSON serialisation in C++          :story:
    CLOCK: [2017-04-12 Wed 20:56]--[2017-04-12 Wed 23:14] =>  2:18

We need to add support for JSON in C++. It will eventually have to
roundtrip to JSON in C# but that will be handled as two separate
stories.

Libraries:

- One option is [[https://github.com/cierelabs/json_spirit][json_spirit]].
- Another option is [[https://github.com/miloyip/rapidjson][RapidJson]].
- Actually there is a project comparing JSON libraries: [[https://github.com/miloyip/nativejson-benchmark][nativejson-benchmark]]
- One interesting library is [[https://github.com/dropbox/json11][Json11]].

When we implement this we should provide support for JSON with
roundtripping tests.

We will not replace the current IO implementation; it should continue
to exist as is, requiring no external dependencies.

We should consider supporting multiple JSON libraries: instead of
making the mistake we did with serialisation where we bound the name
=serialization= with boost serialisation, we should call it by its
real name, e.g. =json_spirit= etc. Then when a user creates a
stereotype for a profile such as =Serializable= it can choose which
serialisation codecs to enable for which language. This means that the
same stereotypes can have different meanings in different
architectures, which is the desired behaviour.

We should create a serialise / deserialise functions following the
same logic as boost:

#+begin_src c++
void serialize(Value& v, const object& o);
void serialize(Value& v, const base& b);

void deserialize(const Value& v, object& o);
base* deserialize(const Value& v);
#+end_src

Or perhaps even better, we can make the above the internal methods and
use =operator<<= and =operator>>= as the external methods:

#+begin_src c++
void operator<<(Value& v, const object& o);
void operator>>(const Value& v, object& o);
#+end_src

Notes:

- create a registrar with a map for each base type. The function
  returns a base type pointer.
- when you deserialize a base type pointer, you call the pointer
  deserialize above. Same for when you have a pointer to an object. It
  will internally call the registrar (if its a base type) and get the
  right function.
- this means we only need to look at type for inheritance. Although we
  should probably always do it for validation? However, what happens
  if we want to make a model so we can read external JSON? It won't
  contain type markings.
- =operator>>= will not be defined for pointers or base classes.
- this wont work for the case of =doc << base=. For this we need a map
  that looks up on type_index.

Merged stories:

For the previous attempt to integrate RapidJson see this commit:

b2cce41 * third party: remove includes and rapid json

*Add support for JSON serialisation*

We should have proper JSON serialisation support, for both reading and
writing. We can then implement IO in terms of JSON.

*Raw JSON vs cooked JSON*

If we do implement customisable JSON serialisation, we should still
use the raw format in streaming. We need a way to disable the cooked
JSON internally. We should also re-implement streaming in terms of
this JSON mode.

*** STARTED Start documenting the theoretical aspects of Dogen        :story:
    CLOCK: [2017-05-26 Fri 13:02]--[2017-05-26 Fri 14:00] =>  0:58
    CLOCK: [2017-05-26 Fri 10:02]--[2017-05-26 Fri 12:01] =>  1:59
    CLOCK: [2017-05-13 Sat 16:07]--[2017-05-13 Sat 18:07] =>  2:00
    CLOCK: [2017-05-12 Fri 14:02]--[2017-05-12 Fri 17:01] =>  2:59
    CLOCK: [2017-05-12 Fri 09:02]--[2017-05-12 Fri 11:55] =>  2:53

Up to now we have more or less coded Dogen as we went along; we
haven't really spent a lot of time worrying about the theory behind
the work we were carrying out. However, as we reached v1.0, the theory
took center stage. We cannot proceed to the next phase of the product
without a firm grasp of the theory. This story is a starting point so
we can decide on how to break up the work.

*** STARTED Move element segmentation into yarn                       :story:
    CLOCK: [2017-06-06 Tue 17:31]--[2017-06-06 Tue 18:23] =>  0:52
    CLOCK: [2017-06-02 Fri 11:16]--[2017-06-02 Fri 11:56] =>  0:40

We've added the notion that an element can be composed of other
elements in quilt, in order to handle forward declarations. However,
with a little bit of effort we can generalise it into yarn. It would
be useful for other things such as inner classes. We don't need to
actually implement inner classes right now but we should make sure the
moving of this feature into yarn is compatible with it.

Notes:

- seems like we have two use cases: a) we need all elements, master
  and extensions and we don't really care about which is which. b) we
  only want masters. However, we must be able to access the same
  element properties from either the master or the extension. Having
  said all that, it seems we don't really need all of the element
  properties for both - forward declarations probably only need:
  decoration and artefact properties.
- we don't seem to use the map in formattables model anywhere, other
  than to find master/extension elements.
- Yarn model could have two simple list containers (masters and
  all). Or maybe we don't even need this to start off with, we can
  just iterate and skip extensions where required.
- so in conclusion, we to move decoration, enablement and dependencies
  into yarn (basically decoration and artefact properties) first and
  then see where segmentation ends.

*** STARTED Implement the context class                               :story:
    CLOCK: [2017-07-01 Sat 21:45]--[2017-07-01 Sat 22:17] =>  0:32
    CLOCK: [2017-07-01 Sat 21:28]--[2017-07-01 Sat 21:44] =>  0:16

Tasks:

- create the transformation context, populate it with all the main
  objects needed by yarn at present.
- Add a method to generate the context and then unpack it to fit the
  current API.

*** Implement the exogenous transformation chain                      :story:

Tasks:

- in yarn, implement:
  - model generation chain;
  - initial target chain; and
  - exogenous transforms (registration etc).
- in the frontends: implement the exogenous transforms interface.
- update knit to conditionally use the transforms code or the legacy
  code.

*** Implement the pre-processing chain                                :story:

This story may be too big as one story.

Tasks:

- implement all of the transforms required by the pre-processing
  chain.
- implement the pre-processing chain in terms of those transforms.
- plug in the pre-processing chain into the initial target chain.

*** Implement the references chain                                    :story:

Tasks:

- implement the references expansion in the references chain.
- plug in the references chain into the model generation chain.
- consider using a multi-threaded approach. If its too hard we should
  just stick to the single-threaded implementation we have at present.

*** Implement the model generation chain                              :story:

Tasks:

- implement the output languages expansion, considering
  multi-threading. If its too hard we should just stick to the
  single-threaded implementation we have at present.
- implement the merge transform.
- implement the intermediate model transform.

*** Implement the post-processing chain                               :story:

This story may be too big as one story.

Tasks:

- implement the external transform chain.
- implement all other transforms required by the post-processing
  chain.
- plug it in the model generation chain.
- fix all errors when we replace the legacy code with the new
  transform-based code.

*** Implement the code-generation chain                               :story:

Tasks:

- Add registration, interfaces etc.
- implement the kernels in terms of the new interfaces.
- update knit to use the code generator.

*** Move all data types into its own namespace                        :story:

Now we have placed all the transforms under namespace =transforms=,
for symmetry purposes it would be nice to have some top-level
namespace for the data types. Names:

- entities
- ...

If we cannot find any good names, we may need to leave these objects
at the top-level. However, we should probably also place the code
generator at the top-level as well.

** Deprecated
