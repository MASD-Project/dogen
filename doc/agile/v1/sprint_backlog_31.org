#+title: Sprint Backlog 31
#+options: date:nil toc:nil author:nil num:nil
#+todo: STARTED | COMPLETED CANCELLED POSTPONED
#+tags: { story(s) epic(e) spike(p) }

* Sprint Goals

- work on PMM.

* Stories

** Active

#+begin: clocktable :maxlevel 3 :scope subtree :indent nil :emphasize nil :scope file :narrow 75 :formula %
#+CAPTION: Clock summary at [2022-04-09 Sat 02:28]
| <75>                                                       |         |       |       |       |
| Headline                                                   | Time    |       |       |     % |
|------------------------------------------------------------+---------+-------+-------+-------|
| *Total time*                                               | *56:02* |       |       |   0.0 |
|------------------------------------------------------------+---------+-------+-------+-------|
| Stories                                                    | 56:02   |       |       |   0.0 |
| Active                                                     |         | 56:02 |       |   0.0 |
| Edit release notes for previous sprint                     |         |       |  6:06 |   0.0 |
| Create a demo and presentation for previous sprint         |         |       |  0:27 |   0.0 |
| Fix broken org-mode tests                                  |         |       |  3:09 |   0.0 |
| Sprint and product backlog grooming                        |         |       |  5:40 |   0.0 |
| Move build to GitHub                                       |         |       |  4:07 |   0.0 |
| Update vcpkg to latest                                     |         |       |  3:00 |   0.0 |
| Remove third-party dependencies outside vcpkg              |         |       |  1:19 |   0.0 |
| Remove deprecated travis and appveyor config files         |         |       |  0:02 |   0.0 |
| Create clang build using libc++                            |         |       |  0:36 |   0.0 |
| Rewrite CTest script to use github actions                 |         |       | 13:15 |   0.0 |
| Remove database options from help                          |         |       |  0:07 |   0.0 |
| Generate doxygen docs and add to site                      |         |       |  1:51 |   0.0 |
| Add packaging step to github actions                       |         |       |  0:21 |   0.0 |
| Setup MSVC Windows build for debug and release             |         |       |  3:31 |   0.0 |
| Can't see build info in github builds                      |         |       |  0:35 |   0.0 |
| Update build instructions in readme                        |         |       |  0:34 |   0.0 |
| Replace Dia IDs with UUIDs                                 |         |       |  0:22 |   0.0 |
| Update the test package scripts for the GitHub CI          |         |       |  0:39 |   0.0 |
| Move codec related tests into codecs                       |         |       |  1:02 |   0.0 |
| Update nightly builds to use new vcpkg setup               |         |       |  0:15 |   0.0 |
| Assorted improvements to CMake files                       |         |       |  6:26 |   0.0 |
| Windows package is broken                                  |         |       |  0:17 |   0.0 |
| Capitalise titles in models correctly                      |         |       |  0:06 |   0.0 |
| Add full and relative path processing to PM                |         |       |  0:12 |   0.0 |
| Add "verbatim" PlantUML extension                          |         |       |  1:42 |   0.0 |
| Consider standardising all templates as mustache templates |         |       |  0:21 |   0.0 |
#+tblfm: $5='(org-clock-time%-mod @3$2 $2..$4);%.1f
#+end:

Agenda:

#+begin_src emacs-lisp
(org-agenda-file-to-front)
#+end_src

*** COMPLETED Edit release notes for previous sprint                  :story:
    CLOSED: [2021-01-05 Tue 22:06]
    :LOGBOOK:
    CLOCK: [2021-01-05 Tue 22:34]--[2021-01-05 Tue 22:47] =>  0:13
    CLOCK: [2021-01-05 Tue 20:07]--[2021-01-05 Tue 21:11] =>  1:04
    CLOCK: [2021-01-05 Tue 18:27]--[2021-01-05 Tue 20:07] =>  1:40
    CLOCK: [2021-01-04 Mon 22:43]--[2021-01-05 Tue 00:05] =>  1:22
    CLOCK: [2021-01-04 Mon 22:31]--[2021-01-04 Mon 22:42] =>  0:11
    CLOCK: [2021-01-04 Mon 20:25]--[2021-01-04 Mon 22:01] =>  1:36
    :END:

Add github release notes for previous sprint.

Release announcements:

- [[https://twitter.com/MarcoCraveiro/status/1346587523187937281][twitter]]
- [[https://www.linkedin.com/posts/marco-craveiro-31558919_release-dogen-v1030-est%C3%A1dio-joaquim-morais-activity-6752353683461304320-zKp7/][linkedin]]
- [[https://gitter.im/MASD-Project/Lobby][Gitter]]

#+begin_src markdown
![Estadio](https://scontent.flhr4-1.fna.fbcdn.net/v/t1.0-9/108163652_3035579726477117_9033283849917525599_n.jpg?_nc_cat=106&ccb=2&_nc_sid=8bfeb9&_nc_ohc=q2MqbCT1YhgAX_zmBps&_nc_ht=scontent.flhr4-1.fna&oh=48ca18f3dd13f0a746ea29458f643993&oe=6018A9EA)
_Municipal stadium in Moçamedes, Namibe. (C) 2020 [Administração Municipal De Moçâmedes](https://www.facebook.com/permalink.php?id=1473211179380654&story_fbid=3035581253143631)._

# Introduction

Happy new year! The first release of the year is a bit of a bumper one: we finally managed to add support for [org-mode](https://orgmode.org), and transitioned _all_ of Dogen to it. It was a mammoth effort, consuming the entirety of the holiday season, but it is refreshing to finally be able to add significant user facing features again. Alas, this is also a bit of a bitter-sweet release because we have more or less run out of coding time, and need to redirect our efforts towards writing the PhD thesis. On the plus side, the architecture is now up-to-date with the conceptual model, mostly, and the bits that aren't are fairly straightforward (famous last words). And this is nothing new; Dogen development has always oscillated between theory and practice. If you recall, a couple of years ago we had to take a nine-month coding break to learn about the theoretical underpinnings of [MDE](https://en.wikipedia.org/wiki/Model-driven_engineering) and then resumed coding on [Sprint 8](https://github.com/MASD-Project/dogen/releases/tag/v1.0.08) for what turned out to be a 22-sprint-long marathon (pun intended), where we tried to apply all that was learned to the code base. Sprint 30 brings this long cycle to a close, and begins a new one; though, this time round, we are hoping for far swifter travels around the literature. But I digress. Lets not get lost talking about the future, and focus instead on the release at hand. And _what_ a release it was.

# User visible changes

This section covers stories that affect end users, with the video providing a quick demonstration of the new features, and the sections below describing them in more detail.

[![Sprint 1.0.30 Demo](https://img.youtube.com/vi/ei8B1Pine34/0.jpg)](https://youtu.be/ei8B1Pine34)
_Video 1: Sprint 30 Demo._

## Org-mode support

A target that we've been chasing for the longest time is the ability to create models using [org-mode](https://orgmode.org). We use org-mode (and [emacs](https://www.gnu.org/software/emacs)) for pretty much everything in Dogen, such time keeping and task management - it's how we manage our [product](https://github.com/MASD-Project/dogen/blob/master/doc/agile/product_backlog.org) and [sprint backlogs](https://github.com/MASD-Project/dogen/blob/master/doc/agile/v1/sprint_backlog_30.org), for one - and we'll soon be using it to write [academic papers](https://jonathanabennett.github.io/blog/2019/05/29/writing-academic-papers-with-org-mode/) too. It's just an amazing tool with a great tooling ecosystem, so it seemed only natural to try and see if we could make use of it for modeling too. Now, even though we are very comfortable with org-mode, this is not a decision to be taken lightly because we've been using [Dia](https://wiki.gnome.org/Apps/Dia) since Dogen's inception, over eight years ago.

![Dia diagram](https://raw.githubusercontent.com/MASD-Project/dogen/master/doc/blog/images/colour_coded_uml_diagrams.png)
_Figure 1: Dia diagram for a Dogen model with the introduction of colouring, Dogen [v1.0.06](https://github.com/MASD-Project/dogen/releases/tag/v1.0.06)_

As much as we profoundly love Dia, the truth is we've had concerns about relying on it _too much_ due to its [sparse maintenance](https://gitlab.gnome.org/GNOME/dia). In particular, Dia relies on an old version of GTK, meaning it could get pulled from distributions at any time; we've already had a similar experience with [Gnome Referencer](https://tracker.debian.org/news/937606/removed-122-2-from-unstable/), which wasn't at all pleasant. In addition, there are a number of "papercuts" that are mildly annoying, if livable, and which will probably not be addressed; we've curated a list of [such issues](https://github.com/MASD-Project/dogen/blob/master/doc/agile/v1/sprint_backlog_28.org#dia-limitations-that-impact-dogen-usage), in the hope of _one day_ fixing these problems upstream. The direction of travel for the maintenance is also not entirely aligned with our needs. For example, we recently saw the removal of python support in Dia - at least in the version which ships with Debian - a feature in which we relied upon heavily, and intended to do more so in the future. All of this to say that we've had a number of ongoing worries that motivated our decision to move away from Dia. However,  I don't want to sound too negative here - and please don't take any of this as a criticism to Dia or its developers. Dia is an absolutely brilliant tool, and we have used it for over two decades; It is great at what it does, and we'll continue to use it for free modeling. Nonetheless, it has become increasingly clear that the directions of Dia and Dogen have started to diverge over the last few years, and we could not ignore that. I'd like to take this opportunity to give a huge thanks to all of those involved in Dia (past and present); they have certainly created an amazing tool that stood the test of time. Also, although we are moving away from Dia use in mainline Dogen, we will continue to support the Dia codec and we have tests to ensure that the current set of features [will continue to work](https://github.com/MASD-Project/frozen).

That's that for the rationale for moving away from Dia. But why org-mode? We came up with a nice laundry list of reasons:

- **"Natural" Representation**: org-mode documents are trees, with arbitrary nesting, which makes it a good candidate to represent the nesting of namespaces and classes. It's just a _natural_ representation for structural information.
- **Emacs tooling**: within the org-mode document we have full access to Emacs features. For example, we have spell checkers, regular copy-and-pasting, etc. This greatly simplifies the management of models. Since we already use Emacs for everything else in the development process, this makes the process even more fluid.
- **Universality**: org-mode is fairly universal, with support in [Visual Studio Code](https://github.com/vscode-org-mode/vscode-org-mode), [Atom](https://atom.io/packages/organized) and even [Vim](https://github.com/jceb/vim-orgmode) (for more details, see [Get started with Org mode without Emacs](https://opensource.com/article/19/1/productivity-tool-org-mode)). None of these implementations are as good as Emacs, of course - not that we are biased, or anything - but they are sufficient to at least allow for basic model editing. And installing a simple plugin in your editor of choice is much easier than having to learn a whole new tool.
- **"Plainer" plain-text**: org-mode documents are regular text files, and thus easy to life-cycle in a similar fashion to code; for example, one can version control and diff these documents very easily. Now, we did have Dia's files in uncompressed XML, bringing some of these advantages, but due to the verbosity of XML it was very hard to see the wood for the trees. Lots of lines would change every time we touched a model element - and I literally mean "touch" - making it difficult to understand the nature of the change. Bisection for example was not helped by this.
- **Models as documentation**: Dogen aims to take the approach of "Literate Modeling" described in papers such as [Literate Modelling - Capturing Business Knowledge with the UML](https://discovery.ucl.ac.uk/id/eprint/933/1/10.0_Literate_Modelling.pdf). It was clear from the start that a tool like Dia would not be able to capture the wealth of information we intended to add to the models. Org-mode on the other hand is the ideal format to bring disparate types of information together (see [Replacing Jupyter with Orgmode](https://rgoswami.me/posts/jupyter-orgmode) for an example of the sort of thing we have in mind).
- **Integration with org-babel**: Since models contain fragments of source code, org-mode's support for [working with source code](https://orgmode.org/manual/Working-with-Source-Code.html) will come in handy. This will immediately be really useful for handling text templates, and even more so in the future when we add support for code merging.

Over the past few sprints we've been carrying out a fair bit of experimentation on the side, generating org-mode files from the existing Dia models; it was mostly an exercise in feasibility to see if we could encode all of the required information in a comprehensible manner within the org-mode document.  These efforts convinced us that this was a sensible approach, so this sprint we focused on adding end-to-end support for org-mode. This entailed reading org-mode documents, and using them to generate the exact same code as we had from Dia. Unfortunately, though [C++ support for org-mode exists](https://orgmode.org/worg/org-tools/index.html), we could not find any suitable library for integration in Dogen. So we decided to write a simple parser for org-mode documents. This isn't a "generic parser" by any means, so if you throw invalid documents at it, do expect it to blow up _unceremonially_. Figure 2 shows the ```dogen.org``` model represented as a org-mode document.

![Org model in org](https://github.com/MASD-Project/dogen/raw/master/doc/blog/images/dogen_org_model.png)
_Figure 2: ```dogen.org``` model in the org-mode representation._

We tried as much as possible to leverage native org-mode syntax, for example by using [tags](https://orgmode.org/manual/Tags.html) and [property drawers](https://orgmode.org/manual/Property-Syntax.html) to encode Dogen information. However, this is clearly a first pass and many of the decisions may not survive scrutiny. As always, we need to have a great deal of experience editing models to see what works and what does not, and it's likely we'll end up changing the markup in the future. Nonetheless, the guiding principle is to follow the "spirit" of org-mode, trying to make the documents look like "regular" org-mode documents as much as possible. One advantage of this approach is that the existing tooling for org-mode can then be used with Dogen models - for example, [org-roam](https://www.orgroam.com/), [org-ref](https://github.com/jkitchin/org-ref) _et al._ Sadly, one feature which we did not manage to achieve was the use of ```stitch-mode``` in the org-babel blocks. It appears there is some kind of incompatibility between org-mode and [polymode](https://github.com/polymode/polymode); more investigation is required, such as for instance playing with the interestingly named [poly-org](https://github.com/polymode/poly-org). As Figure 3 demonstrates, the stitch templates are at present marked as ```fundamental```, but users can activate stitch mode when editing the fragment.

![Text model](https://github.com/MASD-Project/dogen/raw/master/doc/blog/images/org_model_text_stitch_template.png)
_Figure 3: Stitch template in ```dogen.text``` model._

In order to make our life easier, we implemented conversion support for org-mode:

```
$ head dogen.cli.dia
<?xml version="1.0" encoding="UTF-8"?>
<dia:diagram xmlns:dia="http://www.lysator.liu.se/~alla/dia/">
  <dia:diagramdata>
    <dia:attribute name="background">
      <dia:color val="#ffffffff"/>
    </dia:attribute>
    <dia:attribute name="pagebreak">
      <dia:color val="#000099ff"/>
    </dia:attribute>
    <dia:attribute name="paper">
$ dogen.cli convert --source dogen.cli.dia --destination dogen.cli.org
$ head dogen.cli.org
#+title: dogen.cli
#+options: <:nil c:nil todo:nil ^:nil d:nil date:nil author:nil
#+tags: { element(e) attribute(a) module(m) }
:PROPERTIES:
:masd.codec.dia.comment: true
:masd.codec.model_modules: dogen.cli
:masd.codec.input_technical_space: cpp
:masd.codec.reference: cpp.builtins
:masd.codec.reference: cpp.std
:masd.codec.reference: cpp.boost
```

This feature was mainly added for our benefit, but it may also be useful for any users that wish to update their models from Dia to org-mode. We made use of conversion to migrate all of the Dogen core models into org-mode, including the library models - though these required a bit of manual finessing to get them into the right shape. We also performed a number of modeling tasks in the sprint using the new format and the work proceeded as expected; see the below sections for links to a video series on this subject. However, one thing we did notice is that we missed the ability to visualise models as UML diagrams. And that gives us a nice segway into the second major story of this sprint.

## Initial PlantUML support

Whilst the advantages of modeling using textual languages over graphical languages are patently obvious, the truth is the modeling process requires _both views_ in order to progress smoothly. Maybe its just me but I get a lot of information about a system very quickly just by looking at a well-curated class diagram. It is especially so when one does not touch a sub-system for extended periods of time; it only takes a few minutes to observe and absorb the structure of the sub-system by looking carefully at its class diagram. In Dogen, we have relied on this since the beginning, particularly because we need to context-switch in-and-out so often. With the move to org-mode we suddenly found ourselves unable to do so, and it was quite disorienting. So we decided to carry out yet another little experiment: to add basic support for [PlantUML](https://plantuml.com/). PlantUML is a textual notation that describes pretty much all types of UML diagrams, as well as a tool that converts files in that notation over to a graphical representation. The syntax is very simple and intuitive. Take for example one of the samples they supply:

```PlantUML
@startuml
Class11 <|.. Class12
Class13 --> Class14
Class15 ..> Class16
Class17 ..|> Class18
Class19 <--* Class20
@enduml
```

This very simple and compact notation produces the rather wonderful UML class diagram:

![PlantUML example](https://s.plantuml.com/imgw/img-fa90e8d3b95abb6ff2192dd122b0b7d8.webp)
_Figure 4: UML Class Diagram generated from PlantUML sample. Source: [PlantUML site](https://plantuml.com/class-diagram)._

Given the notation is so straightforward, we decided to create a codec that outputs PlantUML documents, which can then be processed by their tool. To do so, simply convert the model:

```
$ dogen.cli convert --source dogen.cli.org --destination dogen.cli.plantuml
```

The listing below has a fragment of the output produced by Dogen; it contains the PlantUML representation of the ```dogen.org``` model from Figure 2.

```PlantUML
@startuml
set namespaceSeparator ::
note as N1
Provides support for encoding and decoding Emacs's org-mode
documents.

The support is very basic and focuses only on the features
of org mode required by Dogen.
end note

namespace entities #F2F2F2 {
        class section #F7E5FF {
                +{field} blocks std::list<block>
        }

        class document #F7E5FF {
                +{field} affiliated_keywords std::list<affiliated_keyword>
                +{field} drawers std::list<drawer>
                +{field} section section
                +{field} headlines std::list<headline>
        }
<snip>
```

You can process it with PlantUML, to produce SVG output (or PNG, etc):

```
$ plantuml dogen.org.plantuml -tsvg
```

The SVG output is particularly nice because you can zoom in and out as required. It is also rendered very quickly by the browser, as attested by Figure 5.

![SVG dogen.org](https://raw.githubusercontent.com/MASD-Project/dogen/master/projects/dogen.org/modeling/dogen.org.svg)
_Figure 5: ```dogen.org``` SVG representation, produced by PlantUML._

While it was fairly straightforward to add _basic_ PlantUML support, the diagrams are still quite far from the nice orderly representations we used to have with Dia. They are definitely an improvement on not having any visual representation at all, mind you, but of course given our OCD nature, we feel compeled to try to get them as close as possible to what we had before. In order to do so we will have to do some re-engineering of the codec model and bring in some of the information that lives in the logical model. In particular:

- generalisation parsing so that we can depict these relationships in the diagram; this is actually quite tricky because some of the information may live on profiles.
- some level of resolution: all intra-model types must be resolved in order to support associations.

These changes will have to remain on the work stack for the future. For now the diagrams are sufficient to get us going, as Figures 5 and 6 demonstrate. Finally, its also worthwhile pointing out that PlantUML has [great integration with Emacs](https://github.com/skuro/plantuml-mode) and with org-mode in particular, so in the future it is entirely possible we could "inject" a graphical representation of model elements into the model itself. Clearly, there are many possibilities to explore here, but for now these remain firmly archived in the "future directions" section of the product backlog.

![PlantUML model](https://github.com/MASD-Project/dogen/raw/master/doc/blog/images/plantuml_profiles_model.png)
_Figure 6: PlantUML representation of ```dogen.profiles``` model._

### Add support for reference directories

With this release we also managed to add another feature which we have been pinning for: the ability to have models in multiple directories. A new command line parameter was added: ```--reference-directory```.

```
[marco@lovelace dia]$ /work/DomainDrivenConsulting/masd/dogen/integration/build/output/clang11/Release/stage/bin/dogen.cli generate --help
Dogen is a Model Driven Engineering tool that processes models encoded in supported codecs.
Dogen is created by the MASD project.
Displaying options specific to the generate command.
For global options, type --help.

Generation:
  -t [ --target ] arg              Model to generate code for, in any of the
                                   supported formats.
  -o [ --output-directory ] arg    Output directory for the generated code.
                                   Defaults to the current working directory.
  -r [ --reference-directory ] arg One or more directories to check for
                                   referenced models.
[marco@lovelace dia]$
```

Users can supply directories containing their models and Dogen will check those directories when resolving references. This means you no longer need to keep all your models in a big jumble on the same directory, but should instead start to keep them together with the code they generate. We used this feature in Dogen to separate the old ```dogen.models``` directory, and created a number of ```modeling``` directories where all the content related to modeling for a given component will be placed. For example, see the ```dogen.org``` [modeling directory](https://github.com/MASD-Project/dogen/tree/master/projects/dogen.org/modeling):

```
$ ls -l
total 76
-rw-r--r--   1 marco          marco     3527 2021-01-02 12:37 CMakeLists.txt
-rw-r--r--   1 marco          marco    10360 2021-01-03 17:36 dogen.org.org
-rw-r--r--   1 marco          marco     3881 2021-01-03 13:53 dogen.org.plantuml
-rw-r--r--   1 marco          marco    60120 2021-01-03 13:54 dogen.org.svg
```

# Development Matters

In this section we cover topics that are mainly of interest if you follow Dogen development, such as details on internal stories that consumed significant resources, important events, etc. As usual, for all the gory details of the work carried out this sprint, see the sprint log. As usual, for all the gory details of the work carried out this sprint, see [the sprint log](https://github.com/MASD-Project/dogen/blob/master/doc/agile/v1/sprint_backlog_30.org).

## Milestones and Ephemerides

This sprint saw the 13,000th commit to Dogen.

![13k commit](https://raw.githubusercontent.com/MASD-Project/dogen/master/doc/blog/images/git_commit_13_000th.png)
_Figure 7_: Commit number 13,000th was made to the Dogen GitHub repository.

## Significant Internal Stories

This sprint had two key goals, both of which were achieved: org-mode and PlantUML support. These were described in the user facing stories above. In this section we shall provide more details about how this work was organised, as well as other stories which were not user facing.

### Org-mode work

The following stories were required to bring about org-mode support:

- **Add support for reading org mode documents**: creation of an org-mode parser, as well as a model to represent the types of this domain.
- **Add org-mode codec for input**: story to plug in the new org-mode parser into the codec framework, from an input perspective.
- **Create a model to org transform**: output side of the work; the addition of a transform which takes a Dogen model and generates an org-mode document.
- **Add tags to org model**: originally we tried to infer the element's meta-type by its position (e.g. package, "regular" element, attribute). However, it soon became obvious this was not possible and we ended up having to add org tags to perform this work. A story related to this one was also **Assorted improvements to org model**, where we sorted out a small number of papercuts with the org documents.
- **Consider replacing properties drawer with tables**: an attempt to use org-mode tables instead of property drawers to represent meta-data. We had to cancel the effort as we could not get it to work before the end of the sprint.
- **Convert library models into org**: we spent a fair bit of time in converting all of the JSON models we had on our library into org-mode. The automatic conversion worked fairly well, but it was missing some key bits which had to be added manually.
-  **Convert reference models into org**: similarly to the library models, we had to convert all of Dogen's models into org-mode. This also includes the work for [C++](https://github.com/MASD-Project/cpp_ref_impl/tree/master/projects/cpp_ref_impl.models/org) and [C#](https://github.com/MASD-Project/csharp_ref_impl/tree/master/Src/CSharpRefImpl.Models/org) reference models. We managed to use the automatic conversion for all of these, after a fair bit of work on the conversion code.
- **Create a "frozen" project**: although we were moving away from Dia, we did not want the existing support to degrade. The Dia Dogen models are an exacting test in code generation, which add a lot of value. There has always been an assumption that these would be a significant part of the code generator testing suite, but what we did not anticipate is that we'd move away from using a "core" codec such as Dia. So in order not to lose all of the testing infrastructure we decided to create a ["frozen" version of Dogen](https://github.com/MASD-Project/frozen), which in truth is not completely frozen, but contains a faithful representation across all supported codecs of the Dogen models at that point in time. With Frozen we can guarantee that the JSON and Dia support will not be any worse for all the features used by Dogen at the time the snapshot was taken.
- **Remove JSON and Dia models for Dogen**: once Frozen was put in place, we decommissioned all of the existing Dia and JSON models within Dogen. This caused a number of breaks which had to be hunted down and fixed.
- **Add org-to-org tests** and **Analysis on org mode round-tripping**: we added a "special" type of round-tripping: the org-to-org conversion. This just means we can read an org-mode document and then regenerate it without introducing any differences. It may sound quite tautological, but it has its uses; for example, we can introduce new features to org documents by adding it to the output part of the transform chain and then regenerating all documents. This was useful several times this sprint. It will also be quite useful in the future, when we integrate with external tooling; we will be able to append data to user models without breaking any of the user content (hopefully).
- **Inject custom IDs into org documents**: we tried not to have an identifier in org-mode documents for each element, but this caused problems when recreating the topology of the document. We had to use our org-to-org transform to inject ```custom_id``` (the org-mode attribute [used for this purpose](https://writequit.org/articles/emacs-org-mode-generate-ids.html)), though some had to be injected manually.

### Whitespace handling

Whilst it was introduced in the context of the org-mode, the changes to the handling of whitespace are a veritable epic in its own right. The problem was that in the past we wanted to preserve whitespace as supplied by the user in the original codec model; however, if we did this for org-mode documents, we would end up with very strange looking documents. So instead we decided to trim leading and trailing whitespace for all commentary. It took a while to get it to work such that the generated code had no differences, but this approach now means the org-mode documents look vaguely sensible, as does the generated code. The following stories were involved in adding this feature:

- **Move documentation transform to codec model**: for some reason we had decided to place the documentation trimming transform in the logical model. This made things a lot more complicated. In this sprint we moved it into the codec model, which greatly simplified the transform.
**Stitch templates are consuming whitespace**: this was a bit of a wild-goose chase. We thought the templates were some how causing problems with the spacing, but in the end it was just to do with how we trim different assets. Some hackery was required to ensure text templates are correctly terminated with a new line.
- **Remove leading and trailing new lines from comments**: the bulk of the work where we trimmed all commentary.
- **Allow spaces in headlines for org mode documents**: to make org-mode documents more readable, we decided to allow the use of spaces in headlines. These get translated to underscores as part of the processing. It is possible to disable this translation via the not-particularly-well-named key ```masd.codec.preserve_original```. This was mainly required for types such as ```unsigned int``` and the like.

### PlantUML work

There were a couple of stories involved in adding this feature:

- **Add PlantUML markup language support**: the main story that added the new codec. We also added CMake targets to generate all models.
- **Add comments to PlantUML diagrams**: with this story we decided to add support for displaying comments in modeling elements. It is somewhat experimental, and its look and feel is not exactly ideal, but it does seem to add some value. More work on the cosmetics is required.

### Smaller stories

A number of smaller stories was also worked on:

- **Merge dia codec model into main codec model**: we finally got rid of the Dia "modelet" that we have been carrying around for a few sprints; all of its code has now been refactored and placed in the ```dogen.codec``` model, as it should be.
- **Split orchestration tests by model and codec**: our massive file containing all code generation tests was starting to cause problems, particularly with treemacs and lsp-mode in emacs. This story saw the monster file split into a number of small files, organised by codec and product.
- **Add missing provenance details to codec models**: whilst trobuleshooting an issue we noticed that the provenance details had not been populated correctly at the codec level. This story addresses this shortcoming and paves the way for GCC-style errors, which will allow users to be taken to the line in the org-document where the issue stems from.

### Video series of Dogen coding

This sprint we recorded some videos on the implementation of the org-mode codec, and the subsequent use of these models. The individual videos are listed on Table 2, with a short description. They are also available as a playlist, as per link below.

[![Org-mode codec](https://img.youtube.com/vi/xfJNJ_9uAGU/0.jpg)](https://www.youtube.com/playlist?list=PLwfrwe216gF0wdVhy4fO1_QXJ-njWLSy4)
_Video 2: Playlist "MASD - Dogen Coding: Formatables Refactor"._

|Video | Description |
|---------|-----------------|
| [Part 1](https://youtu.be/xfJNJ_9uAGU) | In this part we provide context about the current task and start off by doing some preliminary work setting up the required infrastructure.|
| [Part 2](https://youtu.be/HueypBCfwIM) | In this video we review the work done to process org mode documents, and start coding the codec transform. However, we bump into a number of problems.|
| [Part 3](https://youtu.be/QE7P9s-8Xg0) | In this video we review the work done to get the org codec to generate files, and analyse the problems we're having at present, likely related to errors processing profiles.|
| [Part 4](https://youtu.be/I-PkSHkpwhI) | In this video we review the work done offline to implement the basic support for reading org-mode documents and start the work to write org mode documents using our org model.|
| [Part 6](https://youtu.be/ZfpqC9PuEog) | In this part we review the round-trip work made to support org mode, and refactor the tags used in org models. We also add support for org custom IDs.|
| [Part 7](https://youtu.be/6XDt7lV0k_k) | Addendum video where we demonstrate the use of the new org mode models in a more expansive manner.|
| [Part 8](https://youtu.be/6wqsbT-jG6Y) | In this second addendum we work on the org-to-org transform, solving a number of issues with whitespacing.|
| [Part 9](https://youtu.be/GvsI7IGk5sY) | In this video we try to explore moving away from properties to represent meta-data and using tables instead, but we run into a number of difficulties and end up spending most time fixing bugs related to element provenance.|

## Resourcing

As you can see from the lovely spread of colours of the pie chart, our story-keeping this sprint was much healthier than usual; the biggest story took 24.3% which is also a great sign of health. Our utilisation rate was also the highest since records began, at 70%, and a marked improvement over the measly 35% we clocked last sprint. To be fair, that is mainly an artefact of the holiday season more than anything else, but who are we to complain - one is always happy when the numbers are going in the right direction, regardless of root cause. On the less positive front, we spent around 16.2% on activities that were not related to our core mission - a sizable increase from the 11% last time round, with the main culprit being the 4.5% spent on addressing Emacs issues (including some [low-level elisp investigations](https://github.com/Alexander-Miller/treemacs/issues/752)). On the plus side, we did make a few nice changes to our Emacs setup, which will help with productivity, so its not just sunk costs. Predictably, the _circa_ 84% dedicated to "real work" was dominated by org-mode stories (~54%), with PlantUML coming in at a distant second (7%). All and all, it was a model sprint - if you pardon the pun - from a resourcing perspective.

![Sprint 30 stories](https://github.com/MASD-Project/dogen/raw/master/doc/agile/v1/sprint_30_pie_chart.jpg)
_Figure 8_: Cost of stories for sprint 30.

## Roadmap

The road map has been working like clockwork for the last few sprints, with us ticking stories off as if it was a mere list - clearly no longer the Oracle of Delphi it once was - and this sprint was no exception. Were we to be able to continue with the same release cadence, the next sprint would no doubt also tick off the next story on our list. Alas, we have ran out of coding time, so Sprint 31 will instead be very long running sprint, with very low utilisation rate. In addition, we won't bother creating sprints when the work is completely dedicated to writing; instead, regular service will resume once the writing comes to an end.

![Project Plan](https://github.com/MASD-Project/dogen/raw/master/doc/agile/v1/sprint_30_project_plan.png)

![Resource Allocation Graph](https://github.com/MASD-Project/dogen/raw/master/doc/agile/v1/sprint_30_resource_allocation_graph.png)

# Binaries

You can download binaries from either [Bintray](https://bintray.com/masd-project/main/dogen/1.0.30) or [GitHub](https://github.com/MASD-Project/dogen/releases/tag/v1.0.30), as per Table 3. All binaries are 64-bit. For all other architectures and/or operative systems, you will need to build Dogen from source. Source downloads are available in [zip](https://github.com/MASD-Project/dogen/archive/v1.0.30.zip) or [tar.gz](https://github.com/MASD-Project/dogen/archive/v1.0.30.tar.gz) format.

| Operative System | Format | BinTray | GitHub |
|----------|-------|-----|--------|
|Linux Debian/Ubuntu | Deb | [dogen_1.0.30_amd64-applications.deb](https://dl.bintray.com/masd-project/main/1.0.30/dogen_1.0.30_amd64-applications.deb) | [dogen_1.0.30_amd64-applications.deb](https://github.com/MASD-Project/dogen/releases/download/v1.0.30/dogen_1.0.30_amd64-applications.deb) |
|Windows | MSI | [DOGEN-1.0.30-Windows-AMD64.msi](https://dl.bintray.com/masd-project/main/DOGEN-1.0.30-Windows-AMD64.msi) | [DOGEN-1.0.30-Windows-AMD64.msi](https://github.com/MASD-Project/dogen/releases/download/v1.0.30/DOGEN-1.0.30-Windows-AMD64.msi) |

_Table 3: Binary packages for Dogen._

**Note 1:** The Linux binaries are not stripped at present and so are larger than they should be. We have [an outstanding story](https://github.com/MASD-Project/dogen/blob/master/doc/agile/product_backlog.org#linux-and-osx-binaries-are-not-stripped) to address this issue, but sadly CMake does not make this a trivial undertaking.

**Note 2:** Due to issues with Travis CI, we did not manage to get OSX to build, so and we could not produce a final build for this sprint. The situation with Travis CI is rather uncertain at present so we may remove support for OSX builds altogether next sprint.

# Next Sprint

The goals for the next sprint are:

- to implement path and dependencies via PMM.

That's all for this release. Happy Modeling!
#+end_src markdown

*** COMPLETED Create a demo and presentation for previous sprint      :story:
    CLOSED: [2021-01-05 Tue 22:33]
    :LOGBOOK:
    CLOCK: [2021-01-05 Tue 22:06]--[2021-01-05 Tue 22:33] =>  0:27
    :END:

Time spent creating the demo and presentation.

**** Presentation

***** Dogen v1.0.30, "Estádio Joaquim Morais"

    Marco Craveiro
    Domain Driven Development
    Released on 5th January 2021

***** Org-mode support
***** PlantUML support
***** Reference models directory

*** COMPLETED Fix broken org-mode tests                               :story:
    :LOGBOOK:
    CLOCK: [2021-09-25 Sat 14:52]--[2021-09-25 Sat 16:03] =>  1:11
    CLOCK: [2021-09-25 Sat 00:00]--[2021-09-25 Sat 00:53] =>  0:53
    CLOCK: [2021-09-24 Fri 00:00]--[2021-09-24 Fri 00:26] =>  0:26
    CLOCK: [2021-09-19 Sun 22:15]--[2021-09-19 Sun 22:54] =>  0:39
    :END:

At present a number of tests are failing. These are mainly due to org-mode
rountripping and spacing.

#+begin_example
Differences found. Outputting head of first 5 diffs.
diff -u include/dogen.identification/types/identification.hpp include/dogen.identification/types/identification.hpp
Reason: Changed generated file.
---  include/dogen.identification/types/identification.hpp
+++  include/dogen.identification/types/identification.hpp
@@ -26,12 +26,7 @@
 #endif

 /**
- * @brief Collection of types related to naming, labelling and general
- * identification within Dogen.
- *
- * UML representation:
- *
- * \image html dogen.identification/modeling/dogen.identification.svg
+ * @brief \image html dogen.identification/modeling/dogen.identification.svg
  */
 namespace dogen::identification {
 }
../../../../projects/dogen.orchestration/tests/dogen_org_product_tests.cpp(178): error: in "dogen_product_org_tests/dogen_identification_org_produces_expected_model": check mg::check_for_differences(od, m) has failed
Conversion generated differences: "/work/DomainDrivenConsulting/masd/dogen/integration/projects/dogen/modeling/dogen.org"
@@ -494,3 +494,4 @@
   :END:

 An error ocurred when dumping dogen's specs.
+

../../../../projects/dogen.orchestration/tests/dogen_org_product_tests.cpp(188): error: in "dogen_product_org_tests/dogen_org_conversion_has_no_diffs": check diff.empty() has failed
Conversion generated differences: "/work/DomainDrivenConsulting/masd/dogen/integration/projects/dogen.cli/modeling/dogen.cli.org"
@@ -181,3 +181,4 @@
    :END:

 Which style to use when dumping the specs.
+

../../../../projects/dogen.orchestration/tests/dogen_org_product_tests.cpp(202): error: in "dogen_product_org_tests/dogen_cli_org_conversion_has_no_diffs": check diff.empty() has failed
Conversion generated differences: "/work/DomainDrivenConsulting/masd/dogen/integration/projects/dogen.logical/modeling/dogen.logical.org"
@@ -4668,3 +4668,4 @@
    :END:

 An error has occurred while formatting.
+

../../../../projects/dogen.orchestration/tests/dogen_org_product_tests.cpp(244): error: in "dogen_product_org_tests/dogen_logical_org_conversion_has_no_diffs": check diff.empty() has failed
Conversion generated differences: "/work/DomainDrivenConsulting/masd/dogen/integration/projects/dogen.identification/modeling/dogen.identification.org"
@@ -12,6 +12,7 @@
 :masd.codec.reference: dogen.profiles
 :masd.variability.profile: dogen.profiles.base.default_profile
 :END:
+
 \image html dogen.identification/modeling/dogen.identification.svg

 * entities                                                           :module:

../../../../projects/dogen.orchestration/tests/dogen_org_product_tests.cpp(286): error: in "dogen_product_org_tests/dogen_identification_org_conversion_has_no_diffs": check diff.empty() has failed
#+end_example

*** STARTED Sprint and product backlog grooming                       :story:
    :LOGBOOK:
    CLOCK: [2022-04-08 Fri 23:18]--[2022-04-08 Fri 23:29] =>  0:11
    CLOCK: [2022-04-08 Fri 22:41]--[2022-04-08 Fri 23:02] =>  0:21
    CLOCK: [2022-04-08 Fri 21:52]--[2022-04-08 Fri 22:02] =>  0:10
    CLOCK: [2022-04-07 Thu 15:36]--[2022-04-07 Thu 15:44] =>  0:08
    CLOCK: [2022-04-03 Sun 12:59]--[2022-04-03 Sun 13:11] =>  0:12
    CLOCK: [2022-03-20 Sun 07:31]--[2022-03-20 Sun 08:33] =>  1:02
    CLOCK: [2021-04-16 Fri 08:30]--[2021-04-16 Fri 08:53] =>  0:23
    CLOCK: [2021-04-03 Sat 11:55]--[2021-04-03 Sat 12:12] =>  0:17
    CLOCK: [2021-04-03 Sat 09:01]--[2021-04-03 Sat 09:29] =>  0:28
    CLOCK: [2021-03-05 Fri 10:40]--[2021-03-05 Fri 11:20] =>  0:40
    CLOCK: [2021-02-14 Sun 10:02]--[2021-02-14 Sun 10:54] =>  0:52
    CLOCK: [2021-01-17 Sun 13:15]--[2021-01-17 Sun 13:25] =>  0:10
    CLOCK: [2021-01-15 Fri 15:02]--[2021-01-15 Fri 15:21] =>  0:19
    CLOCK: [2021-01-09 Sat 17:15]--[2021-01-09 Sat 17:22] =>  0:07
    CLOCK: [2021-01-08 Fri 10:30]--[2021-01-08 Fri 10:50] =>  0:20
    :END:

Updates to sprint and product backlog.

*** COMPLETED Move build to GitHub                                    :story:
    :LOGBOOK:
    CLOCK: [2022-03-20 Sun 19:01]--[2022-03-20 Sun 20:55] =>  1:54
    CLOCK: [2022-03-19 Sat 17:01]--[2022-03-19 Sat 17:19] =>  0:18
    CLOCK: [2021-09-26 Sun 10:11]--[2021-09-26 Sun 11:11] =>  1:00
    CLOCK: [2021-09-25 Sat 16:04]--[2021-09-25 Sat 16:37] =>  0:33
    CLOCK: [2021-09-19 Sun 15:33]--[2021-09-19 Sun 15:55] =>  0:22
    :END:

Travis is no longer supported, nor is bintray. We should move our CI
pipeline to GitHub.

Links:

- [[https://www.reddit.com/r/cpp/comments/of2sf1/github_action_to_set_vcpkg_up_and_cache_it/][reddit: GitHub action to set vcpkg up and cache it]]
- [[https://github.com/otland/forgottenserver/blob/master/.github/workflows/build-vcpkg.yml][build-vcpkg]]: example vcpkg.

Merged stories:

*Consider moving CI to GitHub Actions*

At present we are using Travis and AppVeyor for our CI. However, it
would be nice to have a single place with all of the CI (and even more
ideally, packaging as well). GitHub seems to offer some kind of CI
support via GitHub actions. However, we need to first move to building
on [[*Build dogen from docker][docker]].

Actually it seems we don't even need to do very much. See [[https://raymii.org/s/articles/Github_Actions_cpp_boost_cmake_speedup.html][this article]].

Links:

- [[https://raymii.org/s/articles/Github_Actions_cpp_boost_cmake_speedup.html][Github Actions, C++ with Boost and cmake, almost a 50% speedup with
  caching]]
- [[https://packages.debian.org/sid/libdtl-dev][libdtl-dev]]: dependency available on debian now.
- [[https://github.com/lballabio/QuantLib/tree/master/.github/workflows][quantlib GH]]: support for all operative systems (OSX, Win, Linux) as
  well as a number of interesting actions.

*** COMPLETED Update vcpkg to latest                                  :story:
    :LOGBOOK:
    CLOCK: [2022-03-20 Sun 13:00]--[2022-03-20 Sun 16:00] =>  3:00
    :END:

We need to get latest vcpkg locally and update all dependencies.

Links:

- [[https://github.com/MASD-Project/vcpkg][vcpkg]]
- [[https://lindevs.com/install-vcpkg-on-ubuntu/][Install vcpkg on Ubuntu 20.04]]
- [[https://nicedoc.io/microsoft/vcpkg#vcpkg-as-a-submodule][Vcpkg as a Submodule]]
- [[https://github.com/clangd/clangd/blob/master/.github/workflows/autobuild.yaml][clangd github action]]

*** COMPLETED Remove third-party dependencies outside vcpkg           :story:
    :LOGBOOK:
    CLOCK: [2022-03-20 Sun 10:57]--[2022-03-20 Sun 11:15] =>  0:18
    CLOCK: [2022-03-20 Sun 10:09]--[2022-03-20 Sun 10:30] =>  0:21
    CLOCK: [2022-03-20 Sun 09:40]--[2022-03-20 Sun 10:06] =>  0:26
    CLOCK: [2022-03-19 Sat 17:21]--[2022-03-19 Sat 17:35] =>  0:14
    :END:

We need to simplify our third party packages story:

- remove relational support: Since we do not make use of ODB at present we
  probably could remove support altogether.
- remove boost-di: we only use this in a very limited manner, but because of it
  we need to carry our own vcpkg patches.
- deprecate MASD fork of vcpkg.

*** COMPLETED Remove deprecated travis and appveyor config files      :story:
    :LOGBOOK:
    CLOCK: [2022-04-02 Sat 18:11]--[2022-04-02 Sat 18:13] =>  0:02
    :END:

As part of the move to github we should drop all of the legacy files. This also
includes the old build scripts from the shell.

*** COMPLETED Create clang build using libc++                         :story:
    :LOGBOOK:
    CLOCK: [2022-03-20 Sun 21:40]--[2022-03-20 Sun 22:16] =>  0:36
    :END:

At present we cannot build using clang. The main issue seems to be that dogen
code is using libc++ whereas the vcpkg dependencies are using the GCC standard
library. For now we can default to GCC's library and create a new story to use
clangs.

*** COMPLETED Rewrite CTest script to use github actions              :story:
    :LOGBOOK:
    CLOCK: [2022-04-02 Sat 15:30]--[2022-04-02 Sat 18:11] =>  2:41
    CLOCK: [2022-04-02 Sat 14:40]--[2022-04-02 Sat 15:29] =>  0:49
    CLOCK: [2022-04-02 Sat 11:20]--[2022-04-02 Sat 12:42] =>  1:22
    CLOCK: [2022-04-02 Sat 11:00]--[2022-04-02 Sat 11:19] =>  0:19
    CLOCK: [2022-04-01 Fri 21:47]--[2022-04-02 Sat 00:06] =>  2:19
    CLOCK: [2022-04-01 Fri 20:41]--[2022-04-01 Fri 21:15] =>  0:34
    CLOCK: [2022-04-01 Fri 20:00]--[2022-04-01 Fri 20:41] =>  0:41
    CLOCK: [2022-04-01 Fri 19:30]--[2022-04-01 Fri 19:50] =>  0:20
    CLOCK: [2022-04-01 Fri 16:05]--[2022-04-01 Fri 19:15] =>  3:10
    CLOCK: [2022-03-21 Mon 22:52]--[2022-03-21 Mon 23:33] =>  0:41
    CLOCK: [2022-03-20 Sun 20:56]--[2022-03-20 Sun 21:15] =>  0:19
    :END:

We need to re-write our existing CTest script to make it fit the GitHub actions
approach and integrate it with the lukka scripts.

Links:

- [[https://gitlab.kitware.com/cmake/cmake/-/issues/23383][23383: CTest: Integrating dashboards and Github Actions]]
- [[https://github.com/lukka/run-cmake/issues/73][#73: Integrating CMake actions with CDash and CTest]]

*Previous understanding*

At present we are not running the tests in github actions.

Notes:

- at present it seems the only advantage of the lukka cmake scripts is the
  setting up of the VCPKG caching.

*** COMPLETED Remove database options from help                       :story:
    :LOGBOOK:
    CLOCK: [2022-04-03 Sun 01:39]--[2022-04-03 Sun 01:46] =>  0:07
    :END:

We removed the relational model, but the options are still in the help.

*** COMPLETED Generate doxygen docs and add to site                   :story:
    :LOGBOOK:
    CLOCK: [2021-03-27 Sat 12:00]--[2021-03-27 Sat 13:14] =>  1:14
    CLOCK: [2021-03-23 Tue 20:10]--[2021-03-23 Tue 20:47] =>  0:37
    :END:

*Rationale*: we've got the basics working, with badge and manual uploading of
docs to the site. Create a new story for integrating this with CI.

Now we have a site, we could add the doxygen docs to it.

Notes:

- consider adding links in the source code to the PlantUML diagrams so
  that they come out in doxygen.
- add badge for documentation. Example:

#+begin_src markdown
[![Documentation](https://github.com/MASD-Project/dogen/blob/master/assets/doxygen_badge.svg)]
#+end_src

- add SVG of models to the docs.

Links:

- [[https://jothepro.github.io/doxygen-awesome-css/][doxygen-awesome-css]]: "Doxygen Awesome is a custom CSS theme for
  doxygen html-documentation with lots of customization parameters.W
- [[https://mcraveiro.github.io/dogen/doxygen/index.html][Dogen documentation]]
- [[https://www.reddit.com/r/cpp/comments/ma2r2r/dxoygen_awesome_css_make_your_doxygen_docs/][reddit: dxoygen (/sic./) awesome css : make your doxygen docs
  looking more modern]]
- [[https://github.com/jothepro/doxygen-awesome-css/issues/2][GH issue: Creating a link to the dark theme]]: opened a ticket about
  adding a link to the dark theme version.
- [[https://github.com/adafruit/ci-arduino/tree/master/assets][Example doxygen badge]]
- [[https://www.doxygen.nl/manual/config.html#cfg_image_path][doxygen: IMAGE_PATH]]
- [[https://www.doxygen.nl/manual/commands.html#cmdimage][doxygen: /image]]

*** COMPLETED Add packaging step to github actions                    :story:
    :LOGBOOK:
    CLOCK: [2022-04-02 Sat 18:25]--[2022-04-02 Sat 18:43] =>  0:18
    CLOCK: [2022-04-02 Sat 18:13]--[2022-04-02 Sat 18:16] =>  0:03
    :END:

We should really create packages for all builds. We need to also check that when
we tag we create packages.

Notes:

- we are packaging but we can't see the resulting files. Perhaps they only
  appear at the end of the workflow?

*** COMPLETED Setup MSVC Windows build for debug and release          :story:
   :LOGBOOK:
   CLOCK: [2022-04-03 Sun 14:00]--[2022-04-03 Sun 14:07] =>  0:07
   CLOCK: [2022-04-03 Sun 13:23]--[2022-04-03 Sun 13:27] =>  0:04
   CLOCK: [2022-04-03 Sun 12:48]--[2022-04-03 Sun 12:58] =>  0:10
   CLOCK: [2022-04-03 Sun 10:40]--[2022-04-03 Sun 11:30] =>  0:50
   CLOCK: [2022-04-03 Sun 01:24]--[2022-04-03 Sun 01:34] =>  0:10
   CLOCK: [2022-04-03 Sun 00:51]--[2022-04-03 Sun 00:57] =>  0:06
   CLOCK: [2022-04-03 Sun 00:20]--[2022-04-03 Sun 00:50] =>  0:30
   CLOCK: [2022-04-02 Sat 23:25]--[2022-04-02 Sat 23:40] =>  0:15
   CLOCK: [2022-04-02 Sat 22:23]--[2022-04-02 Sat 22:54] =>  0:31
   CLOCK: [2022-04-02 Sat 21:45]--[2022-04-02 Sat 21:57] =>  0:12
   CLOCK: [2022-04-02 Sat 18:44]--[2022-04-02 Sat 19:20] =>  0:36
   :END:

Notes:

- At present the Windows build seems to be using a mix of Ming and MSVC (but
  failing to find MSVC). We need to make sure both vcpkg and the build use MSVC.
- debug build has a config type of release. Use the release type consistently in
  case its causing other problems. Done.
- ccache is not creating the cache correctly on windows. Seems to work for MSVC
  now but not clang-cl. However, we never had a green build so that may be
  related. Wait until we have one to re-access.

Links:

- [[https://gitlab.kitware.com/cmake/cmake/-/issues/20222]["fatal error C1041" errors when using Ninja/MSVC and setting COMPILE_PDB_NAME]]

*** COMPLETED Can't see build info in github builds                   :story:
    :LOGBOOK:
    CLOCK: [2022-04-04 Mon 18:20]--[2022-04-04 Mon 18:34] =>  0:14
    CLOCK: [2022-04-03 Sun 14:30]--[2022-04-03 Sun 14:42] =>  0:12
    CLOCK: [2022-04-03 Sun 13:12]--[2022-04-03 Sun 13:21] =>  0:09
    :END:

In the past, =--version= showed the commit details etc from CI builds. It seems
that is no longer working.

*** COMPLETED Update build instructions in readme                     :story:
    :LOGBOOK:
    CLOCK: [2022-04-03 Sun 22:22]--[2022-04-03 Sun 22:35] =>  0:13
    CLOCK: [2022-04-03 Sun 14:43]--[2022-04-03 Sun 15:04] =>  0:21
    :END:

We should only support VCPKG builds now. Update docs.

*** COMPLETED Build =linux-clang-debug= fails in CTest step           :story:

Its not obvious why this build is failing. =llvm-cov= is probably returning
non-zero.

This was resolved by capturing the coverage exit status.

*** COMPLETED Replace Dia IDs with UUIDs                              :story:
    :LOGBOOK:
    CLOCK: [2022-04-08 Fri 22:18]--[2022-04-08 Fri 22:40] =>  0:22
    :END:

We still have lots of IDs in models from Dia:

:  :PROPERTIES:
:  :custom_id: O65
:  :END:

We need to update these to use UUIDs.

*** COMPLETED Update the test package scripts for the GitHub CI       :story:
    :LOGBOOK:
    CLOCK: [2022-04-08 Fri 22:03]--[2022-04-08 Fri 22:17] =>  0:14
    CLOCK: [2022-04-08 Fri 21:27]--[2022-04-08 Fri 21:52] =>  0:25
    :END:

We can probably install debian packages in GitHub CI. Try to see if we can run
the old package test scripts in GitHub.

*** COMPLETED Move codec related tests into codecs                    :story:
    :LOGBOOK:
    CLOCK: [2022-04-09 Sat 00:48]--[2022-04-09 Sat 01:50] =>  1:02
    :END:

At present we have tests that just convert from one codec to another but are
located in orchestration. These tests should live in the codec component.

Also, add tests for PlantUML.

*** STARTED Update nightly builds to use new vcpkg setup              :story:
    :LOGBOOK:
    CLOCK: [2022-04-04 Mon 18:48]--[2022-04-04 Mon 18:51] =>  0:03
    CLOCK: [2022-04-04 Mon 18:35]--[2022-04-04 Mon 18:47] =>  0:12
    :END:

At present we are still relying on the old vcpkg setup, with downloads from
dropbox etc. We need to move to the new world of presets.

Notes:

- update the compiler versions (e.g. =clang9-Linux-x86_64-Debug=, etc).

*** STARTED Assorted improvements to CMake files                       :epic:
    :LOGBOOK:
    CLOCK: [2022-04-08 Fri 21:17]--[2022-04-08 Fri 21:26] =>  0:09
    CLOCK: [2022-04-08 Fri 20:35]--[2022-04-08 Fri 20:45] =>  0:10
    CLOCK: [2022-04-08 Fri 17:00]--[2022-04-08 Fri 17:30] =>  0:30
    CLOCK: [2022-04-08 Fri 10:40]--[2022-04-08 Fri 12:37] =>  1:57
    CLOCK: [2022-04-08 Fri 09:24]--[2022-04-08 Fri 10:05] =>  0:41
    CLOCK: [2022-04-07 Thu 18:15]--[2022-04-07 Thu 19:30] =>  1:15
    CLOCK: [2022-04-07 Thu 16:01]--[2022-04-07 Thu 17:06] =>  1:05
    CLOCK: [2022-04-07 Thu 15:13]--[2022-04-07 Thu 15:26] =>  0:13
    CLOCK: [2022-04-07 Thu 14:34]--[2022-04-07 Thu 15:00] =>  0:26
    :END:

#+begin_src cmake
include(CheckIPOSupported)
check_ipo_supported(RESULT result)
if(result)
  set_target_properties(foo PROPERTIES INTERPROCEDURAL_OPTIMIZATION TRUE)
endif()

LINK_WHAT_YOU_USE
set(CMAKE_CXX_CLANG_TIDY "clang-tidy" "-checks=*")
<LANG>_CLANG_TIDY: CMake 3.6+
<LANG>_CPPCHECK
<LANG>_CPPLINT
<LANG>_INCLUDE_WHAT_YOU_USE

install(TARGETS MyLib
        EXPORT MyLibTargets
        LIBRARY DESTINATION lib
        ARCHIVE DESTINATION lib
        RUNTIME DESTINATION bin
        INCLUDES DESTINATION include
        )
#+end_src

*Previous understanding*

It seems we are not using proper CMake idioms to pick up compiler features, as
explained here:

- [[http://unclejimbo.github.io/2018/06/08/Modern-CMake-for-Library-Developers/][Modern CMake for Library Developers]]
- [[https://cliutils.gitlab.io/modern-cmake/][An Introduction to Modern CMake]]
- [[http://www.slideshare.net/DanielPfeifer1/cmake-48475415][CMake - Introduction and best practices]]
- [[https://datascience.dsscale.org/wp-content/uploads/2016/06/151208-LANL-Hoffman-Science.pdf][Building Science with CMake]]
- [[https://github.com/crezefire/cxp][CXP: C++ Cross Platform]]: A template project for creating a cross
  platform C++ CMake project using modern CMake syntax and transitive
  dependencies.
- [[https://cgold.readthedocs.io/en/latest/][CGold: The Hitchhiker’s Guide to the CMake]]
- [[https://polly.readthedocs.io/en/latest/index.html][Polly: Collection of CMake toolchains]]
- [[https://github.com/sblumentritt/cmake_modules][GH cmake_modules]]: "This repository provides a wide range of CMake
  helper files."

We need to implement this using proper CMake idioms.

Notes:

- Add version and language to project.
- start using [[https://cmake.org/cmake/help/v3.3/command/target_compile_options.html][target compile options]] for each target. We will have to repeat the
  same flags; this could be avoided by passing in a variable. See also [[http://stackoverflow.com/questions/23995019/what-is-the-modern-method-for-setting-general-compile-flags-in-cmake][What is
  the modern method for setting general compile flags in CMake?]]
- define qualified aliases for all libraries, including nested aliasing for
  =dogen::test_models=. Ensure all linking is done against qualified names.
- use target include directories for each target and only add the required
  include directories to each target. Mark them with the appropriate visibility,
  including using =interface=. We should then remove all duplication of
  libraries in the specs.
- try replacing calls to =-std=c++-14= with compiler feature detection. We need
  to create a list of all C++-14 features we're using.
- remove all of the debug/release compilation options and start using
  =CMAKE_BUILD_TYPE= instead. See [[http://pastebin.com/jCDW5Aa9][this]] example. We added build type support to
  our builds, but as a result, the binaries moved from =stage/bin= to =bin=.
  There is no obvious explanation for this.
- remove =STATIC= on all libraries and let users specify which linkage to use.
  We already have a story to capture this work.
- remove the stage folder and use the traditional CMake directories. This will
  also fix the problems we have with BUILD_TYPE.
- consider buying the CMake book: https://crascit.com/professional-cmake/.

Merged stories:

*Usage of external module path in cmakelists*                       :story:

It seems like we are not populating the target names
properly. Originally the target name for test model all built-ins was:

: dogen_all_builtins

When we moved the test models into =test_models= the target name did
not change. It should have changed to:

: dogen_test_models_all_builtins

*** STARTED Windows package is broken                                 :story:
    :LOGBOOK:
    CLOCK: [2022-04-08 Fri 17:31]--[2022-04-08 Fri 17:48] =>  0:17
    :END:

When we install the windows package under wine, it fails with:

#+begin_quote
E0fc:err:module:import_dll Library boost_log-vc143-mt-x64-1_78.dll (which is needed by L"C:\\Program Files\\DOGEN\\bin\\dogen.cli.exe") not found
00fc:err:module:import_dll Library boost_filesystem-vc143-mt-x64-1_78.dll (which is needed by L"C:\\Program Files\\DOGEN\\bin\\dogen.cli.exe") not found
00fc:err:module:import_dll Library boost_program_options-vc143-mt-x64-1_78.dll (which is needed by L"C:\\Program Files\\DOGEN\\bin\\dogen.cli.exe") not found
00fc:err:module:import_dll Library libxml2.dll (which is needed by L"C:\\Program Files\\DOGEN\\bin\\dogen.cli.exe") not found
00fc:err:module:import_dll Library boost_thread-vc143-mt-x64-1_78.dll (which is needed by L"C:\\Program Files\\DOGEN\\bin\\dogen.cli.exe") not found
00fc:err:module:LdrInitializeThunk Importing dlls for L"C:\\Program Files\\DOGEN\\bin\\dogen.cli.exe" failed, status c0000135
#+end_quote

This will probably be fixed when we move over to the new way of specifying
dependencies in CMake. Do that first and revisit this problem.

Actually, this did not help.

Links:

- [[https://github.com/microsoft/vcpkg/issues/1653][CMake: provide option to deploy DLLs on install() like VCPKG_APPLOCAL_DEPS
  #1653]]

*** STARTED Capitalise titles in models correctly                     :story:
    :LOGBOOK:
    CLOCK: [2022-04-08 Fri 23:11]--[2022-04-08 Fri 23:17] =>  0:06
    :END:

We still have models with lower case titles:

: * initializer                                                       :element:

Capitalise these correctly.

When we tried to do this to the dogen model, generation failed with the
following error:

: Error: Object has attribute with undefined type: spec_category

We are probably not normalising to lower case.

Merged stories:

*Capitalise model headers correctly*

At present most models still use the "all lower case" notation, copied from Dia.
We need to capitalise headers correctly so that when we generate documentation
they come out correctly.

*** STARTED Add full and relative path processing to PM               :story:
    :LOGBOOK:
    CLOCK: [2022-04-08 Fri 23:29]--[2022-04-08 Fri 23:41] =>  0:12
    :END:

We need to be able to generate full paths in the PM. This will require access to
the file extensions. For this we will need new decoration elements. This must be
done as part of the logical model to physical model conversion. While we're at
it, we should also generate the relative paths. Once we have relative paths we
should compute the header guards from them. These could be generalised to
"unique identifiers" or some such general name perhaps. That should be a
separate transform.

Notes:

- we are not yet populating the archetype kind in archetypes so we cannot locate
  the extensions. Also we did not create all of the required archetype kinds in
  the text models. The populating should be done via profiles.
- we must first figure out the number of enabled backends. The meta-model
  properties will always contain all backends, but not all of them are enabled.
- we need to populate the part directories. For this we need to know what parts
  are available for each backend (PMM), and then ensure the part properties have
  been created. We also need a directory for the part in variability. It is not
  clear we have support for this in the template instantiation domains - we
  probably only have backend, facet, archetype.
- guiding principle: there should be a direct mapping between the two
  hierarchical spaces: the definition meta-model of the physical space and its
  instances in the file-system.

Merged stories:

*Map archetypes to labels*

We need to add support in the PMM for mapping archetypes to labels. We may need
to treat certain labels more specially than others - its not clear. We need a
container with:

- logical model element ID
- archetype ID
- labels

*Implement locator in physical model*

Use PMM entities to generate artefact paths, within =m2t=.

*Create a archetypes locator*

We need to move all functionality which is not kernel specific into yarn for the
locator. This will exist in the helpers namespace. We then need to implement the
C++ locator as a composite of yarn locator.

*Other Notes*

At present we have multiple calls in locator, which are a bit ad-hoc. We could
potentially create a pattern. Say for C++, we have the following parameters:

- relative or full path
- include or implementation: this is simultaneously used to determine the
  placement (below) and the extension.
- meta-model element:
- "placement": top-level project directory, source directory or "natural"
  location inside of facet.
- archetype location: used to determine the facet and archetype postfixes.

E.g.:

: make_full_path_for_enumeration_implementation

Interestingly, the "placement" is a function of the archetype location (a given
artefact has a fixed placement). So a naive approach to this seems to imply one
could create a data driven locator, that works for all languages if supplied
suitable configuration data. To generalise:

- project directory is common to all languages.
- source or include directories become "project sub-directories". There is a
  mapping between the artefact location and a project sub-directory.
- there is a mapping between the artefact location and the facet and artefact
  postfixes.
- extensions are a slight complication: a) we want to allow users to override
  header/implementation extensions, but to do it so for the entire project
  (except maybe for ODB files). However, what yarn's locator needs is a mapping
  of artefact location to extension. It would be a tad cumbersome to have to
  specify extensions one artefact location at a time. So someone has to read a
  kernel level configuration parameter with the artefact extensions and expand
  it to the required mappings. Whilst dealing with this we also have the issue
  of elements which have extension in their names such as visual studio projects
  and solutions. The correct solution is to implement these using element
  extensions, and to remove the extension from the element name.
- each kernel can supply its configuration to yarn's locator via the kernel
  interface. This is fairly static so it can be supplied early on during
  initialisation.
- there is still something not quite right. We are performing a mapping between
  some logical space (the modeling space) and the physical space (paths in the
  filesystem). Some modeling elements such as the various CMakeLists.txt do not
  have enough information at the logical level to tell us about their location;
  at present the formatter itself gives us this hint ("include cmakelists" or
  "source cmakelists"?). It would be annoying to have to split these into
  multiple archetypes just so we can have a function between the archetype
  location and the physical space. Although, if this is the only case of a
  modeling element not mapping uniquely, perhaps we should do exactly this.
- However, we still have inclusion paths to worry about. As we done with the
  source/include directories, we need to somehow create a concept of inclusion
  path which is not language specific; "relative path" and "requires relative
  path" perhaps? These could be a function of archetype location.

Merged stories:

*Generate file paths as a transform*

We need to understand how file paths are being generated at present; they should
be a transform inside generation.

*Create the notion of project destinations*

At present we have conflated the notion of a facet, which is a logical concept,
with the notion of the folders in which files are placed - a physical concept.
We started thinking about addressing this problem by adding the "intra-backend
segment properties", but as the name indicates, we were not thinking about this
the right way. In truth, what we really need is to map facets (better: archetype
locations) to "destinations".

For example, we could define a few project destinations:

: masd.generation.destination.name="types_headers"
: masd.generation.destination.folder="include/masd.cpp_ref_impl.northwind/types"
: masd.generation.destination.name=top_level (global?)
: masd.generation.destination.folder=""
: masd.generation.destination.name="types_src"
: masd.generation.destination.folder="src/types"
: masd.generation.destination.name="tests"
: masd.generation.destination.folder="tests"

And so on. Then we can associate each formatter with a destination:

: masd.generation.cpp.types.class_header.destination=types_headers

Notes:

- these should be in archetypes models.
- with this we can now map any formatter to any folder, particularly if this is
  done at the element level. That is, you can easily define a global mapping for
  all formatters, and then override it locally. This solves the long standing
  problem of creating say types in tests and so forth. With this approach you
  can create anything anywhere.
- we need to have some tests that ensure we don't end up with multiple files
  with the same name at the same destination. This is a particular problem for
  CMake. One alternative is to allow the merging of CMake files, but we don't
  yet have a use case for this. The solution would be to have a "merged file
  flag" and then disable all other facets.
- this will work very nicely with profiles: we can create a few out of the box
  profiles for users such as flat project, common facets and so on. Users can
  simply apply the stereotype to their models. These are akin to "destination
  themes". However, we will also need some kind of "variable replacement" so we
  can support cases like =include/masd.cpp_ref_impl.northwind/types=. In fact,
  we also have the same problem when it comes to modules. A proper path is
  something like:
  - =include/${model_modules_as_dots}/types/${internal_modules_as_folders}=
  - =include/${model_modules_as_dots}/types/${internal_modules_as_dots}.=
  - =include/${model_modules_as_dots}/types/${internal_modules_as_underscores}_=

  This is *extremely* flexible. The user can now create a folder structure that
  depends on package names etc or choose to flatten it and can do so for one or
  all facets. This means for example that we could use nested folders for
  =include=, not use model modules for =src= and then flatten it all for
  =tests=.
- actually it is a bit of a mistake to think of these destinations as purely
  physical. In reality, we may also need them to contribute to namespaces. For
  example, in java the folders and namespaces must match. We could solve this by
  having a "module contribution" in the destination. These would then be used to
  construct the namespace for a given facet. Look for java story on backlog for
  this.
- this also addresses the issue of having multiple serialisation formats and
  choosing one, but having sensible folder names. For example, we could have
  boost serialisation mapped to a destination called =serialisation=. Or we
  could map it to say RapidJSON serialisation. Or we could support two methods
  of serialisation for the same project. The user chooses where to place them.

*** STARTED Add "verbatim" PlantUML extension                         :story:
    :LOGBOOK:
    CLOCK: [2022-04-09 Sat 02:19]--[2022-04-09 Sat 02:28] =>  0:09
    CLOCK: [2022-04-09 Sat 01:51]--[2022-04-09 Sat 02:19] =>  0:28
    CLOCK: [2022-04-08 Fri 23:42]--[2022-04-09 Sat 00:47] =>  1:05
    :END:

One very simple way to improve diagrams is to allow users to associate a
fragment of PlantUML code with a class, for example:

: masd.codec.plantuml: myclass <>-- other_class : test

This fragments are added after the class, verbatim. Its up to the users to
annotate diagrams as they see fit, we merely copy and paste these annotations.

In the future, we may spot patterns of usage that can be derived from meta-data,
but for now we just need the diagrams to be usable like they were in Dia.

Notes:

- notes are not indented at present.
- we are not leaving a space after inheritance.
- empty classes still have brackets.
- no top-level namespace for model. We didn't have this in Dia either.

 Tasks:

- add new feature in codec model.
- add properties in model and element to store the data.
- when converting into PlantUML, output the new properties after dumping the
  class.
- move codec to codec tests from orchestration to codec component.
- codec needs to have a way to bootstrap its context without requiring
  orchestration.

*** Make =parent= feature a CSV collection                            :story:

At present we declare multiple parents like so:

:    :masd.codec.parent: entities::Taggable, entities::Stereotypable, entities::Nameable, entities::Configurable, entities::DeterminableOrigin, entities::TaggableOverridable, entities::Commentable

This is a remnant of the Dia stereotypes field, which was one long CSV string.
However, in the Dia world it makes more sense for us to have:

:    :masd.codec.parent: entities::Taggable
:    :masd.codec.parent: entities::Stereotypable
:    :masd.codec.parent: entities::Nameable
:    :masd.codec.parent: entities::Configurable
: ...

This would make the org-mode document more readable. For this to work, we
probably just need to:

- make the field a CSV collection to allow for the transition without breaking
  anything.
- add processing in codec to handle the collection.

*** Consider making features dynamic elements                         :story:

At present we generate code to bake in features to the Dogen binary. However, in
a world where the PM is a dynamic entity, read out from core dogen models, it
seems the same should happen with features. As with profiles, we just need to
make sure these models are read out first before we start processing regular
model elements.

*** Rename backend to technical space                                 :story:

This is needed to make it compliant with the domain architecture.

*** Create a site for Dogen                                           :story:

- add papers as content.
- add blog posts as content.
- site is generated from org files in Dogen as a vcpkg build.
- add sprint and product backlog as content.
- add models.
- add release notes

Links:

- [[https://github.com/larstvei/org-bootstrap-document][GH: org-bootstrap-document]]: "This is a simple scheme for Org mode to generate
  nice and readable HTML sites. "

*** Create a DOI for dogen                                            :story:

As quantlib has done, we need to create a DOI for dogen.

#+begin_src md
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.1440997.svg)](https://doi.org/10.5281/zenodo.1440997)
#+end_src

CITATION.cff:

#+begin_quote
cff-version: 1.2.0
message: If you use this software, please cite it using these metadata.

title: "QuantLib: a free/open-source library for quantitative finance"
authors:
  - name: "The QuantLib contributors"
url: "https://www.quantlib.org/"
type: software
doi: 10.5281/zenodo.1440997
license: BSD-3-Clause
repository-code: "https://github.com/lballabio/QuantLib"
#+end_quote

Links:

- [[https://zenodo.org/record/5869144#.YlCksdDMKXJ][QuantLib: a free/open-source library for quantitative finance]]

*** Integrate Doxygen with CI                                         :story:

At present we are manually generating the docs and uploading them into our site.
We should instead:

- create a site specific to Dogen which is served from the dogen project - see
  site story.
- add a workflow that generates the doxygen docs and does nothing else. We need
  one for the tags and one for the commits.

Links:

- [[https://github.com/lballabio/QuantLib/blob/master/.github/workflows/doxygen.yml][QuantLib doxygen]]

*** Add target to check headers compile in isolation                  :story:

As per quantlib build, we should check headers compile in isolation.

Links:

- [[https://github.com/lballabio/QuantLib/blob/master/.github/workflows/headers.yml][quantlib header check workflow]]

*** Add target to check test timings                                  :story:

As per quantlib build, we should check for how long tests take to run.

Link:

- [[https://github.com/lballabio/QuantLib/blob/master/.github/workflows/test-times.yml][test-times quantlib workflow]]

*** Clang-cl build is broken                                          :story:

At present we are getting strange linking errors:

#+begin_quote
cmd.exe /C "cd . && D:\a\_temp\1259921409\cmake-3.23.0-windows-x86_64\bin\cmake.exe -E vs_link_exe --intdir=projects\dogen.utility\tests\CMakeFiles\dogen.utility.tests.dir --rc=C:\PROGRA~2\WI3CF2~1\10\bin\100220~1.0\x64\rc.exe --mt=C:\PROGRA~2\WI3CF2~1\10\bin\100220~1.0\x64\mt.exe --manifests  -- C:\PROGRA~1\LLVM\bin\lld-link.exe /nologo projects\dogen.utility\tests\CMakeFiles\dogen.utility.tests.dir\asserter_tests.cpp.obj projects\dogen.utility\tests\CMakeFiles\dogen.utility.tests.dir\comment_formatter_tests.cpp.obj projects\dogen.utility\tests\CMakeFiles\dogen.utility.tests.dir\file_tests.cpp.obj projects\dogen.utility\tests\CMakeFiles\dogen.utility.tests.dir\generators_tests.cpp.obj projects\dogen.utility\tests\CMakeFiles\dogen.utility.tests.dir\indenter_filter_tests.cpp.obj projects\dogen.utility\tests\CMakeFiles\dogen.utility.tests.dir\main.cpp.obj projects\dogen.utility\tests\CMakeFiles\dogen.utility.tests.dir\path_tests.cpp.obj projects\dogen.utility\tests\CMakeFiles\dogen.utility.tests.dir\resolver_tests.cpp.obj projects\dogen.utility\tests\CMakeFiles\dogen.utility.tests.dir\sha1_hasher_tests.cpp.obj projects\dogen.utility\tests\CMakeFiles\dogen.utility.tests.dir\splitter_tests.cpp.obj projects\dogen.utility\tests\CMakeFiles\dogen.utility.tests.dir\test_data_set_tests.cpp.obj projects\dogen.utility\tests\CMakeFiles\dogen.utility.tests.dir\utility_tests.cpp.obj projects\dogen.utility\tests\CMakeFiles\dogen.utility.tests.dir\xml_tests.cpp.obj  /out:stage\bin\dogen.utility.tests.exe /implib:stage\bin\dogen.utility.tests.lib /pdb:stage\bin\dogen.utility.tests.pdb /version:0.0 /machine:x64 /IGNORE:4217 /INCREMENTAL:NO /subsystem:console  stage\bin\dogen.utility.lib  vcpkg_installed\x64-windows\lib\libxml2.lib  vcpkg_installed\x64-windows\lib\boost_system-vc140-mt.lib  vcpkg_installed\x64-windows\lib\boost_serialization-vc140-mt.lib  vcpkg_installed\x64-windows\lib\boost_date_time-vc140-mt.lib  vcpkg_installed\x64-windows\lib\boost_log-vc140-mt.lib  vcpkg_installed\x64-windows\lib\boost_thread-vc140-mt.lib  vcpkg_installed\x64-windows\lib\boost_filesystem-vc140-mt.lib  vcpkg_installed\x64-windows\lib\boost_program_options-vc140-mt.lib  vcpkg_installed\x64-windows\lib\boost_unit_test_framework-vc140-mt.lib  vcpkg_installed\x64-windows\lib\boost_regex-vc140-mt.lib  vcpkg_installed\x64-windows\lib\boost_chrono-vc140-mt.lib  vcpkg_installed\x64-windows\lib\boost_atomic-vc140-mt.lib  vcpkg_installed\x64-windows\lib\boost_log_setup-vc140-mt.lib  vcpkg_installed\x64-windows\lib\zlib.lib  kernel32.lib user32.lib gdi32.lib winspool.lib shell32.lib ole32.lib oleaut32.lib uuid.lib comdlg32.lib advapi32.lib && cmd.exe /C "cd /D D:\a\dogen\dogen\build\output\windows-msvc-clang-cl-debug\projects\dogen.utility\tests && "C:\Program Files\PowerShell\7\pwsh.exe" -noprofile -executionpolicy Bypass -file D:/a/dogen/dogen/vcpkg/scripts/buildsystems/msbuild/applocal.ps1 -targetBinary /.../windows-msvc-clang-cl-debug/stage/bin/dogen.utility.tests.exe -installedDir /.../windows-msvc-clang-cl-debug/vcpkg_installed/x64-windows/bin -OutVariable out""
LINK: command "C:\PROGRA~1\LLVM\bin\lld-link.exe /nologo projects\dogen.utility\tests\CMakeFiles\dogen.utility.tests.dir\asserter_tests.cpp.obj projects\dogen.utility\tests\CMakeFiles\dogen.utility.tests.dir\comment_formatter_tests.cpp.obj projects\dogen.utility\tests\CMakeFiles\dogen.utility.tests.dir\file_tests.cpp.obj projects\dogen.utility\tests\CMakeFiles\dogen.utility.tests.dir\generators_tests.cpp.obj projects\dogen.utility\tests\CMakeFiles\dogen.utility.tests.dir\indenter_filter_tests.cpp.obj projects\dogen.utility\tests\CMakeFiles\dogen.utility.tests.dir\main.cpp.obj projects\dogen.utility\tests\CMakeFiles\dogen.utility.tests.dir\path_tests.cpp.obj projects\dogen.utility\tests\CMakeFiles\dogen.utility.tests.dir\resolver_tests.cpp.obj projects\dogen.utility\tests\CMakeFiles\dogen.utility.tests.dir\sha1_hasher_tests.cpp.obj projects\dogen.utility\tests\CMakeFiles\dogen.utility.tests.dir\splitter_tests.cpp.obj projects\dogen.utility\tests\CMakeFiles\dogen.utility.tests.dir\test_data_set_tests.cpp.obj projects\dogen.utility\tests\CMakeFiles\dogen.utility.tests.dir\utility_tests.cpp.obj projects\dogen.utility\tests\CMakeFiles\dogen.utility.tests.dir\xml_tests.cpp.obj /out:stage\bin\dogen.utility.tests.exe /implib:stage\bin\dogen.utility.tests.lib /pdb:stage\bin\dogen.utility.tests.pdb /version:0.0 /machine:x64 /IGNORE:4217 /INCREMENTAL:NO /subsystem:console stage\bin\dogen.utility.lib vcpkg_installed\x64-windows\lib\libxml2.lib vcpkg_installed\x64-windows\lib\boost_system-vc140-mt.lib vcpkg_installed\x64-windows\lib\boost_serialization-vc140-mt.lib vcpkg_installed\x64-windows\lib\boost_date_time-vc140-mt.lib vcpkg_installed\x64-windows\lib\boost_log-vc140-mt.lib vcpkg_installed\x64-windows\lib\boost_thread-vc140-mt.lib vcpkg_installed\x64-windows\lib\boost_filesystem-vc140-mt.lib vcpkg_installed\x64-windows\lib\boost_program_options-vc140-mt.lib vcpkg_installed\x64-windows\lib\boost_unit_test_framework-vc140-mt.lib vcpkg_installed\x64-windows\lib\boost_regex-vc140-mt.lib vcpkg_installed\x64-windows\lib\boost_chrono-vc140-mt.lib vcpkg_installed\x64-windows\lib\boost_atomic-vc140-mt.lib vcpkg_installed\x64-windows\lib\boost_log_setup-vc140-mt.lib vcpkg_installed\x64-windows\lib\zlib.lib kernel32.lib user32.lib gdi32.lib winspool.lib shell32.lib ole32.lib oleaut32.lib uuid.lib comdlg32.lib advapi32.lib /MANIFEST /MANIFESTFILE:stage\bin\dogen.utility.tests.exe.manifest" failed (exit code 1) with the following output:
lld-link: error: undefined symbol: __declspec(dllimport) public: void __cdecl boost::archive::archive_exception::`vbase dtor'(void)
>>> referenced by projects\dogen.utility\tests\CMakeFiles\dogen.utility.tests.dir\asserter_tests.cpp.obj:(int `public: static void __cdecl boost::archive::save_access::save_primitive<class boost::archive::xml_oarchive, int>(class archive::save_access::xml_oarchive &, int const &)'::`1'::dtor$3)
>>> referenced by projects\dogen.utility\tests\CMakeFiles\dogen.utility.tests.dir\asserter_tests.cpp.obj:(int `protected: void __cdecl boost::archive::xml_iarchive_impl<class boost::archive::xml_iarchive>::load_override<class boost::serialization::nvp<int> const>(class archive::serialization::nvp<int> const &)'::`1'::dtor$3)
#+end_quote

This will probably be fixed when we move over to the new way of specifying
dependencies in CMake. Do that first and revisit this problem.

*** Create clang build using libc++                                   :story:

At present we cannot build using clang and libc++. The main issue seems to be
that dogen code is using libc++ whereas the vcpkg dependencies are using the GCC
standard library. For now we defaulted to GCC's library but the right fix is to
use libc++.

Links:

- [[https://github.com/microsoft/vcpkg/issues/9783][#9783: Add example for using libc++ on Linux]]

*** Reference implementation build is borked                          :story:

We need to upgrade the ODB version of the reference implementation. Annoyingly
this will mean hitting the usual issues with vcpkg. We should probably consider
deprecating ODB from the reference implementation as well, or at least disabling
the building of the generated ODB code.

*** Add github actions build for C#                                   :story:

We need to build on .Net 6.

*** Upload release to github on tags                                  :story:

At present we are manually uploading binaries on a release to github. It would
be nice to integrate this with CI.

Links:

- [[https://gist.github.com/stefanbuck/ce788fee19ab6eb0b4447a85fc99f447][upload-github-release-asset.sh]]
- [[https://developer.github.com/v3/repos/releases/#upload-a-release-asset][Upload a release asset]]

*** Consider standardising all templates as mustache templates        :story:
    :LOGBOOK:
    CLOCK: [2022-03-20 Sun 09:18]--[2022-03-20 Sun 09:39] =>  0:21
    :END:

At present we have a somewhat complex story with regards to templating:

1. we use a mustache-like approach called wale, built in-house. It is used for
   some header files such as the M2T transforms.
2. we use a t4-like approach called stitch, also in-house. It is used for the
   implementation of the M2T transforms.

What would be really nice is if we could use the same approach for both, and if
that approach was not part of Dogen. The purpose of this story is to explore the
possibility of replacing both with a standard implementation of mustache,
ideally available on vcpkg. We already have a story for replacing wale with
mustache in the backlog, so see that for the choice of implementation. This
story concerns itself mainly with the second item in the above list; that is,
can we replace stitch with mustache.

In order to answer this question we first must try to figure out what the
differences between T4 and mustache are. T4 is a "generator generator". That is,
the text template generates C# code that generates the ultimate target of the
template. This means it is possible to embed any logic within the T4 template as
required, to do complex processing. It also means the processing is "fast"
because we generate C# code rather than try to introspect at run time. Stitch
uses the same approach. However, after many years of using both T4 and Stitch,
the general conclusion has been that the templates should be kept as simple as
possible. The main reason is that "debugging" through the templates is
non-trivial, even though it is simple C++ code (in the case of stitch).

Mustache on the other hand puts forward an approach of logic-less templates.
That is, the templates are evaluated dynamically by the templating engine, and
the engine only allows for a very limited number of constructs. In some
implementations, the so called "template hash", that is the input to the
template, is a JSON object. All the template can do is refer to entries in the
JSON object and replace tokens with the values of those entries.

Until recently we deemed mustache to be too simple for our needs because Dogen
templates were very complex. However, several things have changed:

- we do not want the templates to have any indentation at all; this should be
  left to clang-format as a subsequent T2T transform. This removes a lot of
  functionality we had in Stitch.
- we do not want the logical model objects to be processed any further in the
  template. As explained above this leads to a lot of complications. We want the
  object to be in its final form.
- we want all relationships etc to be encoded in the logical model object prior
  to M2T transformation.

In other words, we have slowly been converging towards logic-less templates,
though we are not yet there. The main stumbling blocks are:

- epilogue and prologue are at present handled by assistants:

#+begin_src
    text::formatters::assistant ast(lps, e, a, true/*requires_header_guard*/);
    const auto& o(ast.as<logical::entities::structural::object>(e));

    {
        auto sbf(ast.make_scoped_boilerplate_formatter(o));
        {
            const auto ns(ast.make_namespaces(o.name()));
            auto snf(ast.make_scoped_namespace_formatter(ns));
#>

class <#= o.name().simple() #>;

<#+
        } // snf
#>

<#+
    } // sbf

#+end_src

   Ideally we should just have a way to ask for the values of these fields.
- we need to investigate all templates and see if a JSON representation of a
  logical model element is sufficient to capture all required information.
  However the best way to do this is to have an incremental approach: provide a
  mustache based M2T and then incrementally move each M2T at a time.

If we do move to mustache, there are lots of advantages:

- remove all of templating code.
- we could allow users to supply their own mustache templates in a model. We can
  even allow for the dynamic creation of PMM elements and then the association
  of those elements with templates. End users cannot of course extend the LMM,
  but even just extending the LMM gives them a lot of power.
- we could create a stand alone tool that allows users to play with templates.
  All they need is a dump of the JSON representation of the objects in their
  model (this could be an option in Dogen). Then the tool can take the template
  and the JSON and render it to =std::out=. This makes template development much
  easier. If we integrate it with Emacs, we could even have a view where we
  do: 1) JSON 2) template 3) output. Users can then change 1) and 2) and see the
  results in 3). We don't even have to extend emacs for this, we could just use
  the compilation command.

Notes:

- if we could create JSON schemas for the LMM, we could then allow users to
  create their own JSON representations. Not sure how useful this would be.
- we need JSON support in Dogen for this.
- we need to measure how much slower Dogen would be with this approach.
  Presumably mustache is a lot slower that Stitch.
- from this perspective, the PMM is fixed but the PM then becomes a dynamic
  entity. We can supply a PM model with Dogen but that is just Dogen's
  interpretation of the physical space; users could supply their own PM's as
  required. The PMs need to bind to the PMM: either the user supplies its own
  TS, part etc or it must bind (via meta-data) to existing parts, TS etc. We
  also need to support two styles of declaring PM entities: inline (e.g. nested)
  or outline (e.g. we want to bind a given facet, part etc to an already
  existing TS, etc).
- we could hash both the mustache template and the JSON object used as input,
  and save those two hashes in the generated file. If the hashes match, don't
  bother regenerating.

Links:

- [[https://en.wikipedia.org/wiki/Text_Template_Transformation_Toolkit][wikipedia: Text Template Transformation Toolkit]]

*** Improve vcpkg integration for generated code                      :story:

If the user requests, we should also generate a vcpkg project that is
a clone of vcpkg but builds all of the base dependencies and pushes
them to a known location (e.g. GCS). Then, the build steps should
first download from that known location and put it on the path. It
should be trivial to update the vcpkg clone, e.g.: user adds new vcpkg
dependency to the model; dogen updates the data file, user commits the
update, new vcpkg build is triggered and generates new vcpkg zip, with
a stamp. User updates model to point to the new stamp and pushes. Next
build will use new vcpkg libraries. Ideally vcpkg builds for all
supported platforms (this is requested in the product model).

Links:

- [[https://devblogs.microsoft.com/cppblog/vcpkg-accelerate-your-team-development-environment-with-binary-caching-and-manifests/][vcpkg: Accelerate your team development environment with binary
  caching and manifests]]

*** Look at warnings in lgtm                                          :story:

We seem to have a number of code quality warnings, check them and fix the
important ones.

Links:

- [[https://lgtm.com/projects/g/MASD-Project/dogen/alerts/?mode=list][lgtm warnings]]

*** org-to-org transform removes custom id's from attributes          :story:

Diff of =share/library/masd.org= after transform:

:
:  *** mode                                                          :attribute:
:      :PROPERTIES:
: -    :custom_id: 4e770d9b-44b4-4a6d-8504-49629f4d29c1
:      :masd.codec.value: c++
:      :END:

We should always preserve all attributes.

*** Process org-mode image links                                      :story:

At present we have hard-coded doxygen notation for image links:

: \image html dogen.orchestration/modeling/dogen.orchestration.svg

Instead, we should use org-mode notation for these links:

: #+CAPTION: This is the caption for the next figure link (or table)
: #+NAME:   fig:SED-HR4049
: [[./img/a.jpg]]

These then need to be read out by the org-mode parser and converted internally
into doxygen links.

Links:

- [[https://orgmode.org/manual/Images.html][org-mode manual: images]]

*** org-to-org transform creates mustache templates incorrectly       :story:

At present we determine the language for the block by looking at the name of the
property. If its called =content= we use =mustache=. However, if a user creates
a field called =content= this should not kick in. We should have a configuration
option at the model level that enables this "intelligent" behaviour, and enable
it only for the =dogen.text= model.

: *** content                                                       :attribute:
:    :PROPERTIES:
:    :masd.codec.type: std::string
:    :END:
:
: #+begin_src mustache
: Contents of the artefact.
: #+end_src

*** Consider integrating org-spec with org-model                      :story:

#+begin_quote
An Org-mode template for technical specification documents and HTML publishing
#+end_quote

It would be nice to generate models that can produce org-spec HTML output.

Links:

- [[https://github.com/thi-ng/org-spec][org-spec GH]]

*** Change file format of tracing dumps according to codec            :story:

At present we always dump the transform inputs and outputs as =.json=. However,
if the content is in org-mode format, it would make more sense to have a =.org=
extension. The transform doing the dump should override the extension.

*** Logical model still has a traits class                            :story:

These should all have been removed, but its still there:

: #include "dogen.logical/types/traits.hpp"

O*** Rename merger to model compiler or weaver                         :story:

What we call "merging" is really the job of the "model compiler". We
should rename these transforms accordingly. The model compiler weaves
the models together. We can just rename the merger to these
terms. Literature:

#+begin_quote
A model compiler takes a set of executable UML models and weaves them
together according to a /consistent set of rules/. This task involves
executing the mapping functions between the various source and target
models to produce a single all-encompassing metamodel [...] that
includes all the structure, behavior and logic --- everything --- in
the \marginpar{Weaving, model compilers} system. [...] Weaving the
models together at once addresses the problem of architectural
mismatch, a term coined by David Garlan to refer to components that do
not fit together without the addition of tubes and tubes of glue code,
the very problem MDA is intended to avoid! A model compiler imposes a
single architectural structure on the system as a whole.
#+end_quote

*** Limitations of the current org-mode approach                      :story:

At present we decided to implement org-mode support directly in Dogen,
which has some advantages:

- we can process org-mode documents without having Emacs - e.g. you
  can create documents in other editors and still benefit from
  Dogen support.

However, there are also problems:

- org-mode is very complex. We don't want to support only a partial
  subset of the format; we want users to create regular org-mode
  documents with all of the org-mode functionality and then have them
  exported into code. This means our parser has to be very clever.
- we want to be able to export the model to other formats such as HTML
  / PDF etc. This means the document may contain all sorts of weird
  and wonderful config for those formats which we do not care about.
- we want users to add sections for documentation purposes such as
  images, etc. These won't necessarily be used for Dogen.

All of this makes us think we may have taken the wrong approach. We
should instead support some well-defined intermediary format which can
be understood by Dogen unequivocally, and which has a "trivial"
parsing implementation, similar to Dia XML. Then:

- we can then create an org-mode exporter in elisp which uses the
  existing org-mode functionality to determine what should be
  converted and what should be ignored.
- with this we can be confident that the org-mode document is handled
  correctly.

There are downsides though:

- third-party editors will no longer be supported - they will require
  their own exporter code, and most do not support this.
- there are more steps to the process, which is particularly annoying
  when you have several models. You now need to ensure you have exported
  them all, else you may get strange errors.
- the format must support mapping to the original locations so that we
  can still support LSP with proper errors, etc.

*** Add minor mode in emacs that finds element location               :story:

It would be nice to be able to run a command in emacs that opens the
model element associated with the current file.

*** Allow setting colours and visibility on PlantUML relations        :story:

When we start to model all relations on diagrams, they will become
quite confusing. However, we could probably make things easier by
allowing users to decide what colour to add to a relation and also if
they should be visible or not. These can be supplied as meta-data.

From [[https://plantuml.com/class-diagram#8dfb3b05fc895d2b][PlantUML docs]]:

#+begin_quote
You can change the color or style of individual relation or arrows
using the inline following notation:

: #color;line.[bold|dashed|dotted];text:color
#+end_quote

#+begin_src plantuml :file my-diagram.png
@startuml
class foo
foo --> bar : normal
foo --> bar1 #line:red;line.bold;text:red  : red bold
foo --> bar2 #green;line.dashed;text:green : green dashed
foo --> bar3 #blue;line.dotted;text:blue   : blue dotted
@enduml
#+end_src

#+RESULTS:
[[file:my-diagram.png]]

Notes:

- we need to have an additional property to model the comments on the
  link, supplied by meta-data.
- we could also have different colours for each comment type:
  - source comments.
  - user comments for diagram only (not supported yet).

*** Add support for "diagram-only" comments                           :story:

We may want to add documentation for the purposes of the model that we
do not want expressed in code. It would be nice to be able to mark
some comments as "diagram-only".

*** Parse org-mode syntax in comment                                  :story:

At present we are expecting users to use doxygen mark up in the
model. This is not ideal:

- if we generate say C++ and C# the markup is invalid in one.
- if we generate HTML/PDFs the markup looks weird.

We should expect documents to have org markup only and then interpret
it in the generation. We probably only need a few items:

- lists
- =code variables=
- /italics/ and _underscores_
- links.

*** Org roundtrip does not add blank line at the end of document      :story:

Errors:

#+begin_src
FAILED: projects/dogen.orchestration/tests/CMakeFiles/run_dogen.orchestration.tests
cd /work/DomainDrivenConsulting/masd/dogen/integration/build/output/clang11/Release/stage/bin && /work/DomainDrivenConsulting/masd/dogen/integration/build/output/clang11/Release/stage/bin/dogen.orchestration.tests --log_level=error
Running 156 test cases...
Conversion generated differences: "/work/DomainDrivenConsulting/masd/dogen/integration/projects/dogen/modeling/dogen.org"
@@ -494,3 +494,4 @@
   :END:

 An error ocurred when dumping dogen's specs.
+

../../../../projects/dogen.orchestration/tests/dogen_org_product_tests.cpp(188): error: in "dogen_product_org_tests/dogen_org_conversion_has_no_diffs": check diff.empty() has failed
Conversion generated differences: "/work/DomainDrivenConsulting/masd/dogen/integration/projects/dogen.cli/modeling/dogen.cli.org"
@@ -181,3 +181,4 @@
    :END:

 Which style to use when dumping the specs.
+

../../../../projects/dogen.orchestration/tests/dogen_org_product_tests.cpp(202): error: in "dogen_product_org_tests/dogen_cli_org_conversion_has_no_diffs": check diff.empty() has failed
Conversion generated differences: "/work/DomainDrivenConsulting/masd/dogen/integration/projects/dogen.logical/modeling/dogen.logical.org"
@@ -4668,3 +4668,4 @@
    :END:

 An error has occurred while formatting.
+

../../../../projects/dogen.orchestration/tests/dogen_org_product_tests.cpp(244): error: in "dogen_product_org_tests/dogen_logical_org_conversion_has_no_diffs": check diff.empty() has failed

3 failures are detected in the test module "dogen.orchestration.tests"
ninja: build stopped: subcommand failed.
Error running CMake.

Compilation exited abnormally with code 1 at Sun Apr 11 20:15:01
Elapsed: 00:00:13.738
#+end_src

*** Simplistic renaming based on GUIDs                                :story:

One really simple way of renaming classes would be to have the UUID in
the comments (ideally the boilerplate) of each file. We could then
have a pre-generation step that reads in all the files and maps them
to an ID. Then, if a file is handcrafted, we could use the contents
instead of creating a blank file.

Notes:

- we could possibly also do some minor hackery such as search /
  replace the old namespace with the new namespace, and the old class
  name with the new class name though that would be much more
  dangerous. On the plus side, git would likely detect the rename
  which would mean we could then diff.
- we could possibly also issue the git rename commands for the
  affected files.
- note that generated files would not be part of this simplistic
  renaming.
- most of the work could be carried out in the physical model.
- one assumption here is that all handcrafted files are originally
  generated with their GUIDs and users must not delete them.
- this makes one wonder if we should not create a type of files that
  are "partially generated". That is, we could allow users freedom
  within some bounds but the "header" and "footer" of the file must
  always be generated by Dogen. This would guarantee the correct
  namespaces, header guards, etc. Perhaps we could make this an
  option:

  - fully generated
  - header and footer generation
  - skeleton generation as a one-off.

*** Generation statistics                                             :story:

It would be very useful to know percentages of generated code versus
hand-crafted code. We already have a report which groups files, we can
add to that report.

*** Remove commas from PlantUML enums                                 :story:

We don't need to add commas to separate PlantUML enums.

*** Fix PlantUML namespace comments                                   :story:

At present the comments appear as a link to the namespace. We should
try to do whatever it is we did for the model comment, which looks
like a regular note at the top of the namespace.

In addition, sub-namespaces seem to generate both a class with the
comment as well as the namespace itself (see text model).

*** Create a local resolver in codec to support PlantUML use case     :story:

We can create most of the links in PlantUML via local resolution. We
could create a local resolver, which only looks at types for the
current model. It lives inside of codec. For those types, if it
resolves, we can create the PlantUML link. In addition, we could also
resolve operations in the same way (once they have been
modeled).

Ideally, we should implement this resolve in such a way that it can be
used for merged models and stand alone models. We created a story on
the new approach for the resolver; we need to have a look at that and
see if it can be implemented as part of this work. For example, we
could flatten all names prior to calling resolver; use a GUID against
each type, read from custom ID in org mode.

The resolver needs to be primed with all of the existing model names
and namespaces, without depending on the qualified names data
structure. It should have its own data structures. It could live in
=identification=. The output of the resolver should be the GUID of the
type the name points to, or nothing if it could not resolve.

In the calling models, we need a transform that decomposes a type into
the names it references. Then, for each name, we call the resolver.

Notes:

- we could also create two step resolution. We could resolve all local
  names first, and mark them as resolved (for example by adding the
  UUID of the resolved type to the name) and leaving unresolved types
  unmarked. Then, the second merged model resolution would only
  resolve types which are not yet resolved. This would probably speed
  things up because we may end up with smaller containers.

*** Generate PNGs for PlantUML models                                 :story:

At present we are generating SVGs for the Plant UML models. This is
not ideal because emacs does not process them very well. Also, we are
checking in the SVG. We probably don't need to do that, nor do we need
to check in the Plant UML source, but it does offer an easy way to
check for regressions. At any rate, we should just have a CMake target
that creates the PNGs in the build output directory, and open those in
emacs with tabs and scroll bars.

*** Fix PlantUML indentation                                          :story:

At present if we indent a diagram in emacs we get a different
indentation compared to the generated one. We need to either get emacs
to indent correctly, or copy the emacs indentation. The main problem
at present is that we are indenting classes correctly in generated
code:

#+begin_src plantuml
namespace entities #F2F2F2 {
    class section #F7E5FF {
        +{field} blocks std::list<block>
    }
}
#+end_src

Whereas emacs does not:

#+begin_src plantuml
@startuml

namespace entities #F2F2F2 {
    class section #F7E5FF {
        +{field} blocks std::list<block>
    }
}
@enduml
#+end_src

Note that the behaviour seems different in org-babel. Note also that
notes have incorrect indentation (text model, inside a namespace):

#+begin_src plantuml
note top of  transformation_error
An error occurred whilst applying a transformation.
end note
#+end_src

Note also the extra space before exception name, as well as the
missing indentation inside the note.

Actually what is causing the problem with emacs indentation is the use
of top-level notes:

#+begin_src plantuml
note as N1
Contains all of the M2T transforms for all supported backends.
end note
#+end_src

We need to investigate why this causes indentation problems. Seems
like its valid syntax.

Note also that all comments are not indented correctly.

*** Consider creating a "top-level" group in PlantUML                 :story:

There are a number of classes that always show up at the top:

- registrar
- cmakelists
- main
- etc

These could also be part of a top-level group.

We could also have a group for logic-less templates if they are at the
top-level.

*** Consider adding operations for PlantUML                           :story:

We don't need full operation support for it to be useful. We could
have minimal support and use it to update the UML diagrams. It would
then later on be extended for merging code generation.

*** Empty classes do not need brackets in PlantUML                    :story:

At present we are still adding start and end brackets to empty classes:

#+begin_src plantuml
class string_to_document_transform <<dogen::handcrafted::typeable>> #FFFACD {
}
#+end_src

This takes space for no reason. We could just not print those brackets.

*** Consider creating a product PlantUML diagram                      :story:

Once we have support for product models, we should be able to create a
composite Plant UML diagram of the entire product, with linkages for
all types within the product. This means we should keep this use case
in mind when we resolve the problems we currently have with
associations intra-model.

*** Partial information extraction from logical model                 :story:

Since we just need generalisation and association information, we
could probably create a specialised chain in the logical model that
gives us the bare minimum to populate the relevant properties; we can
then extract those and map them to the codec ID. We should also make
the codec ID mandatory and use a map for the codec elements. The
orchestration model is responsible for stitching the information.

*** org-model and links to references                                 :story:

At present we are adding links as part of the drawers in
org-models. However, this is not ideal. We want to use regular
org-mode constructs. There are several use cases for links:

- we want org-mode links so that we can make use of tools such as
  org-roam.
- we need to use the links for dogen to resolve the model. Both of
  these use cases happen whilst the code is in its normal shape in the
  git repository.
- when we generate doxygen documentation we need links that can work
  when the site has been published. At this point the models have all
  been copied to a different location by doxygen.

We need to find out a way to make links work for all of these use cases.

*** PlantUML and hyperlinks                                           :story:

Apparently it is possible to embed HTTP links in SVG diagrams. This
means it may also be possible to supply these as inputs in the
PlantUML model. If so, it would be nice to be able to find the model
definition of an element by clicking on the element. Its not clear if
this would work in the SVG support we have in Emacs.

Links:

- [[https://alligator.io/svg/hyperlinks-svg/][Hyperlinks/Anchors Inside SVG Graphics]]

*** Type that references itself results in a recursive include        :story:

In org-mode headline we seem to be including the headline itself:

: #include "dogen.org/types/entities/headline.hpp"

In the associations transform, we could do a quick check: if a type
references itself, the remove the association.

*** Use a Dogen drawer instead of properties                          :story:

Its possible users will want to add their own drawers to Dogen
documents. For example, maybe you want to clock against model items or
use org-brain. We need to preserve all of these entries when
roundtripping. The easiest way to achieve that is to try to separate
the Dogen information from the non-Dogen one. If we had our own
drawers it would be much easier, we could simply state that you are
not allowed to add any non-Dogen stuff there and copy across the Dogen
drawer into the original document.

We could keep the element ID as a =CUSTOM_ID= in the =PROPERTIES=
drawer though as that is a org concept.

*** Org Roundtripping is lossy at present                             :story:

One way to roundtrip documents without losing information is to
preserve the original org document, run the Dogen transforms (for
example to obtain the generalisation and association information),
transform that back into an org-model and then copy over the dogen
elements into the original org document by performing lookups based on
element ID. This way we ensure we do not lose any information of the
original model. The way we are roundtripping at present, if you add
any non-Dogen headlines, these would be dropped on the round trip.

In fact, its like we need a "merge algorithm" to merge the source
document with the roundtripped document.

*** Copy org documentation from rust implementations                  :story:

The rust module for org-mode seems very well documented. We should try
to copy across all applicable documentation.

Links:

- [[https://github.com/org-rs/org-rs/blob/master/rust/element/src/headline.rs][org-rs headline example]]

*** Consider adding support for "literate testing"                    :story:

It would be nice if we could create an org-mode file specifying a
test, then add the code as an orb-babel clock and then tangle the file
into a c++ file. Ideally the tangling should be done by Dogen (as well
as by org-mode).

Actually, we don't need a separate org-mode file, this is just the
class definition for the test fixture.

Links:

- [[https://github.com/jkitchin/org-ref/blob/master/test/all-org-test.org][all-org-test.org]]: literate test from org-ref.

*** Documentation as the aggregate model view                         :story:

It would be really nice if we could "merge" different types of
documentation, all written using org-mode:

- user manual
- developer manual, which is the aggregation of the product model and
  all the component models.

These should create two separate PDFs. We should also be able to
create a dynamic site for the product by just pointing to the git
repository of the project.

*** Reporting with diffs                                              :story:

At present its possible to create a diff with dry run and diffing
enabled or to do a report showing all operations - which produces an
org-mode report. However, what would be nice, especially when testing
is to merge the two: create a report that also includes the diffs.

Links:

- [[https://github.com/MASD-Project/dogen/releases/tag/v1.0.12][Sprint 12]]: introduction of reporting.

** Deprecated
*** CANCELLED Enable relational model locally                         :story:

*Rationale*: we removed the relational model.

At present we are not building locally the relational model. We need to ensure
we are not breaking this code.

*** CANCELLED Benchmarks do not work for utility tests                :story:

*Rationale*: removed benchmark support.

When we run the benchmarks for utility we get an error:

: Running 95 test cases...
: /home/marco/Development/DomainDrivenConsulting/dogen/projects/utility/tests/asserter_tests.cpp(141): error: in "asserter_tests/assert_directory_good_data_set_returns_true": check asserter::assert_directory(e, a) has failed

Seems like the tests do not clean up after themselves. We need to add
some clean up logic and re-enable the tests. We probably should just
remove all of the benchmarks infrastructure, given we never use it and
it has probably bit-rotted by now.
