#+title: Sprint Backlog 06
#+options: date:nil toc:nil author:nil num:nil
#+todo: STARTED | COMPLETED CANCELLED POSTPONED
#+tags: { story(s) epic(e) }

* Mission Statement

- Finish moving enablement and dependencies into yarn.
- Start sorting out object templates and profiles.

* Stories

** Active

#+begin: clocktable :maxlevel 3 :scope subtree :indent nil :emphasize nil :scope file :narrow 75 :formula %
#+CAPTION: Clock summary at [2017-11-03 Fri 11:33]
| <75>                                                                        |         |       |       |       |
| Headline                                                                    | Time    |       |       |     % |
|-----------------------------------------------------------------------------+---------+-------+-------+-------|
| *Total time*                                                                | *50:38* |       |       | 100.0 |
|-----------------------------------------------------------------------------+---------+-------+-------+-------|
| Stories                                                                     | 50:38   |       |       | 100.0 |
| Active                                                                      |         | 50:38 |       | 100.0 |
| COMPLETED Edit release notes for previous sprint                            |         |       |  2:19 |   4.6 |
| STARTED Sprint and product backlog grooming                                 |         |       |  2:08 |   4.2 |
| CANCELLED Add an "at" field to transform stats                              |         |       |  0:10 |   0.3 |
| COMPLETED Move enablement into yarn                                         |         |       |  1:01 |   2.0 |
| COMPLETED Consider revamping the project logo                               |         |       |  2:02 |   4.0 |
| COMPLETED Rename top-level transformations                                  |         |       |  1:33 |   3.1 |
| COMPLETED Clean-up context usage                                            |         |       |  0:38 |   1.3 |
| COMPLETED Housekeeper should know of text models                            |         |       |  2:05 |   4.1 |
| COMPLETED Rename the model to text transforms                               |         |       |  0:29 |   1.0 |
| COMPLETED Rename kernel and family                                          |         |       |  2:44 |   5.4 |
| COMPLETED Clean up formatter names                                          |         |       |  1:00 |   2.0 |
| COMPLETED Caching in travis                                                 |         |       |  0:59 |   1.9 |
| COMPLETED Consider collapsing element properties into element               |         |       |  1:08 |   2.2 |
| COMPLETED Create the archetype location properties                          |         |       | 13:58 |  27.6 |
| COMPLETED Analysis work on moving to c++ 17                                 |         |       |  0:32 |   1.1 |
| COMPLETED Upgrade rtags to latest                                           |         |       |  0:36 |   1.2 |
| COMPLETED Experiment with adding colour to dia diagrams                     |         |       |  3:01 |   6.0 |
| COMPLETED Move artefact into yarn                                           |         |       |  2:21 |   4.6 |
| COMPLETED Supply the yarn options to prober                                 |         |       |  0:23 |   0.8 |
| STARTED Experiment with a database model                                    |         |       |  1:20 |   2.6 |
| STARTED Split registrar into two classes                                    |         |       |  0:50 |   1.6 |
| STARTED Generate file paths as a transform                                  |         |       |  9:21 |  18.5 |
#+TBLFM: $5='(org-clock-time% @3$2 $2..$4);%.1f
#+end:

*** COMPLETED Edit release notes for previous sprint                  :story:
    CLOSED: [2017-09-18 Mon 21:39]
    CLOCK: [2017-09-18 Mon 20:32]--[2017-09-18 Mon 21:30] =>  0:58
    CLOCK: [2017-09-18 Mon 19:10]--[2017-09-18 Mon 20:31] =>  1:21

Add github release notes for previous sprint.

Title: Dogen v1.0.05, "Tribunal"

#+begin_src markdown
![Tribunal](https://lh4.googleusercontent.com/-jGPjhmZ1ZU8/TeI_Gc1PFtI/AAAAAAAAIwQ/UBPUpWaRuHA/s894/IMG_2594.JPG)
_Tribunal, Namibe, Angola. (C) SkyScrapperCity, 2011._

Overview
=======
The bulk of this sprint was focused on three refactoring tasks:

- **Renaming Concepts to Object Templates**: This is a long-standing clean-up that needed doing. One of the key principles in Yarn is to avoid binding to language specific terms when those terms don't cleanly map across to several programming languages. Since inception, "Concepts" has been a flagrant violation, as it alludes to a C++ feature which it isn't even a proper implementation of, nor does it map to generics. With the work on profiles looming, this clean-up became ever more pressing. Granted, "object templates"  is rather more verbose - but we decided to make the change in the interest of cleaning up Yarn vocabulary. It is, at least, a more accurate reflection of this meta-model element's responsibilities.
- **Probing support**: Historically, Dogen has always had good logging, allowing us to troubleshoot most issues quickly. However, with Yarn's transition towards a transformation-based architecture, it has become increasingly difficult to figure out what each transformation is doing. The linear nature of the log does not help, given that one is trying to visualise a graph. Thus, troubleshooting of issues has slowed down noticeably, so something had to be done. Probing is the proposed solution for this problem, and it has already made  troubleshooting orders of magnitude faster. This feature is described in depth below.
- **Work on moving kernel specific transforms**: we continued our long road on moving all of the "kernel-specific" transforms which aren't actually kernel-specific into Yarn. Enablement is almost done, but it remains elusive.

In addition to this, there were other minor (but still significant) strands of work:

- we continued work on the theme "everything is a transform", adding more transform chains and cleaning up more terminology as we went along. This work is now more or less complete, with the core of Yarn providing a set of primitives that are in keeping with the literature on code generation - in particular [Model-Driven Software Engineering in Practice](https://www.amazon.co.uk/Model-Driven-Software-Engineering-Practice-Synthesis/dp/1608458822). This has greatly simplified Yarn's conceptual model and vocabulary since we can now rely on "standard" terms.
- in a similar vein, we continued to merge more functionality into Yarn, deprecating the Knit model and moving its contents as transforms into Yarn.

User visible changes
================
The most important user visible changes introduced with this sprint are related to stereotypes:

- all meta-model types must now be prefixed: where you had ```object``` you must now put ```yarn::object```. This change was done in preparation for both the generalisation of profiles, and for adding the ability to refer to object templates (née concepts) across models.
- as explained in the previous section, ```concept``` has been renamed to ```object_template```, so where you had ```concept``` you must now put ```yarn::object_template```.

In addition, there was also a ORM related change that brings it in line with all other tagged values: the low-level ODB parameter was renamed from ```odb_pragma``` to ```quilt.cpp.odb.pragma```. So, in your models, where you had:

```
#DOGEN odb_pragma=no_id
```

You must replace it with:

```
#DOGEN quilt.cpp.odb.pragma=no_id
```

The final user visible change is the most significant in terms of time spent: transform probing. As it happens, it is not really aimed at end-users, but its worth describing the feature as it may still prove to be useful.

A new set of command line options have been added to ```dogen.knitter```:

```
  --probe-stats                         Generate stats about executed
                                        transforms.
  --probe-stats-disable-guids           Disable guids in probe stats, to make
                                        comparisons easier.
  --probe-stats-org-mode                Use org-mode format for stats. Requires
                                        enabling stats.
  --probe-all                           Dump all available probing information
                                        about transforms.
  --probe-directory                     Directory in which to dump probe data.
                                        Only used if transforms probing is
                                        enabled.
  --probe-use-short-names               Use short names for directories and
                                        files. Useful for Windows where long
                                        paths are not supported.
```

We'll start with ```--probe-stats``` and related options, since it is the most likely to be of use to end users. It is now possible to dump statistics about the transform graph, allowing simple benchmarkings. When a user selects this option, a file is generated under the probing directory (configurable via ```--probe-directory```), with the name ```transform_stats.txt```. As an example, here is the ```head``` of the generation of the ```yarn``` model:

```
root (1574 ms) [version: v1.0.06, log: debug, probing: off] [4423093f-eb3e-40af-a370-b879684f7950]
    dogen.yarn.code_generation_chain (1527 ms) [yarn.dia] [c6d812e9-9e97-4084-a1e1-afd804929dc0]
        yarn.transforms.model_generation_chain (1075 ms) [] [9778eeab-107a-4c0f-a633-87ffd06fcd5c]
            yarn.transforms.endomodel_generation_chain (890 ms) [yarn.dia] [3425b8d7-7ab2-4f95-a53a-b8c4bf7e0485]
                yarn.transforms.initial_target_chain (398 ms) [yarn.dia] [229a572e-70c1-4934-be79-db7e481de5bc]
                    yarn.transforms.exomodel_generation_chain (333 ms) [yarn.dia] [240ea71b-778a-4601-8682-153ad8b78d51]
                        yarn.dia.exomodel_transform (58 ms) [yarn.dia] [5e599d88-9676-41e9-aa9a-aaf4ebb134f8]
                        yarn.transforms.annotations_transform (12 ms) [] [7d95b799-72d0-471f-a50c-bb29a0d70709]
                        yarn.transforms.naming_transform (10 ms) [] [5c768d15-7964-4d54-a9c1-f32acc452161]
                    yarn.transforms.exomodel_to_endomodel_transform (0 ms) [<dogen><yarn>] [e8ec0c9f-92f1-4b03-a755-a335beda1c44]
```

As you can see, each node has the total elapsed time it took the transform to execute. In addition, the root node of the graph contains information about the configuration, so that we can compare like with like. This includes the Dogen version, the type of logging and whether detailed probing was enabled or not. You will also not fail to notice the GUIDs next to each node in the graph. These are correlation IDs, enabling one to find the logging for each of the transforms in the log file:

```
2017-09-18 11:22:11.618837 [DEBUG] [yarn.helpers.transform_prober] Starting: yarn.transforms.endomodel_pre_processing_chain (229a572e-70c1-4934-be79-db7e481de5bc)
```

If instead one just wants to diff two transformation graphs - perhaps looking for performance changes, or changes in the composition of the grap - one can disable the GUIDs via ```--probe-stats-disable-guids```.

```
root (1530 ms) [version: v1.0.06, log: debug, probing: off]
    dogen.yarn.code_generation_chain (1522 ms) [yarn.dia]
        yarn.transforms.model_generation_chain (1066 ms) []
            yarn.transforms.endomodel_generation_chain (880 ms) [yarn.dia]
                yarn.transforms.initial_target_chain (393 ms) [yarn.dia]
                    yarn.transforms.exomodel_generation_chain (328 ms) [yarn.dia]
                        yarn.dia.exomodel_transform (58 ms) [yarn.dia]
                        yarn.transforms.annotations_transform (12 ms) []
                        yarn.transforms.naming_transform (9 ms) []
                    yarn.transforms.exomodel_to_endomodel_transform (1 ms) [<dogen><yarn>]
```

For Vi and Emacs users, there is an additional way of interacting with the transform graph: we've added an org-mode compatible dump of the graph via ```--probe-stats-org-mode```. This feature is extremely useful because it allows collapsing and expanding the graph interactively from within the editor:

![org-mode](https://github.com/DomainDrivenConsulting/dogen/raw/master/doc/blog/images/emacs_org_mode_stats.png)

The second aspect of probing is the ability to dig deep into each transform, in order to understand what it was doing. For this we can use ```--probe-all```. Once enabled, a dump is generated for each transform in the transform graph of its inputs and outputs - where applicable. These are also stored in the probe directory. The directory structure follows the graph:

```
000-archetype_location_repository.json
001-type_repository.json
002-mapping_set_repository.json
003-dogen.yarn.code_generation_chain
transform_stats.txt
```

Each transform chain becomes a directory, and each transform has files with inputs and outputs, in JSON. It is trivial to indent the JSON files and diff input with output to figure out what the transform did - or, more likely, didn't do.

As always, there were complications with Windows. Since this operative system does not support long paths, we found that probing often failed with errors because our transform graph is deeply nested and the transforms have very long names. To allow one to use this feature under Windows, we've added ```--probe-use-short-names```. This makes the files and directories a lot less meaningful, but at least it still works:

```
000.json
001.json
002.json
003
transform_stats.txt
```

It is difficult to overstate the importance of probing in Dogen development. It was already used during this sprint to quickly get to the bottom of issues in enablement, and it was found to greatly simply this task. In the future, when we have rapid JSON support, one can conceive of a feature to read the dumped data into a test to replicate some particular bug very quickly.

For more details of the work carried out this sprint, see the [sprint log](https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/v1/sprint_backlog_05.org).

Next Sprint
===========
Next sprint we'll resume the work on moving kernel-agnostic transformations from the kernels into yarn.

Binaries
======
You can download binaries from [Bintray](https://bintray.com/domaindrivenconsulting/Dogen) for OSX, Linux and Windows (all 64-bit):

- [dogen_1.0.05_amd64-applications.deb](https://dl.bintray.com/domaindrivenconsulting/Dogen/1.0.05/dogen_1.0.05_amd64-applications.deb)
- [dogen-1.0.05-Darwin-x86_64.dmg](https://dl.bintray.com/domaindrivenconsulting/Dogen/1.0.05/dogen-1.0.05-Darwin-x86_64.dmg)
- [dogen-1.0.05-Windows-AMD64.msi](https://dl.bintray.com/domaindrivenconsulting/Dogen/dogen-1.0.05-Windows-AMD64.msi)

For all other architectures and/or operative systems, you will need to build Dogen from source. Source downloads are available below.
#+end_src

- [[https://twitter.com/MarcoCraveiro/status/909878261852835843][Tweet]]
- [[https://www.linkedin.com/feed/update/urn:li:activity:6315644420331053056][LinkedIn]]
- [[https://gitter.im/DomainDrivenConsulting/dogen][Gitter]]

*** STARTED Sprint and product backlog grooming                       :story:
    CLOCK: [2017-11-03 Fri 11:14]--[2017-11-03 Fri 11:33] =>  0:19
    CLOCK: [2017-11-02 Thu 08:22]--[2017-11-02 Thu 08:46] =>  0:24
    CLOCK: [2017-10-21 Sat 22:11]--[2017-10-21 Sat 22:31] =>  0:20
    CLOCK: [2017-10-21 Sat 11:28]--[2017-10-21 Sat 11:48] =>  0:20
    CLOCK: [2017-10-05 Thu 07:08]--[2017-10-05 Thu 07:15] =>  0:07
    CLOCK: [2017-09-29 Fri 10:01]--[2017-09-29 Fri 10:25] =>  0:24
    CLOCK: [2017-09-18 Mon 21:32]--[2017-09-18 Mon 21:39] =>  0:07
    CLOCK: [2017-09-18 Mon 00:01]--[2017-09-18 Mon 00:08] =>  0:07

Updates to sprint and product backlog.

*** COMPLETED Add logging to all top-level workflow activities        :story:
    CLOSED: [2017-09-18 Mon 21:43]

*Rationale*: probing has addressed this problem.

We need to make sure the log file is narrating a story. For this we
need to add logging to all start and end of activities by the
workflows. This means that when we filter by workflow name we should
be able to quickly figure out where things went wrong.

*** COMPLETED Add logging to test suite                               :story:
    CLOSED: [2017-09-18 Mon 21:42]

*Rationale*: initialisation of logging in tests has addressed this
problem.

At present its not possible to figure out where a test suite starts or
ends in the log file. We should also move the asserts from =DEBUG= to
=TRACE=, unless there is an error.

*** CANCELLED Add an "at" field to transform stats                    :story:
    CLOSED: [2017-09-18 Mon 22:21]
    CLOCK: [2017-09-18 Mon 22:11]--[2017-09-18 Mon 22:21] =>  0:10

*Rationale*: given the current state of affairs in C++, its best if we
just rely on the file timestamp.

At present we cannot tell when the transform stats were dumped. We
could of course look at timestamps but to make life easier for the
user we could add a field with a date in local time - or perhaps UTC?

*** COMPLETED Move enablement into yarn                               :story:
    CLOSED: [2017-09-19 Tue 08:36]
    CLOCK: [2017-09-19 Tue 20:58]--[2017-09-19 Tue 21:19] =>  0:21
    CLOCK: [2017-09-19 Tue 07:41]--[2017-09-19 Tue 08:01] =>  0:20
    CLOCK: [2017-09-19 Tue 07:20]--[2017-09-19 Tue 07:40] =>  0:20

It seems that the concepts around enablement are actually not kernel
specific but instead can be generalised at the meta-model level. We
need to create adequate representations in yarn to handle facets,
etc. We then need to move across the code that computes enablement
into yarn so that all kernels can make use of it.

Problems:

- we are checking to see if the hash facet is enabled with c++ 98; if
  so, we throw as this facet is incompatible. We cannot do this from
  yarn since we do not know what c++ standards are.
- because we do not have a mapping between a archetype location and
  the meta-type, we will be enabling/disabling all archetype locations
  across all meta-types.
- because we do not have element segmentation, the element extensions
  will be disabled. Actually this will probably work just the same,
  given that all elements exist.
- enablement must be done after external transformations so it picks
  up fabric types.
- we need to support formatting styles in order to be able to use the
  artefact properties from the meta-model.
- in quilt.cpp, someone did an upfront generation of all archetype
  properties against the archetype locations. We not doing that in
  yarn, so nothing is coming out. This was done during transformation
  in formattables.
- with a move into yarn, we seem to have broken the overwrite flag
  logic; changes no longer result in new code being generated.
- we also have borked the includes: dependency builder is looking into
  the formattables instead of element. However, we then run into
  segmentation issues because we cannot find forward declarations on
  the main element.

To do:

- kernel registrar type index map - done.
- assistant to latch on to element; use new element properties where
  possible.
- facet properties must be handled, and assistant must use the yarn
  version.
- c# formatter registrar type index map - done.
- bug in template instantiating: artefact expansions do not seem to
  take kernel into account - done.
- use new enabled fields.
- delete all enablement classes in c++ and enabled/overwrite properties.

*Previous Understanding*

We need to make use of the exact same logic as implemented in
=quilt.cpp= for enablement. Perhaps all of the enablement related
functionality can be lifted and grafted onto quilt without any major
changes.

*** COMPLETED Consider revamping the project logo                     :story:
    CLOSED: [2017-09-20 Wed 22:00]
    CLOCK: [2017-09-21 Thu 09:10]--[2017-09-21 Thu 10:14] =>  1:04
    CLOCK: [2017-09-20 Wed 21:47]--[2017-09-20 Wed 22:00] =>  0:13
    CLOCK: [2017-09-18 Mon 22:11]--[2017-09-18 Mon 22:56] =>  0:45

Try doing something slightly less "street".

*** COMPLETED Rename top-level transformations                        :story:
    CLOSED: [2017-09-29 Fri 12:31]
    CLOCK: [2017-09-29 Fri 12:18]--[2017-09-29 Fri 12:31] =>  0:13
    CLOCK: [2017-09-29 Fri 12:14]--[2017-09-29 Fri 12:17] =>  0:03
    CLOCK: [2017-09-29 Fri 10:57]--[2017-09-29 Fri 11:14] =>  0:17
    CLOCK: [2017-09-29 Fri 10:26]--[2017-09-29 Fri 10:56] =>  0:30
    CLOCK: [2017-09-18 Mon 21:40]--[2017-09-18 Mon 22:10] =>  0:30

We no longer need the code-generator outside of transforms; we can now
have a code-generation chain.

Actually in addition, we need two top-level transforms:

- a text model generation chain, which produces the text model, and is
  useful for services;
- a code genration chain, which uses the text model generation chain
  and then writes it to the file system. In the future we could have
  an archive generation chain which produces a tarball, zip etc.

Tasks:

- rename kernel related transforms to "model to text" as this is what
  they are doing.
- remove code-generation, create a transform for it.

*** COMPLETED Clean-up context usage                                  :story:
    CLOSED: [2017-09-29 Fri 12:57]
    CLOCK: [2017-09-29 Fri 12:58]--[2017-09-29 Fri 13:11] =>  0:13
    CLOCK: [2017-09-29 Fri 12:32]--[2017-09-29 Fri 12:57] =>  0:25

We've included context generation in the code generation
transform. This is not ideal. It should be the responsibility of the
client to create the context.

*** COMPLETED Housekeeper should know of text models                  :story:
    CLOSED: [2017-09-29 Fri 16:40]
    CLOCK: [2017-09-29 Fri 16:39]--[2017-09-29 Fri 16:42] =>  0:03
    CLOCK: [2017-09-29 Fri 16:22]--[2017-09-29 Fri 16:38] =>  0:16
    CLOCK: [2017-09-29 Fri 15:49]--[2017-09-29 Fri 16:01] =>  0:12
    CLOCK: [2017-09-29 Fri 15:30]--[2017-09-29 Fri 15:48] =>  0:18
    CLOCK: [2017-09-29 Fri 14:13]--[2017-09-29 Fri 15:29] =>  1:16

It should be the responsibility of the house keeper to collect the
expected files and extract managed directories.

The housekeeper API doesn't make a lot of sense either: we should just
return the candidates for deletion rather than take in a lambda for
deletion.

The job of the "housekeeper" is to compute a list of unexpected
files. Its name should be: =file_linter=.

*** COMPLETED Rename the model to text transforms                     :story:
    CLOSED: [2017-10-06 Fri 10:08]
    CLOCK: [2017-10-06 Fri 10:01]--[2017-10-06 Fri 10:08] =>  0:07
    CLOCK: [2017-10-06 Fri 09:47]--[2017-10-06 Fri 10:00] =>  0:13
    CLOCK: [2017-10-05 Thu 07:21]--[2017-10-05 Thu 07:30] =>  0:09

We originally called the transforms "model to text" but actually they
are "model to text model" transforms.

*** COMPLETED Rename kernel and family                                :story:
    CLOSED: [2017-10-06 Fri 14:07]
    CLOCK: [2017-10-06 Fri 14:06]--[2017-10-06 Fri 14:10] =>  0:04
    CLOCK: [2017-10-06 Fri 13:19]--[2017-10-06 Fri 14:05] =>  0:46
    CLOCK: [2017-10-06 Fri 13:12]--[2017-10-06 Fri 13:18] =>  0:06
    CLOCK: [2017-10-06 Fri 13:01]--[2017-10-06 Fri 13:11] =>  0:10
    CLOCK: [2017-10-06 Fri 12:57]--[2017-10-06 Fri 13:00] =>  0:03
    CLOCK: [2017-10-06 Fri 12:49]--[2017-10-06 Fri 12:56] =>  0:07
    CLOCK: [2017-10-06 Fri 12:19]--[2017-10-06 Fri 12:25] =>  0:06
    CLOCK: [2017-10-06 Fri 12:04]--[2017-10-06 Fri 12:18] =>  0:14
    CLOCK: [2017-10-06 Fri 11:57]--[2017-10-06 Fri 12:03] =>  0:06
    CLOCK: [2017-10-06 Fri 11:32]--[2017-10-06 Fri 11:56] =>  0:24
    CLOCK: [2017-10-06 Fri 10:53]--[2017-10-06 Fri 11:31] =>  0:38

We need to use the term "family" to signify a group of archetypes such
as "c++ headers", "c++ implementations", "c# implementations"
etc. However, we have already used this term in the archetype
location. So we need to:

- rename kernel to backend. This clarifies things since we keep
  calling kernels backends anyway.
- rename family to kernel. So quilt becomes a kernel, implemented by a
  number of backends: quilt.cpp, quilt.csharp and so forth.
- rename archetype location group to archetype location family.

*** COMPLETED Clean up formatter names                                :story:
    CLOSED: [2017-10-08 Sun 16:41]
    CLOCK: [2017-10-08 Sun 16:35]--[2017-10-08 Sun 16:41] =>  0:06
    CLOCK: [2017-10-08 Sun 16:17]--[2017-10-08 Sun 16:34] =>  0:17
    CLOCK: [2017-10-08 Sun 15:39]--[2017-10-08 Sun 16:16] =>  0:37

At present we have confusing terminology in formatters:

- formatter name, helper name
- static artefact

We should just standardise everything as "id's" which at least is
consistent with how we deal with yarn names. Still not ideal given
that the "id" is in effect "archetype" in archetype location, but its
slightly less confusing.

*** COMPLETED Caching in travis                                       :story:
    CLOSED: [2017-10-15 Sun 07:49]
    CLOCK: [2017-10-15 Sun 07:41]--[2017-10-15 Sun 07:49] =>  0:08
    CLOCK: [2017-10-14 Sat 22:20]--[2017-10-14 Sat 22:37] =>  0:17
    CLOCK: [2017-10-14 Sat 21:45]--[2017-10-14 Sat 22:19] =>  0:34

It seems it is possible to cache in travis. We should try to enable it
for our builds and see if it improves build times.

Links:

- [[https://github.com/lballabio/QuantLib/blob/master/.travis.yml][QuantLib travis.yml]] with caching enabled
- [[https://blog.travis-ci.com/2016-05-03-caches-are-coming-to-everyone][Caching now available for everyone]]
- [[https://docs.travis-ci.com/user/caching/][Caching Dependencies and Directories]]
- [[https://ccache.samba.org/][CCache]]
- [[https://crascit.com/2016/04/09/using-ccache-with-cmake/][Using ccache with CMake]]
- [[https://github.com/perl11/potion/issues/41][clang: error: argument unused during compilation: '-I core']]
- [[https://bugzilla.samba.org/show_bug.cgi?id%3D8118][Bug 8118 - don't pass -D, -I, -U to compiler]]

*** COMPLETED Consider collapsing element properties into element     :story:
    CLOSED: [2017-10-15 Sun 18:44]
    CLOCK: [2017-10-15 Sun 18:45]--[2017-10-15 Sun 18:49] =>  0:04
    CLOCK: [2017-10-15 Sun 18:24]--[2017-10-15 Sun 18:44] =>  0:20
    CLOCK: [2017-10-15 Sun 17:39]--[2017-10-15 Sun 18:23] =>  0:44

Do we really need element properties as a stand alone class? It seems
all of its attributes should just be part of element.

*** COMPLETED Create the archetype location properties                :story:
    CLOSED: [2017-10-20 Fri 11:00]
    CLOCK: [2017-10-20 Fri 10:51]--[2017-10-20 Fri 10:55] =>  0:04
    CLOCK: [2017-10-20 Fri 10:41]--[2017-10-20 Fri 10:50] =>  0:09
    CLOCK: [2017-10-20 Fri 10:35]--[2017-10-20 Fri 10:40] =>  0:05
    CLOCK: [2017-10-20 Fri 10:29]--[2017-10-20 Fri 10:34] =>  0:05
    CLOCK: [2017-10-20 Fri 09:54]--[2017-10-20 Fri 10:28] =>  0:34
    CLOCK: [2017-10-20 Fri 08:45]--[2017-10-20 Fri 09:53] =>  1:08
    CLOCK: [2017-10-17 Tue 19:00]--[2017-10-17 Tue 19:07] =>  0:07
    CLOCK: [2017-10-17 Tue 18:40]--[2017-10-17 Tue 18:59] =>  0:19
    CLOCK: [2017-10-17 Tue 18:18]--[2017-10-17 Tue 18:39] =>  0:21
    CLOCK: [2017-10-17 Tue 07:09]--[2017-10-17 Tue 07:29] =>  0:20
    CLOCK: [2017-10-15 Sun 19:20]--[2017-10-15 Sun 19:53] =>  0:33
    CLOCK: [2017-10-15 Sun 18:45]--[2017-10-15 Sun 19:19] =>  0:34
    CLOCK: [2017-10-15 Sun 17:28]--[2017-10-15 Sun 17:38] =>  0:10
    CLOCK: [2017-10-13 Fri 15:31]--[2017-10-13 Fri 15:50] =>  0:19
    CLOCK: [2017-10-13 Fri 14:16]--[2017-10-13 Fri 14:26] =>  0:10
    CLOCK: [2017-10-13 Fri 11:51]--[2017-10-13 Fri 13:45] =>  1:54
    CLOCK: [2017-10-10 Tue 18:42]--[2017-10-10 Tue 19:13] =>  0:31
    CLOCK: [2017-10-10 Tue 18:20]--[2017-10-10 Tue 18:41] =>  0:21
    CLOCK: [2017-10-10 Tue 07:11]--[2017-10-10 Tue 07:55] =>  0:44
    CLOCK: [2017-10-08 Sun 17:13]--[2017-10-08 Sun 17:23] =>  0:10
    CLOCK: [2017-10-08 Sun 16:42]--[2017-10-08 Sun 17:12] =>  0:30
    CLOCK: [2017-10-08 Sun 14:52]--[2017-10-08 Sun 15:38] =>  0:46
    CLOCK: [2017-10-08 Sun 14:12]--[2017-10-08 Sun 14:51] =>  0:39
    CLOCK: [2017-10-06 Fri 10:09]--[2017-10-06 Fri 10:52] =>  0:43
    CLOCK: [2017-10-05 Thu 07:15]--[2017-10-05 Thu 07:20] =>  0:05
    CLOCK: [2017-09-29 Fri 14:02]--[2017-09-29 Fri 14:13] =>  0:11
    CLOCK: [2017-09-29 Fri 11:40]--[2017-09-29 Fri 12:13] =>  0:33
    CLOCK: [2017-09-29 Fri 11:17]--[2017-09-29 Fri 11:39] =>  0:22
    CLOCK: [2017-09-29 Fri 11:15]--[2017-09-29 Fri 11:16] =>  0:01
    CLOCK: [2017-09-22 Fri 13:58]--[2017-09-22 Fri 14:07] =>  0:09
    CLOCK: [2017-09-22 Fri 13:43]--[2017-09-22 Fri 13:57] =>  0:14
    CLOCK: [2017-09-22 Fri 13:35]--[2017-09-22 Fri 13:42] =>  0:07
    CLOCK: [2017-09-22 Fri 13:18]--[2017-09-22 Fri 13:34] =>  0:16
    CLOCK: [2017-09-22 Fri 13:08]--[2017-09-22 Fri 13:17] =>  0:09
    CLOCK: [2017-09-22 Fri 11:31]--[2017-09-22 Fri 12:02] =>  0:31
    CLOCK: [2017-09-22 Fri 11:26]--[2017-09-22 Fri 11:30] =>  0:04

We have a number of properties scattered around the model that need to
be treated as a unit. We don't really have a good name for it, but as
they are all related to archetype location stuff,
=archetype_location_properties= seems like a good name.

The reading of the "global" properties is done in the new archetype
location transform. Enablement takes these properties and uses it to
populate its global configuration.

Notes:

- is there a need for a global overwrite flag? We already have the
  force write command line option. We seem to have this at all levels
  (backend, facet, archetype).

Tasks:

- create the =archetype_location_properties=.
- update enablement to use new properties, drop legacy ones.
- create a transform that reads in all the meta-data related to
  them. Place it prior to enablement.
- update enablement to use the =archetype_location_properties= to
  populate its global and local caches.
- add disable_facet_directories to locator properties?

*** COMPLETED Analysis work on moving to c++ 17                       :story:
    CLOSED: [2017-10-21 Sat 12:21]
    CLOCK: [2017-10-21 Sat 11:49]--[2017-10-21 Sat 12:21] =>  0:32

Have a quick go at bumping C++ standard version to 17 and see what breaks.

*** COMPLETED Upgrade rtags to latest                                 :story:
    CLOSED: [2017-10-21 Sat 13:46]
    CLOCK: [2017-10-21 Sat 13:10]--[2017-10-21 Sat 13:46] =>  0:36

We seem to be experiencing some random problems with rtags. Try
getting latest and see if it gets better.

*** COMPLETED Experiment with adding colour to dia diagrams           :story:
    CLOSED: [2017-10-27 Fri 13:10]
    CLOCK: [2017-10-27 Fri 10:09]--[2017-10-27 Fri 13:10] =>  3:01

As per this paper, using colours in diagrams could be useful:

- [[http://www.robwortham.com/wp-content/uploads/2016/05/ICAPS-2016-PlanRob-Instinct-Planner.pdf][Instinct: A Biologically Inspired Reactive Planner for Embedded
  Environments]]

It was mentioned in this discussion:

- https://mail.gnome.org/archives/dia-list/2016-September/msg00021.html

Play around with creating a script that updates diagrams with a
palette of colours so that we can distinguish between the different
meta-types.

*** COMPLETED Move artefact into yarn                                 :story:
    CLOSED: [2017-11-02 Thu 19:39]
    CLOCK: [2017-11-03 Fri 08:45]--[2017-11-03 Fri 09:30] =>  0:45
    CLOCK: [2017-11-02 Thu 18:41]--[2017-11-02 Thu 19:39] =>  0:58
    CLOCK: [2017-11-02 Thu 09:06]--[2017-11-02 Thu 09:17] =>  0:11
    CLOCK: [2017-11-02 Thu 09:01]--[2017-11-02 Thu 09:05] =>  0:04
    CLOCK: [2017-11-02 Thu 08:47]--[2017-11-02 Thu 09:00] =>  0:13
    CLOCK: [2017-10-31 Tue 18:45]--[2017-10-31 Tue 18:55] =>  0:10

Originally we had placed artefact in the formatters model, but now
that we have text models, it makes more sense to have it in yarn.

*** COMPLETED Supply the yarn options to prober                       :story:
    CLOSED: [2017-11-03 Fri 09:43]
    CLOCK: [2017-11-03 Fri 09:38]--[2017-11-03 Fri 10:01] =>  0:23

At present most of the arguments supplied to prober come from the
options anyway - why not just supply the options to it?

*** STARTED Experiment with a database model                          :story:
    CLOCK: [2017-10-31 Tue 18:01]--[2017-10-31 Tue 18:45] =>  0:44
    CLOCK: [2017-10-31 Tue 08:22]--[2017-10-31 Tue 08:58] =>  0:36

Try to create a dogen model to store documents in a relational
database in a de-normalised representation. We should also store the
original representation supplied by the user as well as support
versioning.

Actions:

- put workspace, delete workspace, get workspaces
- put input, delete input, get inputs
- put request for generating output, delete output, get outputs

*** STARTED Split registrar into two classes                          :story:
    CLOCK: [2017-11-03 Fri 10:23]--[2017-11-03 Fri 11:13] =>  0:50

At present we do not distinguish between the setting up of the
registrar and the usage of the registrar. Up to know this is not a
major issue, although its a bit of a smell that we have to call
validate at some arbitrary point.

However, with the new parts/builder setup, this becomes even more of a
problem because we only want to build the parts once we have
registered all of the formatters. The right thing would have been to
have:

- a registrar builder, used during registration;
- a build step which returns the (validated) registrar. Once build is
  called, we should throw if anyone attempts to add more formatters.

This makes it hard to misuse the API.

Notes:

- how does this affect plugins? will it still be possible to register
  formatters from a shared library?

Tasks:

- create a registrar builder with most of the existing registrar
  interface. On build it computes the parts, generates the repository,
  etc and then supplies that to the registrar. The registrar itself is
  no longer static, just a member of the workflow.

*** STARTED Generate file paths as a transform                        :story:
    CLOCK: [2017-11-03 Fri 10:02]--[2017-11-03 Fri 10:22] =>  0:20
    CLOCK: [2017-10-21 Sat 10:30]--[2017-10-21 Sat 11:27] =>  0:57
    CLOCK: [2017-10-20 Fri 13:05]--[2017-10-20 Fri 13:42] =>  0:37
    CLOCK: [2017-10-20 Fri 11:33]--[2017-10-20 Fri 11:55] =>  0:22
    CLOCK: [2017-10-20 Fri 10:56]--[2017-10-20 Fri 11:32] =>  0:36
    CLOCK: [2017-09-22 Fri 09:41]--[2017-09-22 Fri 11:26] =>  1:45
    CLOCK: [2017-09-21 Thu 14:20]--[2017-09-21 Thu 14:55] =>  0:35
    CLOCK: [2017-09-21 Thu 12:21]--[2017-09-21 Thu 12:31] =>  0:10
    CLOCK: [2017-09-21 Thu 11:55]--[2017-09-21 Thu 12:20] =>  0:25
    CLOCK: [2017-09-21 Thu 10:50]--[2017-09-21 Thu 11:32] =>  0:42
    CLOCK: [2017-09-20 Wed 20:12]--[2017-09-20 Wed 21:46] =>  1:34
    CLOCK: [2017-09-19 Tue 21:42]--[2017-09-19 Tue 21:47] =>  0:05
    CLOCK: [2017-09-19 Tue 21:20]--[2017-09-19 Tue 21:41] =>  0:21
    CLOCK: [2017-09-19 Tue 17:51]--[2017-09-19 Tue 18:43] =>  0:52

Add a yarn transform for file path generation.

In order to solve this problem, we need to create a generic
architecture that compute file paths. We have two key
responsibilities:

- computing the full path, used for writing the artefact.
- computing a relative path, used for:
  - includes;
  - header guards;
  - visual studio C# projects at present, and in the future, c++ projects;
  - paths in ODB files, which requires the relative path to both the
    odb and types facets.
  - paths in CMakeLists for ODB files.
  - paths in msbuild for ODB files.

*Computing the full path*

At present we are computing the full path by having a kernel-specific
locator who loads its information as follows:

- output directory path, cpp headers output directory path; can be
  sourced from options.
- type repository: can be sourced from context.
- enable kernel directories: read from meta-data.
- module ids: already available in model.
- formatters repository: part of this can be replaced by sourcing the
  archetype location from context. However, we also use the formatter
  to generate the path.

In addition, we read data from meta-data:

- include, source directory name
- header, implementation file extension
- disable facet directories
- kernel directory name
- for each facet, facet directory name, facet postfix, archetype
  postfix

This information can all be read up front from the root annotation.

We then compute different kinds of paths:

- project path: full path to the project directory. Starts with the
  supplied output directory, skips external modules, adds model
  modules, skips internal modules. Includes_ kernel directory, if
  enabled.
- facet path: includes facet directory, internal modules, model
  modules. Handles module names differently from all other
  names. Includes file name and extension (supplied as paramters).

Finally, formatters call specific functions to obtain the full path or
include path. However, each formatter is then responsible for
supplying things such as is header file/implementation file, is
CMakeLists etc.

*Towards a more general locator architecture*

Locator needs to be able to load all of the meta-data related to:

- kernels: kernel directory, is kernel enabled
- facets: directory, postfix, archetype postfix

The biggest problem we have is that, given an element and an
archetype, we are not able to determine:

- the full path: what is the extension? is the archetype in a facet or
  not? e.g. top-level CMakeLists. Is it in a directory that lives
  outside of the project directory and outside of facet directories?
  e.g. src CMakeLists. Is it in a facet? e.g. ODB files.
- the relative paths: relative to what? how many to compute.

However, some things do have a functional relationship:

- given archetype location, you can only have one extension. One
  extension can have many archetype locations. This includes
  separating headers from implementation, etc. Formatters know the
  extension.

We could introduce two concepts:

- directory groups: project, kernel, other: include,
  implementation. Directory groups contain directory groups. Directory
  groups have settings: a name; whether to add external modules,
  internal modules, model modules;

  - file groups: include, implementation.

Each group has an associated configuration:

- directory configuration:
  - id: yarn, quilt.cpp/quilt.csharp, include/source/
  - name
  - type: model, kernel, intra-kernel. Not actually modeled in code.
  - external modules: as path components, as folders, does not
    contribute (none). Enum: path contribution type. Not available for
    kernel configuration.
  - model modules: as path components, as folders, does not
    contribute. Not available for kernel configuration.
  - internal modules: as path components, as folders, does not
    contribute. Not available for model directory configuration or
    kernel configuration.
  - facets: as path components, as folders, does not
    contribute.
  - enabled:
- file configuration:
  - name: C++ header files, C++ implementation files, CMakeFiles, MSBuild
    files, C# files.
  - extension: .cpp, etc.

A path is composed of segments, which are sets of path components. The
following segments exist:

- output segment: supplied by the command line, as it references full paths.
- output override segment: supplied by the command line, as it
  references full paths. Must have a intra-kernel segment name.
- model segment
- kernel segment
- intra-kernel segment: needs to know if the parent has been
  overriden. Else, defaults to output + model + kernel.
- facet segment: Composed of the facet directory name (configurable,
  enabled or disabled) and the facet postfix (configurable, enabled or
  disabled)

Examples:

- =yarn.directory_configuration.flat_mode=: if true, no other
  directory configuration options may be specified. No directories
  will be generated at all. However we will still use the facet and
  archetype post-fixes (these then become mandatory). We need to also
  worry about CMakeLists: we can't have include/src files because they
  have the same name. We need to disable the include CMakeLists.txt
  and add the install for headers into source CMakeLists.txt.
- =yarn.directory_configuration.directory_name=: defaults to model
  name. If user supplied, the rest is ignored. If not supplied, and
  all other path contribution types are set to none, there will be no
  contribution from model directory configuration.
- =yarn.directory_configuration.separator=: defaults to dot.
- =yarn.directory_configuration.external_modules=: none.
- =yarn.directory_configuration.model_modules=: path_components.
- =quilt.cpp.directory_configuration.directory_name=: each kernel
  provides a default (e.g. =cpp=, =cs=).
- =quilt.cpp..directory_configuration.external_modules=: none.
- =quilt.cpp.directory_configuration.model_modules=: path_components.
- =yarn.directory_configuration.internal_modules=: path_components.

Note: it should be possible to assign a different intra-kernel
directory configuration for a given (element, archetype) pair. For
example, if it is public vs internal. The trouble with this is that we
want the directory configurations to be supplied by the kernel at
context construction time, but we do not know of the overrides until
we start processing the elements. Thus we need an element level
configuration "directory group override" that is read during
processing, that takes precedence over the kernel level default.

Styles: dogen style, vs flat style. Dogen style:

Creates the directory structure as follows:

- the model segment is composed of just the model directory; the model
  directory is composed of the model modules, separated by dots.
- the kernel segment is composed of just the kernel directory - but only if
  there is more than one kernel enabled.
- followed by the intra-kernel
enabled

**** Merged Stories
***** Split out the file extension from the formatter

At present we have handled file extensions in one of two ways:

- we baked them in into locator, dynamically: this is the case for
  =hpp= and =cpp=, where locator is responsible for retrieving the
  meta-data related to extensions.
- we hacked them in into locator, statically: this is the case for
  CMakeLists, where the =txt= is hard-coded in.
- we hacked them in into the elements: this is the case for Visual
  Studio solutions and projects.

In reality, what we need is to create a separation between the
archetype, the extension "kind" and the actual extension. All
archetypes have a fixed "extension kind". For example, C++ headers
will always have a C++ header extension even though the actual header
extension used is not known. In other cases the extension kind has a
fixed extension (CMakeLists, Visual Studio projects, solutions). At
present this mapping is done via the multiple functions locator
supplies.

We could conceivably have an enumeration for extension kind and then
have a single function for full paths, that just takes in the
extension kind, archetype etc. This would replace the proliferation of
"full path for XYZ".

We also have the concept of inclusion paths. We should generalise this
to just "relative paths" and have a "add project directory?" flag.

***** Name all project paths according to a scheme

The locator API looks really confusing due to the various kinds of
paths. We need to catalogue them all and name them properly.

- output directory: directory into which knitter will write all files,
  unless "c++ headers output directory" is set, in which case it will
  write all files except for the headers.
- c++ headers output directory: directory in which knitter will write
  the headers. Only applicable to c++.
- include directory: aka inclusion directory; directory to place in
  the include path.

***** Handling of visual studio projects and solutions is incorrect

At present we added the extension of the solution/project to the
element name, e.g.:

: all_path_and_directory_settings.csproj

This happens to work for the simpler cases, but if we try to add a
postfix we then have a problem:

: dogen.test_models.all_path_and_directory_settings.csproj_vc15_

Projects and solutions do not seem to fit our conceptual model for the
element space. We need to somehow have distinct element IDs but yet
not associate the extension with the name directly. Up to now we never
had two distinct elements with the exact same name but generating two
different artefacts with different extensions.

This is a problem because we will need to have the ability to generate
multiple project files for different versions of visual studio.

For now we removed the project and solution postfixes:

: #DOGEN quilt.csharp.visual_studio.solution.postfix=_vs15_
: #DOGEN quilt.csharp.visual_studio.project.postfix=_vc15_

In order to fit our conceptual model, we need to make some adjustments
to our implementation of projects and solutions. First, there is only
one meta-model element for *both* projects and solutions. This is
derived from the fact that they both share a common name. The
conceptual model does not involve file extensions - or file paths for
that matter; archetypes exist only in archetype space, and their
"paths" in this space are only related to the facets they belong
to. The physical location is a property of files, which are
expressions of archetypes in "file space". Thus, there is only one
single element, provisionally called "visual studio", which has
multiple archetypes (and their associated formatters):

- solution
- project

Second, a solution and project may be instantiated multiple times,
depending on the version of visual studio and the associated
compiler. Externally users supply a visual studio version and that
internally will map to different instances of the formatters. We must
instantiate the formatters for each supported version because we may
need to create multiple versions simultaneously: his is the use case
where users want to generate projects and solutions for multiple
versions of VS at the same time.

THe good news is that we already have something similar: master
includes. We can adapt a lot of the logic we have for master
includes. There are some differences though:

- we will have multiple instances on the same facet.
- we need some external mechanism to determine if a given version is
  enabled. We could force users to enter the "enabled" property for
  each version in the meta-data, but that would get really messy since
  there are only a few valid combinations of solution and project
  version. Its better if users supply the Visual Studio versions and
  we infer the solution and projects to enable. But we do not have a
  mechanism for this at present. We could add a "is enabled" to
  formatters like we did for helpers, supplying the element; we would
  then check the Visual Studio version in the element and return false
  if it didn't match the formatters version. Or we could change the
  formatter's interface to return optional artefact. Whilst this is a
  bit more painful - we'd have to change all formatters - it fits the
  code structure slightly better.
- we need to have different file names depending on the
  version. Worse: if there is just a single version we do not need to
  have a "version prefix". If there are multiple versions we need to
  add the prefix. The fist use case is easy: we already have archetype
  prefixes; we just need to add a prefix for each version. The second
  part requires some hacking. We could have an option in locator:
  "apply archetype postfix" supplied as an argument. Since we have the
  Visual Studio element we have visibility of all enabled versions.

***** Add a "flat directory" mode

It would be nice to have a mode in which all files get placed in a
single-directory: no src, include, etc – just one big folder with all
files.

Actually we can already achieve this:

- set =quilt.cpp.disable_facet_directories= to true
- set =quilt.cpp.include_directory_name= to empty
- set =quilt.cpp.source_directory_name= to empty

It is however a bit painful. It would be nice to have a shorthand for
this, which could be the "flat directory" mode. It is also compatible
with split project mode (we just have flat directories in two
different top-level directories), which is nice.

We should check that =enable_unique_file_names= is set to true.

Key: =quilt.cpp.flat_directory_mode.enabled=.

*** Update backend shape to match yarn                                :story:

In an ideal world, the backends should be made up of two components:

- *meta-model*: a set of types that augment yarn with backend
  specific elements. This is what we call fabric at present.
- *transforms*: of these we have two kinds:
  - the model-to-model transforms that involve either yarn meta-model
    elements or backened specific meta-model elements. These live in
    fabric at present.
   - the model-to-text transforms that convert a meta-model element
     (yarn or backend specific) into an artefact. These we call
     formatters at present.

The ultimate destination for the backend is then to have a shape that
reflects this:

- rename formatters to transforms
- move artefact formatter into yarn; with this it means we can also
  move all of the top-level workflow formatting logic into
  yarn. However, before we can do this we must make all of the backend
  specific code in the formatter interface go away.
- note that at this point we no longer need to know what formatters
  belong to what backend other than perhaps to figure out if the
  backend is enabled. This means yarn can now have the registrars for
  formatters and organise them by backend. Which means the
  model-to-text chain will own all of these. However, we still have
  the managed directories to worry about; somehow, someone has to be
  able to compute the managed directories per kernel. This could be
  done at yarn level if the locator is clever enough.

Of course, before we can contemplate this change, we must first get
rid of formattables altogether.

We must also somehow model canonical formatters in yarn. Take this
into account when we do:

:        /*
:         * We must have one canonical formatter per type per facet.
:         * FIXME: this check is broken at the moment because this is
:         * only applicable to yarn types, not fabric types. It is also
:         * not applicable to forward declarations. We need some
:         * additional information from yarn to be able to figure out
:         * which types must have a canonical archetype.
:         */

*** Improvements to dia model                                         :story:

Assorted notes on cleaning-up the dia model:

- create a base class such as =value= and make all values inherit from
  it instead of using boost variant.
- according to DTD, a composite can be made up of either composites or
  attributes. We incorrectly modeled it as having just one inner
  composite.
- perhaps this is better thought of slightly differently: an attribute
  has child nodes. The child nodes can either be leaf nodes, in which
  case they are values, or non-leaf nodes in which case they are
  composite nodes. Composite nodes themselves can have child nodes. If
  they are leaf nodes they are values; if they are non-leaf nodes they
  are either attributes or composites.
- note that we do not need to use shared pointers in composite: we
  could simply have an attribute by value. However, we still need to
  handle the case where the children are either composite or
  attributes. So if we somehow could get composite and attribute to
  have a common base class, we could have a container of that base
  class in composite. For this we would need a shared pointer.
- consider adding the postfix =node= to class names and make it a real
  tree, as per dia's implementation.
- covert all vectors to lists since we do not know their sizes on
  construction.
- one thing to bear in mind is that if we fix the tree structure, we
  will break the XML parsing code in hydrator, which took quite a
  while to get right (and has hacks such as "inner composite").
- its not obvious why we need to treat =dia::string= in a different
  way from all other attribute values (except for =dia::font=).

*** Consider bucketing elements by meta-type in model                 :story:

At the moment we have a flat container of elements in the main
model. However, it seems like one of its use cases will be to bucket
the elements by meta-type before processing: formatters will want to
locate all formatters for a given meta-type and apply them all. At
present we are asking for the formatters for meta-name
repeatedly. This makes no sense, we should just ask for them once and
apply all formatters in one go.

For this we could simply group elements by meta-name in the model
itself and then use that container at formatting time. However, there
may be cases where looping through the whole model is more convenient
(during transforms) so this is not without its downsides.

Alternatively we could consider just bucketing in the formatters'
workflow itself.

This work will only be useful once we get rid of the formattables
model.

*** Properties vs configuration                                       :story:

Originally we had defined properties to mean things which are computed
and configuration to mean things which are read directly from the
meta-data and not touched afterwards. This made life easier in
determining how each class was used. However, this was not strictly
enforced and now there are many cases where properties are used when
configuration should have been (and probably vice-versa). In addition,
we have cases where we should have used configuration but used nothing
(type parameters springs to mind). We need to do a clean up of the
meta-model.

*** Create a text model post-processing chain                         :story:

The following transforms can be done after generation of the text model:

- clang format
- protected regions: read the file on disk, replace contents of the
  protected region with the data read from disk.

These can be contained in a post-processing chain for the text model.

Note that we need artefacts to have an associated language so that we
can use the correct clang format configuration. If a language is not
supported by clang format (e.g. c#) we should just skip the files. The
text model could group files by language.

*** Postfix and directory fields in annotations look weird            :story:

Why are we manually instantiating postfix and directory for each
formatter/facet instead of using templates?

*** Rename options to transformation request                          :story:

These are not really "options"; it is a request made into yarn to
code-generate a model. We haven't yet got a proper name but it has to
somehow involve the word "request". The best way is to visualise this
as part of some API where may such requests can be made (and handled
concurrently).

This also means we need to split out the request from the context. We
should have an initialisation phase where we construct the context and
then we should be able to reuse the pipeline for many requests. This
also means that the right place to put the transform metrics is in the
request - not the context - given that these are request specific.

The best way to go about it may be to have two contexts:

- transformation context: const; loaded at start-up.
- request context: request specific context, including probing and the
  request itself.

Then:

- clients are responsible for setting up the transformation
  context. This ensures we do it only once.
- clients are also responsible for setting up the request context, but
  they then do it for each request.

Note also that a request should support multiple target models.

*** Detect unqualified stereotypes                                    :story:

If a user enters say =enumeration= instead of =yarn::enumeration= we
are providing an unhelpful error message:

: Error: Attribute type is empty: structured

This is because we validate the class as if it was an object and then
figure out that there are no types against the attributes. One easy
way to make things more useful is to detect unqualified stereotypes
and error straight away with a more useful message such as "did you
mean yarn::xyz?".

We could also do the same if the stereotype is blank ("did you mean
enumeration?").

*** Tidy-up fabric                                                    :story:

Now we have dynamic transforms, we don't really need all the classlets
we've created in fabric. We can get away with probably just the
dynamic transform, calling all the factories.

*** Clean-up archetype locations modeling                             :story:

We now have a large number of containers with different aspects of
archetype locations data. We need to look through all of the usages of
archetype locations and see if we can make the data structures a bit
more sensible. For example, we should use archetype location id's
where possible and only use the full type where required.

Notes:

- formatters could return id's?
- add an ID to archetype location; create a builder like name builder
  and populate ID as part of the build process.

*** Use element ids for associations                                  :story:

There doesn't seem a need for having entire names for associations;
these are used to find information by ID anyway. We should try to
convert them to element id's instead and see what breaks.

- transparent, opaque associations
- base, derived visitor
- contained by

We can't do this for:

- visitor: we use the name in the formatter.

Actually there is a reason for this: we use the names to build the
file paths and the includes. We need to add some comments.

*** Add facet validation against language standard                    :story:

With the move of enablement to yarn, we can no longer validate facets
against the language standard. For example, we should not allow
hashing on C++ 98. The code was as follows:

#+begin_src c++
void enablement_expander::validate_enabled_facets(
    const global_enablement_configurations_type& gcs,
    const formattables::cpp_standards cs) const {
    BOOST_LOG_SEV(lg, debug) << "Validating enabled facets.";

    if (cs == formattables::cpp_standards::cpp_98) {
        using formatters::hash::traits;
        const auto arch(traits::class_header_archetype());

        const auto i(gcs.find(arch));
        if (i == gcs.end()) {
            BOOST_LOG_SEV(lg, error) << archetype_not_found << arch;
            BOOST_THROW_EXCEPTION(expansion_error(archetype_not_found + arch));
        }

        const auto& gc(i->second);
        if (gc.facet_enabled()) {
            const auto fctn(gc.facet_name());
            BOOST_LOG_SEV(lg, error) << incompatible_facet << fctn;
            BOOST_THROW_EXCEPTION(expansion_error(incompatible_facet + fctn));
        }
    }

    BOOST_LOG_SEV(lg, debug) << "Validated enabled facets.";
}
#+end_src

It was called from the main transform method in enablement transform,
prior to uptading facet enablement.

*** Tidy-up assistant API                                             :story:

Now we have element in assistant we can start removing the need for
element in the calls, making the templates simpler.

*** Facets incompatible with standards                                :story:

Some facets may not be supported for all settings of a language. For
example the hash facet is not compatible with C++ 98. We need to have
some kind of facet/formatter level validation for this.

*** Handcrafted templates                                             :story:

At present we generate constructors, swap, etc. for handcrafted
classes. Ideally users should be able to create a profile that enables
the things they want to see on a template and then associate it with a
stereotype. For this we will need aspect support.

*** Drop the original extension in tailor                             :story:

Filenames in tailor look weird:

: dart.dia.json

it should just be:

: dart.json

*** Move dependencies into yarn                                       :story:

Actually the dependencies will be generated at the kernel level
because 99% of the code is kernel specific. However, we need to make
it an external transform.

Tasks:

- create the locator in the C++ external transform
- create a dependencies transform that uses the existing include
  generation code.

*Previous understanding*

It seems all languages we support have some form of "dependencies":

- in c++ these are the includes
- in c# these are the usings
- in java these are the imports

So, it would make sense to move these into yarn. The process of
obtaining the dependencies must still be done in a kernel dependent
way because we need to build any language-specific structures that the
dependencies builder requires. However, we can create an interface for
the dependencies builder in yarn and implement it in each kernel. Each
kernel must also supply a factory for the builders.

*** Consider folding quilt into yarn                                  :story:

In the far distant future, when we finally finish merging all the
quilt specific stuff into yarn (e.g. formattables), it actually makes
sense to deprecate quilt as a concept. Yarn then becomes the central
point, and frontends and backends are just implementations that hook
into it. Thus we then have simply =yarn.cpp= and =yarn.csharp=.

However, there is still a concept that needs to be captured: the
kernel. That is, a set of backends that work together to provide some
kind of "service". In quilt's case the basic type definitions. We
could potentially want to implement other backends that are totally
distinct from quilt. However, we still do not have a concrete use case
for this. Thus it may make more sense to just fold now and worry about
these more flexible use cases when they arrive. We can always rename.

*** Code-generate annotations type templates                          :story:

Tasks:

- create a meta-model element for type templates. Add container in
  exomodel for it. Name: =yarn::annotation_type_template=?
- add frontend support for the type template element.
- add a transform that reads all the meta-data from type templates and
  populates the yarn element of the type template. Add this transform
  to the exomodel transforms, at the end of the chain (e.g. after
  annotations).
- create a meta-model element for the initialiser of type templates,
  made up of all type templates in the model. Add a container of
  initialiser in endomodel.
- add a transform that moves all of the type templates into the
  initialiser. This can be done as part of the exomodel to endomodel
  transform. Or maybe we should have a stand alone transform, and the
  final transform simply ignores type templates.
- create a registrar in annotations that registers type templates.
- create a stitch template for the initialiser, taking the registrar
  as an argument, and registering all type templates.
- add all type templates to all models, and generate the type
  initialisers.
- hook the type initialisers to the initialisers.
- change type group repository to initialise from the registrar.
- delete all type groups JSON and hydrator and related code.

Merged stories:

*Initialisation of meta-data*

At present we are reading meta-data files for every transformation. In
reality, it makes no sense to allow the meta-data files to change
dynamically, because the consumers of the meta-data are hard-coded. So
it would make more sense to treat them as a initialisation step. This
will make even more sense when we code-generate the types instead of
using JSON. Then we can hook up the generated code to the
initialisers.

*** Cannot make qualified references to concepts                      :story:

At present it is not possible to consume concepts defined in a
referenced model, nor is it possible to refer to a concept in a
different module from the module in which the element is in, e.g.: say
concept C0 is declared in module M0; all types of M0 can have C0 as
stereotype and that will resolve. However any types on any other
module cannot see the concept.

One suggestion is to allow scoped names in stereotypes:
=module::Concept=.

The heuristic for concept resolution is then:

- external modules are never part of the scoped name;
- on a scoped concept with M names, we first start by assuming that
  the first name is the model module and M-2 is/are the internal
  module(s). We try this for all names in M-2, e.g. first two names
  are model modules and M-3 names are internal modules and so forth.

*** Add support for object templates that work cross-model            :story:

We've implemented support for cross-model inheritance in sprint 87 but
we did not cover object templates. Most of the approach is the same,
but unfortunately we can't just reuse it.

Tasks:

- we need a refines field which is a text collection.
- we need refinement settings, factory etc.
- update parsing expander.

*** Move formatting styles into yarn                                  :story:

We need to support the formatting styles at the meta-model level.

*** Throw on unsupported stereotypes                                  :story:

In some cases we may support a feature in one language but not on
others like say ORM at present. If a user requests ORM in a C# model,
we should throw.

If we are in compatibility mode, however, we should not throw.

Note that we are already throwing if a stereotype is totally
unknown. The problem here is that the stereotype is known, but not
supported for all kernels. This is a bit trickier.

We also need to check the existing code in stereotypes transform to
stop trowing if compatibility flag is on.

*** Change order of includes according to Lakos major design rule     :story:

Lakos says:

#+begin_quote
The .c file of every component should include its own .h file as the
first substantive line of code.
#+end_quote

We decided to include it as the last line. However, Lakos approach has
the side-effect of automatically detecting headers that are missing
includes. We used to do this manually by generating =.cpp= files that
just included the header but then had to remove it because it was
slowing down compilation. With Lakos approach we get the best of both
worlds.

We need to also update the generated code to follow this
approach. This will require some thinking.

*** Move element segmentation into yarn                               :story:

We've added the notion that an element can be composed of other
elements in quilt, in order to handle forward declarations. However,
with a little bit of effort we can generalise it into yarn. It would
be useful for other things such as inner classes. We don't need to
actually implement inner classes right now but we should make sure the
moving of this feature into yarn is compatible with it.

Notes:

- seems like we have two use cases: a) we need all elements, master
  and extensions and we don't really care about which is which. b) we
  only want masters. However, we must be able to access the same
  element properties from either the master or the extension. Having
  said all that, it seems we don't really need all of the element
  properties for both - forward declarations probably only need:
  decoration and artefact properties.
- we don't seem to use the map in formattables model anywhere, other
  than to find master/extension elements.
- Yarn model could have two simple list containers (masters and
  all). Or maybe we don't even need this to start off with, we can
  just iterate and skip extensions where required.
- so in conclusion, we to move decoration, enablement and dependencies
  into yarn (basically decoration and artefact properties) first and
  then see where segmentation ends.

Tasks:

- add a concept for element extensions: =Extensible=. Contains a list
  of element pointers.
- populate it with the extensions.
- change enablement to merge all element properties of extensible
  elements.

*** Create a yarn locator                                             :story:

We need to move all functionality which is not kernel specific into
yarn for the locator. This will exist in the helpers namespace. We
then need to implement the C++ locator as a composite of yarn
locator. It will live in fabric.

*Other Notes*

At present we have multiple calls in locator, which are a bit
ad-hoc. We could potentially create a pattern. Say for C++, we have
the following parameters:

- relative or full path
- include or implementation: this is simultaneously used to determine
  the placement (below) and the extension.
- meta-model element:
- "placement": top-level project directory, source directory or
  "natural" location inside of facet.
- archetype location: used to determine the facet and archetype
  postfixes.

E.g.:

: make_full_path_for_enumeration_implementation

Interestingly, the "placement" is a function of the archetype location
(a given artefact has a fixed placement). So a naive approach to this
seems to imply one could create a data driven locator, that works for
all languages if supplied suitable configuration data. To generalise:

- project directory is common to all languages.
- source or include directories become "project
  sub-directories". There is a mapping between the artefact location
  and a project sub-directory.
- there is a mapping between the artefact location and the facet and
  artefact postfixes.
- extensions are a slight complication: a) we want to allow users to
  override header/implementation extensions, but to do it so for the
  entire project (except maybe for ODB files). However, what yarn's
  locator needs is a mapping of artefact location to  extension. It
  would be a tad cumbersome to have to specify extensions one artefact
  location at a time. So someone has to read a kernel level
  configuration parameter with the artefact extensions and expand it
  to the required mappings. Whilst dealing with this we also have the
  issue of elements which have extension in their names such as visual
  studio projects and solutions. The correct solution is to implement
  these using element extensions, and to remove the extension from the
  element name.
- each kernel can supply its configuration to yarn's locator via the
  kernel interface. This is fairly static so it can be supplied early
  on during initialisation.
- there is still something not quite right. We are performing a
  mapping between some logical space (the modeling space) and the
  physical space (paths in the filesystem). Some modeling elements
  such as the various CMakeLists.txt do not have enough information at
  the logical level to tell us about their location; at present the
  formatter itself gives us this hint ("include cmakelists" or "source
  cmakelists"?). It would be annoying to have to split these into
  multiple archetypes just so we can have a function between the
  archetype location and the physical space. Although, if this is the
  only case of a modeling element not mapping uniquely, perhaps we
  should do exactly this.
- However, we still have inclusion paths to worry about. As we done
  with the source/include directories, we need to somehow create a
  concept of inclusion path which is not language specific; "relative
  path" and "requires relative path" perhaps? These could be a
  function of archetype location.

*** Add a modeline to stitch                                          :story:

It would be nice to be able to supply the mode and other emacs
properties to stitch templates. For that we just need a special KVP
used at the top that contains the modeline:

: <#@ modeline="-*- mode: poly-stitch; tab-width: 4; indent-tabs-mode: nil; -*-" #>

Stitch can read this KVP and ignore it.

*** Create "opaque" kernel and element properties                     :story:

As part of the element container, we can have a set of base classes
that are empty: =opaque_element_properties=. This class is then
specialised in each kernel with the properties that are specific to
it. We probably need an equivalent for:

- kernel level properties
- element level properties
- attribute level properties.

We then have to do a lot of casting in the helpers.

Once we got these opaque properties, we can then create "kernel
specific expanders" which are passed in to the yarn workflow. These
populate the opaque properties.

*** Move helpers into yarn                                            :story:

Looking at helpers, it is clear that they are common to all
languages. We just need to rename the terminology slightly -
particularly wrt to streaming properties - and then move this code
across into yarn.

*** Move facet properties into yarn                                   :story:

We should be able to handle these generically in yarn.

*** Move ORM camel-case and databases into yarn                       :story:

We should handle this property at the ORM level, rather than at the
ODB level.

Similarly, we should move the ODB databases into yarn and make that a
ORM-level concept.

*** Distinguish between meta-types that require canonical archetypes  :story:

At present it is not possible to know which meta-types require
canonical archetypes and which don't. In the validation we said:

:         * We must have one canonical formatter per type per facet.
:         * FIXME: this check is broken at the moment because this is
:         * only applicable to yarn types, not fabric types. It is also
:         * not applicable to forward declarations. We need some
:         * additional information from yarn to be able to figure out
:         * which types must have a canonical archetype.

We should have some kind of flag in yarn to distinguish. This still
requires a bit of thinking.

*** Tidy-up of inclusion terminology                                  :story:

Random notes:

- imports and exports
- some types support both (headers)
- some support imports only (cpp)
- some support neither (cmakelists, etc).

** Deprecated
