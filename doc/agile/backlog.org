#+title: Backlog
#+options: date:nil toc:nil author:nil num:nil
#+todo: ANALYSIS IMPLEMENTATION TESTING | COMPLETED CANCELLED
#+tags: story(s) epic(e) task(t) note(n) spike(p)

* Backlog
** Development Stories

Stories that we intend to look at, at some point.

*** Support for file level comments via meta-data                     :story:

We could easily have a tag for file level comments and transport that
all the way to the output. The only problem is that it would be a one
liner only so it may not be that useful.

Multi-line support could be simulated by concatenating multiple
entries - cumbersome but workable...

*** Caching qname lookups                                             :story:
    CLOCK: [2013-10-30 Wed 18:02]--[2013-10-30 Wed 18:03] =>  0:01
    CLOCK: [2013-10-30 Wed 08:38]--[2013-10-30 Wed 08:43] =>  0:05

Once the model has been merged and resolved, all qnames in the model
all known to resolve to a valid type, model or module. This means we
could cache in the qname itself a pointer to the object the qname
resolves into. There are two problems with this approach:

- we do not have a base class that covers types, models and
  module. one could be created (=modeling_entity=?) with an associated
  visitor. but then:
- formatters are not designed to think at the =modeling_entity= level;
  a formatter that does types may not necessarily be able to do
  modules or models. Thus we would need to convert from a
  =modeling_entity= to a type, model or module before we get to the
  formatter.

However one imagines that a great number of lookups would be avoided
if this was possible.

*** Models should have an associated language                         :story:
    CLOCK: [2013-10-30 Wed 08:07]--[2013-10-30 Wed 08:15] =>  0:08

Certain models (e.g. system / library models) can only be used in a
give language; for example =boost= and =std= only make sense in C++. A
.Net library model would only make sense in .Net, etc. These are
Language Specific Models (LSM). Once a model depends on a LSM it
itself becomes an LSM and it should not be able to then make use of
models of other languages nor should one be able to request a code
generation for other languages.

However, one day we will have a system model which is a Language
Agnostic Model (LAM). The system model will provide a base set of
functionality across languages such as containers, and for each type
it will have mappings to language specific types. The mapping is
declared as meta-data in the appropriate section
(i.e. =tags::cpp::mapped_type= or something of that ilk). If a model
depends only on LAMs, it is itself a LAM and can be used to generate
code on any supported language (presumably a supported language is
defined to be that for which we have both mappings and a code
generation backend).

A first step for this would be to have a language enumeration in SML
which is a property of the model, and one entry of which is "language
agnostic".

*** Includer generation should be done from meta-data                 :story:
    CLOCK: [2013-10-27 Sun 20:40]--[2013-10-27 Sun 20:58] =>  0:18

It would be nice if we could determine which includer files to create
by looking at the meta-data. For this we need a notion of an inclusion
group, defined at the model level:

- =cpp.types.includers.general=
- =cpp.types.includers.value_objects=
- ...

Under each of these one would configure the aspect:

- =cpp.types.includers.general.generate=: =true=
- =cpp.types.includers.general.file_name=: =a/b/c=
- =cpp.types.includers.general.is_system=: =false=

Then, each type, module etc would declare its membership (as a list):

- =cpp.includers.member=: =cpp.types.includers.general=
- =cpp.includers.member=: =cpp.types.includers.value_objects=
- ...

*** Copyright holders is scalar when it should be an array            :story:

At present its only possible to specify a single copyright holder. It
should be handled the same was as odb parameters, but because that is
done with a massive hack, we are not going to extend the hack to
copyright holders. Instead, this story will be handled when we move
over to using =boost::property_tree::ptree=.

*** Forward declaration is not always correct for services            :story:

In cases where we used a service as a way of declaring a stand alone
function (such as the traversals in SML), the forward declarations do
not match the header file at all. In this cases we should use
=nongeneratable= rather than =service= stereotypes, and perhaps when
that happens we should switch off forward declarations?

*** Remove speculative facet layers for hash and serialization        :story:

For some unfathomable reason we decided to add a layer of indirection
for both hash and serialization. This is for speculative reasons as in
the future we may want to add boost hash and other forms of
serialization. However, in keeping with the (often violated) rule that
we never add code without a use case, we need to remove this.

*** Add tests for tagging of modules, primitves and enumerations      :story:
*** Implement the property cache in SML                               :story:
*** Add tests for all permutations of the domain formatter            :story:
*** Add tagging for propagatable parameters                           :story:

Some implementation specific parameters should be propagated along the
composition graph (e.g. boost serialisation status disabled). We could
spot these parameters whilst building the model and do the propagation
there and then.

We need to create language specific classes to propagate parameters,
assign proper defaults to them, etc.

*** Parameter to disable cpp file                                     :story:

It would be really useful to define a implementation specific
parameter which disables the generation of a cpp file for a
service. This would stop us from having to create noddy translation
units with dummy functions just to avoid having to define exclusion
regexes.

*** Add getter and setter prefixes                                    :story:

External users may have getter and setter prefix conventions such as
=set_prop= or =SetProp=. It would be nice if we could pass in a
getter/setting prefix and then dogen would append them when converting
the diagram, e.g. =--getter-prefix=set_=.

We should check what ODB has done for this and implement the same
pattern.

*** Fix spelling of =rountrip_type=                                   :story:

Should be =roundtrip_type=.

*** "Data driven" includer                                            :story:

We should simply go through all the types in the SML model and for
each type and each facet create the corresponding inclusion
path. locator can be used to generate standard paths, and a model
specific mapping is required for other models such as std.

Include then takes the relationships extracted by extractor, the
mappings generated by this mapper and simply appends to the inclusion
list the file names. it also appends the implementation specific
headers.

This story is very closely related to [[*Loading%20external%20models%20from%20file][profiles]].

*** Formatters should cache qname formatting                          :story:

We seem to re-format the same qname lots of times. We should just use
a =std::ostringstream= to format once and reuse the resulting
string. Probably worth doing this change after the performance tests
are in.

*** Refactor Licence formatter                                        :story:

- year is hard-coded to 2012: At present the licence formatter has an
  hard-coded year of 2012. It should really be a parameter passed in.
- we should really only have one formatter that understands different
  commenting syntaxes (e.g. cmake comments, c++ comments).
- we should support multiple licences.

*** Add a code generation marker                                      :story:

Now that we've started to mix-and-match hand-crafted code with
code-generated code, we should really have an easy way to distinguish
which files are which. A simple comment at the top for files generated
by dogen (with the corresponding dogen version) would suffice. This
could be done in a similar fashion to the licence formatter. It should
either be after the licence or at the very top and take on the
responsibilities of emacs/vi headers.

We should also add a model level version which will be stamped on the
marker.

In addition, we should also stamp the dogen version too. However, this
will make all our tests break every time there is a new commit so
perhaps we need to have this switched off by default.

*** Split floating point stream settings from double                  :story:

We had a problem where the output of floating point numbers was being
truncated due to scientific notation being used. A quick fix was to
just update the properties of all streams which use either doubles,
floats or _bools_ with precision etc settings. The real fix is to
distinguish between the two such that we only enable =bool= related
settings when dealing with bools and floating point settings when
dealing with =double= or =float=.

*** Split is floating point like from int like in view model          :story:

At present we only have a single test data generator helper method for
any numeric type: =is_int_like=. This works ok, but it means we are not
generating useful test data for doubles, e.g: =1.0= instead of a
slightly more useful =1.2345= or some such number.

We need a =is_floating_point_like= method to be able to distinguish
between them, and then the associated changes in the generators to
create floating point numbers.

*** Stereotypes to disable facets                                     :story:

At present we do not generate files for all facets in a service other
than types. However, the correct fix is to have stereotypes to disable/enable
facets:

- =nonhashable=, =hashable=: hashing support
- =nontestable=, =testable=: test data support
- =nonserializable=, =serializable=: serialisation support
- =nonimplementable=, =implementable=: service does not have a CPP file
- =nonstreamable=, =streamable=: IO support

These stereotypes can then be combined:

: service,nonimplementable,serializable

Results in a service for which there will only be a header file and
serialization support.

By default services would have all aspects other than domain disabled,
entities and values would have all aspects enabled.

*** System models set meta-type to invalid                            :story:

Something is not quite right on the resolution logic

*** Improve the integration of dogen with dia                         :story:

It would be great if the model generation in dia was slightly more
interactive:

- dia could have a button to run/configure an external tool, where the
  setup for dogen would be kept
- pushing an execute button would code generate
- pushing a validate button would validate the current diagram, taking
  into account declared references. references to types that are not
  resolved could make the class or function go red.

The idea is to do the least intrusive changes in dia that would
provide us with this support. In order to access dogen, instead of
running the executable and parsing the command line output, it would
make more sense to create a C interface that supports these specific
use cases (and nothing else).

*** Add support for qualified class names in dia                      :story:

It has become apparent that creating large packages in dia and placing
all classes in a large package is cumbersome:

- there are issues with the large package implementation in dia,
  making copying and pasting a dark art; its not very obvious how one
  copies into a package (e.g. populating the child node id correctly).
- models do not always have a neat division between packages; in
  dogen, where packages would be useful, there are all sorts of
  connections (e.g. inheritance, association) between the package and
  the model "package" or other packages. Thus is very difficult to
  produce a representative diagram.

A solution to this problem would be to support qualified names in
class names; these would be interpreted as being part of the current
model. One would still have to define a large package, but it could be
empty, or contain only the types which only have connections inside
the package, plus comments for the package, etc.

*** Convert all files in library into JSON                            :story:

We started off by using the INI format, but then subsequently found it
too inexpressive to be able to carry SML representations and started
using JSON. However, modeline groups, etc are still in INI format.

*** Create an SML level concept for facets                            :story:

In reality, "facets" are not a C++ thing; they are language
neutral. They are, however, expressed differently in different
languages. For example:

- types: same on all languages
- debug_printing: overloaded operator<< in C++, toString() in Java,
  ToString() in C#, etc.
- serialisation: slightly less obvious, but effectively the most
  "native" serialisation available for the given programming
  language. For C++ this is boost serialisation.
- hashing: language specific support for hashing, in C++ either std
  hash or boost hash, in Java/C# overloading of hash functions.
- test_data: some facilities for test data generation
- relational: bindings for relational databases. ODB in C++.

We can introduce these concepts at the SML level, probably at the
=model= and =abstract_object= level; we can then do further
translation at the language level, as required.

*** Consider model as a container of types                            :story:

At present model is composed of objects, primitives, concepts,
modules, etc. We could bring together all descendants of types into a
single container (e.g. types). However, in places we do thinks like
looking at the primitive container to see if the container has any
primitive types - these would become slower as we'd now be looking at
the entire type collection. Need to look at all usages of these
containers in the code to see if this would be a win or not.

*** Consider adding YQL support                                       :story:

YQL offers a REST based API with lots of interesting information; an
example of the information provided is available [[https://github.com/yql/yql-tables/blob/master/yahoo/finance/yahoo.finance.quant.xml][here]]. There should be
somewhere a matching XML schema for each of these queries, at least
for the end points that return XML. It would be great if one could
take one of those schemas and generate an SML representation for them.

More generally, it would be great if dogen was able to create a domain
model off of an XML schema. However, we already have the Code
Synthesis [[http://www.codesynthesis.com/products/xsd/][XSD tool]] for that, so maybe this is just scope creep.

*** Consider adding merging code generation support                   :story:

At present it is not possible to manually add methods to a class that
was code generated; one must stop code generating the class and
maintain the whole class manually. However, in some cases it makes
sense to have a combination of both:

- value objects need helper methods such as for example boolean
  properties (e.g. =is_empty=) that make use of other properties, or
  simple methods such as population etc that really belong to the
  object rather than an external service
- services sometimes need state and it would be good if we could
  manage that via code generation.

For this we need a merging code generator: that is, a code generator
that is aware of code that was crafted manually and does not overwrite
it - but instead "intelligently" merges manual with code generated
code.

From the beginning we avoided this because we thought it would be too
complicated for dogen. However, its increasingly becoming apparent
that this is a needed feature for the real world - there are many
cases where we are working around this deficiency. A few solutions are
possible:

- let the code generator manage the header file and create two types
  of CPP files, one which includes the other: a manual and an
  "automatic" one. This would effectively separate the two types of
  code. For this dogen would have to be able to generate complex types
  in operations (e.g. we'd have to solve the lack of support for
  =const std::string&=).
- use clang to do the merging. this probably means adding some kind of
  attribute to every method - possibly using C++ attribute support
  (e.g. =[ [generated ] ]= and/or =[ [ manual ] ]= (spaces due to org
  mode). We could then say to clang: read current state of the file,
  grab every non-generated method and copy them across to the newly
  code generated file. Merging could be the final stage before
  writing. In addition, we should also have some meta-data to
  determine which files require merging. The meta-data could be
  populated automatically (e.g. grep for the manual attribute) or
  manually.

*** Create includers for value objects only                           :story:

At present we are using the facet includers in unit tests. This is not
ideal because it means that every time we do a change in a service
header, all tests recompile. In reality we should have two types of
inclusions:

- canned tests should include only value objects, etc - e.g. no
  services.
- service tests should include the header for the service and any
  additional dependencies the service may require.

Perhaps we could have a second type of includer that only has value
objects, etc.

*** Validate inheritance graph does a lot of double-checks            :story:

In method =validate_inheritance_graph=, we should really just check
that the parent exists since we know all objects get checked
anyway. this results in a lot of double-checks for no reason.

*** Concept resolution is not particularly clean                      :story:

At present resolver is tasked with converting the hierarchy of
concepts into a container with a set of =qnames= that represent the
concepts the type models. It takes into account both the inheritance
from a concept perspective (e.g. refinement) and the type-related
inheritance (e.g. if our parent already models a concept we do not
have to model it too). However, the code is very hacky and needs to be
cleaned up.

*** Do not copy models in merger                                      :story:

At present we are adding the partial models into the merger by copying
them into an associative container. It would be nicer to avoid the
copying as it adds no value. This should wait until we have a way to
get performance numbers out.

*** Towards a more generic use of implementation specific parameters  :story:

We should do an inventory of all dogen features which can be
reimplemented as implementation specific parameters. For example,
immutability should result in a generic parameter being added to the
type at the SML level:

: immutable = true

which then gets resolved into a set of language specific parameters:

: cpp.copy_constructor.status = disabled
: cpp.setters.status = disabled
: ...

The formatter then looks for these tags to decide whether to add a
method or not. If we had more languages, they would have equivalent
formatting commands.

The same would apply to facets. These would have a top-level generic
parameter such as =hashing=:

: hashing = true

Which then expands to implementation specific hashing:

: cpp.hashing.std_hashing = true

or

: cpp.hashing.boost_hashing = true

The facet is now just a short-hand for a set of implementation
specific parameters. There is some default mapping applied in this
grouping. The user can shortcut the process by disabling the mapping
and supplying implementation specific parameters:

: hashing = false
: cpp.hashing.boost_hashing = true

Assuming =std_hashing= as a default.

In addition, depending on the parameter, it may be propagatable /
expandable. For example, if hashing is set to false in a type at the
bottom of a graph relationship, we must propagate it to all members of
the graph. Similarly, if hashing is disabled in the model, we must
propagate it to all types in the model.

*** Adding linking libraries is not handled                           :story:

At present whenever a model requires additional link library targets
we need to disable CMake generation and do it by hand. However:

- for well-known dependencies such as boost we could create a
  convention (e.g. assume/require that the CMake boost libraries flags
  are set via find boost)
- for user level dependencies we should add implementation specific
  parameters at the model level.

*** Test data generator does not detect cycles in object graph        :story:

At present we handle composition correctly, but not other forms of
cycles in the object graph.

Let model M be composed of class A with a member of type class B, and
class B with a member of type =shared_ptr= to class A. The test data
generated for such model will contain an infinite loop. We need a way
to detect such loops, potentially in SML, and then generate code which
breaks the loop.

This could be done by explicitly checking if the type of any member
variable loops back into the type itself. Of course one could conceive
cycles that involve many edges in the object graph, and for these we'd
still generate invalid code.

Another approach would be to have an unordered map of type
association; the map would have the IDs of every type as we go further
into the association graph. It would be pushed and popped as we go in
and out of branches; at the same time we need to have a look back
capacity to see the few elements in the stack. When a pattern emerges
that involved types of a certain ID, they would stop creating any
further associations.

*** Split a fully formed model from partial models                    :story:

We should really have two distinct types to represent the model that
is returned from the dia to sml transformer from the model returned by
the merger. Potentially this could be called =partial_model=.

*** Create a =key_extractor= service                                  :story:

Continuing from Sprint 26.

We need a way to automatically extract a key for a =keyed_entity=.
The right solution is to create a service to represent this
concept.

Injector creates objects for these just like it does with keys; the
C++ transformer intercepts them and generates the correct view models.

*** Add content to the introduction in manual                         :story:
*** Use explicit casting for versioned to unversioned conversions     :story:

Continuing from previous iteration, see description in Sprint 26.

*** Consider not creating unversioned keys for single property        :story:

If a key is made up of a single property, its a bit nonsensical to
create an unversioned key. We should only generate the versioned
key. However, it does make life easier. Wait for real world use cases
to decide.

*** Detect invalid child nodes                                        :story:

When copying a set of classes from a diagram, where these classes
where contained in a package, dia seems to copy across the =childnode=
id. This is a problem because when pasted in a new diagram, if those
classes are not in a package there is now the potential for total
mismatching - for instance, they could be children of an
association. Dogen should validate that children belong to UML
elements which can have children, and if not issue good error
messages - perhaps even talking about the possible cause for the
error.

*** Refactor Dia to SML transformer                                   :story:

- remove all properties from context which are used only internally in
  the transformer.
- split context into inputs and outputs: =transformation_result= as a
  candidate for the outputs.
- inputs are passed in at construction time and remain constant.
- each transformation method returns a value which can be slotted into
  the model by the workflow, contained in a transformation result.
- this does mean a lot of concatenation at the workflow level though.

*** Add tests for SML workflow                                        :story:

We don't seem to have any. A few come to mind:

- model with no generatable types returns false
- model with generatable types returns true
- multiple models get merged
- system models get injected

*** Rename nested qname to composite qname                            :story:

New understanding:

This story requires further analysis. Blindly following the composite
pattern was tried but it resulted in a lot of inconsistencies because
we then had to follow MEC-33 and create =abstract_qname=; however, the
nested qname does not really behave like a composite qname; its more
like the difference between a type in isolation and a type
instantiated as an argument of a function. For example, whilst the
type in isolation may have unknown template parameters, presumably, as
an argument of a function these have been instantiated with real
types.

Previous understanding:

We should just follow the composite pattern in the naming.

*** Injection framework                                               :story:

We need a more generic way of handling system types injection into
models. This is because there is a number of things that can be
derived from the existing model types:

- keys
- diff support
- reflection
- cache code
- etc.

So we need to:

- make injector a composite of injectors that do the real work such as
  =key_injector=. internally =injector= just delegates the work to
  these classes.
- injector decides which internal injectors to use based on options
  passed in.
- in the IoC spirit, we should probably create a =injector_interface=.

*** Register types for multiple models is misbehaving                 :story:

It seems that somehow we're clobbering the type registration of one
model with another in register types. This is probably because we are
reusing type id's somehow. This wasn't a problem until now because we
were not using inheritance in anger but with the sml changes, it is a
problem as one cannot load dia and sml types off the same registration
(e.g. as in XML serialisation helper).

One solution for this problem would be to create serialisers which
hide the machinery of serialisation internally; one should be able to
just pass in a stream in and get a type out.

*** Comments seem to be trimmed                                       :story:

For some reason we seem to be munching any blank lines at the end of
comments. We should only remove the lines with the well known dogen
marker, all other lines should be left untouched.

*** Type resolution in referenced models                              :story:

We did a hack a while ago whereby if a type is of a referenced model,
we don't bother resolving it. As an optimisation this is probably
fine, but however, it hides a bug which is that we fail to resolve
properties of referenced models properly. The reason why is that these
properties have a blank model name. We could simply force it to be the
name of the referenced model but then it would fail to find
primitives. So we leave it blank during the dia to sml translation and
then if it gets to the resolver, it will not be able to resolve the
type. We could add yet another layer of try-logic (e.g. try every
model name in the references) but it seems that this is just another
hack to solve a more fundamental problem. The sort of errors one gets
due to this are like so:

: 2013-06-29 23:10:34.831009 [ERROR] [sml.resolver] Pod has property with undefined type:  { "__type__": "dogen::sml::qname", "model_name": "", "external_module_path": [ ] , "module_path": [ ] , "type_name": "qname", "meta_type": { "__type__": "meta_types", "value": "invalid" } }
: 2013-06-29 23:10:34.831294 [FATAL] [dogen] Error: /home/marco/Development/kitanda/dogen/projects/sml/src/types/resolver.cpp(202): Throw in function dogen::sml::qname dogen::sml::resolver::resolve_partial_type(const dogen::sml::qname&) const
: Dynamic exception type: boost::exception_detail::clone_impl<dogen::sml::resolution_error>

*** Visitor adaptor for usage in ranges                               :story:

It would be great if we automatically generated an adaptor to visitors
which could be plugged into a range. Internally the adaptor would
perform the accept on its =operator()=. We could also have an adaptor
for a =std::pair= which would be templatised on the first member of
the pair. Or should one just use a keys or values range iterator.

*** Visitor with =std::function= for each =visit= method              :story:

It would be nice if the code generator created a visitor which has as
its properties a set of =std::function= which match the signature of
the visit functions; then the visit functions would just check that
the functions have been assigned and call them. If not, throw.

*** Improve logging of disconnected inheritance objects               :story:

At present the error message for an inheritance object in dia which
has less than two connections is less than helpful:

: 2013-06-26 22:58:50.236488 [ERROR] [dia_to_sml.processor] Expected 2 connections but found: 1
: 2013-06-26 22:58:50.236917 [FATAL] [dogen] Error: /home/marco/Development/kitanda/dogen/projects/dia_to_sml/src/types/processor.cpp(166): Throw in function dogen::dia_to_sml::processed_object dogen::dia_to_sml::processor::process(const dogen::dia::object&)
: Dynamic exception type: boost::exception_detail::clone_impl<dogen::dia_to_sml::processing_error>
: std::exception::what: Expected 2 connections but found: 1
: [tag_workflow*] = Code generation failure.

We should really try to detail which object ID failed, as well as
details of the connected object if possible, etc.

*** Check concept properties for identity                             :story:
    CLOCK: [2013-06-24 Mon 22:33]--[2013-06-24 Mon 22:36] =>  0:03

When we added concepts we didn't had a link to the processing of
identity attributes. This means that if we get a property via modeling
a concept it is not processed and added to the keys.

Update injector to follow concepts.

*** Sort model dependencies                                           :story:

It seems the order of registration of models has moved with recent
builds of dogen (1418). Investigate if we sort the dependencies and if
not, sort them.

*** Use pimpl for a few "one-shot" services                           :story:

We have quite a few services where it would be great to have
transactional semantics. For example, when building a graph in
=sml::grapher=, it would be great if one could have a list of objects
to graph as an input and some kind of =grapher_result= as the
output. From a potential =grapher_interface= it would look like a
simple method in the interface, almost static. The problem with this
approach of course is that it makes the =grapher_interface=
implementations cumbersome because one has to pass all parameters to
all internal methods instead of using class state. The present
approach is to make it a "prepare" and then "use" sort of service,
causing the usual nonsensical methods of "is it finished yet" and "are
you trying to use the service a second time" (e.g. =is_built=,
etc). Even if we pass in all the inputs in the constructor, its still
not ideal. There are two options:

- set member variables inside the "one-shot" function and then unset
  them at the end;
- have a =grapher= implementation which uses a =grapher_impl= that
  does provide a sensible implementation. We used to do this inside
  the =.cpp= files but then they became too big to manage.

*** Assignment operator should be protected in ABC                    :story:

As per MEC 33. We should probably do the same for the move and copy
constructors.

*** Remove generation types in SML                                    :story:

SML knows not of code generation so we shouldn't have a generation
type in it. What we should have instead is a way of identifying a type
as belonging to the target model or not. In a way, its qname already
does that.

Partial generation is actually a c++ model decision based on how much
features it supports.

*** SML models could have a model classification                      :story:

Consider creating an enumeration for model classification (e.g. type
of the model):

- relational model
- core domain model
- generic sub-domain model
- segregated core model

This still requires a lot of analysis work around the DDD book.

*** Change transformation code to use a type visitor                  :story:

Now we have a base type, we could probably simplify some of the
transformation code:

- dia to sml
- sml to c++
- potentially merger

*** Test data generator with immutability looks wrong                 :story:

We are using the full constructor for immutability, but its not clear
how that would work on a inheritance tree. Ensure we have test cases
for this.

*** Make EOS support optional                                         :story:

With the release of boost 1.54 We can almost compile dogen with a
vanilla boost. once we make ODB optional, the only blocker would be
EOS. We should make it optional too. This is not so easy because it
would break the tests as the output is expected to contain EOS
stuff. Perhaps we should consider removing it altogether?

*** Add support for boost concept                                     :story:

Now dogen supports concepts, the natural thing to do is to express
them in C++ code. This could easily be done using boost concept, or
the C++-14 concepts light.

See [[http://www.boost.org/doc/libs/1_53_0/libs/concept_check/creating_concepts.htm][Creating Concepts]].

*** Add support for boost and/or std tuple                            :story:
    CLOCK: [2013-06-04 Tue 18:30]--[2013-06-04 Tue 18:32] =>  0:02
    CLOCK: [2013-06-04 Tue 18:18]--[2013-06-04 Tue 18:27] =>  0:09

It would be nice to be able to use =std::tuple= and/or =boost::tuple=
from dogen. The processing would be rather similar to containers. It
would be even nicer if one could associate an enumeration to a tuple
so that the gets would be more meaningful, e.g.:

: std::get<my_field>()

rather than

: std::get<0>()

Using =std::tuple= would mean we'd have to create our own serialisers
for it most likely.

*** Make ODB support optional                                         :story:

We should be able to build dogen without ODB. It would still generate
all the ODB headers etc, but the database test model would not be
compiled. This would be useful to reduce the number of dependencies.

*** Add support for posix_time_zone                                   :story:

At present we need to use std::string to convey time zone
information. We should be able to use the time zones available in
boost date time library.

See boost documentation: [[http://www.boost.org/doc/libs/1_53_0/doc/html/date_time/local_time.html#date_time.local_time.posix_time_zone][Posix Time Zone]]

*** Add support for GtkBuilder / Glade XML files                       :epic:

There is nothing stopping us from using a GtkBuilder / Glade XML file
as an input, create some SML from it and then generate code which
would do the boiler plate setup of the UI. With a bit more work one
could potentially even generate the bindings for a presentation model.

*** Consider renaming formatters                                      :story:

These are not really formatters; not sure what the right name should
be though; templates?

*** Add support for object cloning                                    :story:

We should have a clone method which copy constructs all non-pointer
types, and then creates new objects for pointer types.

*** Remote method invocation                                          :story:
    CLOCK: [2013-05-24 Fri 07:46]--[2013-05-24 Fri 08:13] =>  0:27

See [[*Type%20framing][type framing]], [[*Model%20and%20type%20enums][Model and type enums]],

It seems fairly straightforward to add remote method invocation to a
few select types. The following would have to be done:

- create a new stereotype like =dispatchable=, =remotable= or suchlike
- create a new stereotype: interface.
- add support for interface code generation.
- validation: model must have a model ID, thought to be unique across
  models.
- validation: types must be marked as both =remotable= and
  =interface= and have a unique type ID in the model.
- validation: types must have at least one public method
- injector: if at least one type is =remotable=, a new system
  package is created: =rmi=.
- injector: a system enumeration will be created with all the
  supported serialisation types. actually, we should create this
  anyway in serialisation or reflection.
- rmi will contain one class that represents a "frame". this
  frame will be composed as follows: model ID, type ID, serialisation
  type, raw buffer. we need to look at RMI terminology to come up with
  a good name for this frame.
- messages: for each method that exists in each dispatchable service,
  a message class will be created with a name following some well
  defined convention such as =CLASS_NAME_METHOD_NAME=. we need
  examples to make up a sensible convention. or perhaps an
  implementation specific parameter can override the class name. the
  message class is a data object and has as attributes all of the
  parameters of the method.
- a dispatcher class will be created in dispatching. it will have as
  constructor arguments references to all the dispatchable
  services. when passed in a frame, it will hydrate it and dispatch it
  to the correct service.
- a "framer" class will be created in dispatching. it will be
  configured for a given serialisation type. it will take a message
  object, serialise it and frame it.
- we could support the notion of callbacks. for this we need to be
  able to serialise stubs as references such that when the other end
  receives it, it calls a registrar to activate a client stub.

Now we just need a way of creating some generic interfaces that take a
wire client and a wire service and plug the framer and the dispatcher
into it.

*** Inserter for enumerations shouldn't throw                         :story:

We only use the inserter for debug dumping and it could happen that we
are about to write the message for an exception when we decide to
throw. Instead we should just print unexpected/invalid value and cast
it to a numeric value in brackets.

*** Generate state diagrams                                           :story:

There is nothing stopping us from reading the UML State Chart objects
in Dia and generating an FSM off of it, using one (or both) of boost's
state machines. We could make the state machine contain inheritable
methods which could be overridden by the user manually.

*** Generate service skeleton                                         :story:

Since we already have all of the boiler plate code for services such
as licence, header guards, etc - we could just create a service
skeleton to stop us from having to copy it from the forward
declarations.

In addition to the class definition, it should also define all of the
automatic constructors, and add a private section at the bottom.

*** Add versioning support                                            :story:
    CLOCK: [2013-05-13 Mon 08:28]--[2013-05-13 Mon 08:37] =>  0:09

New understanding:

- Add versioning support by adding versions at the pod level and at
  the property level. Properties with 0 version will have no special
  handling. Properties with non-zero version (V) will have the
  following code added in serialisation:

: if (version > V)
:    // read or write property

- If a number of consecutive properties all share the same version,
  dogen will group them under the same version if. There will be no
  other special grouping or otherwise changing of order of properties.
- The pod version will be max(version) of all properties for that
  class, excluding inherited properties.
- The pod version will be stamped using boost serialisation class
  version macro, unless the pod version is zero.
- Dogen will make no validation or otherwise dictate the management of
  version numbers; its up to the users to ensure they make sensible
  backwards compatibility decisions such as adding only new properties
  and always adding to the end.
- The model version is a human level concept and has no direct
  relation to class versioning. It will be implemented as an
  implementation specific parameter in the Dia model and as a string
  in the SML model class. See [[*Add%20a%20code%20generation%20marker][Add a code generation marker]].
- Model version will be used for the following:
  - stamped on doxygen documentation for the model namespace;
  - stamped on DLLs, etc.
  - used by humans to convey the "type" of changes made to the
    diagram/model (e.g. a minor version bump is a small change, etc).

Previous understanding:

Versioning support is now available in SML, so we need to apply it to
SML itself. That is, we need a way of having two versions of an SML
model coexist, and allow Dogen to diff those two versions to make code
generation decisions so that we can add basic backwards compatibility
support.

Before we can do this, we need a way of stamping a model version into
models. This can easily be done via implementation specific
parameters. See [[*Add%20a%20code%20generation%20marker][Add a code generation marker]].

We then need to create some kind of strategy for version number
management:

- minor bumps are backwards compatible; e.g. only adding new fields.
- major bumps are not backwards compatible: e.g. deleting fields,
  classes, etc.

However, at present we only support a single version number. Perhaps
we should just declare which versions are backwards compatible and
which ones are not.

Once all of these are in place we should add versioning support to
dogen:

- add a new command line argument: =--previous-version= or something
  of the kind.
- the model supplied by this argument must have the same name as the
  model supplied by =--target=.
- change all SML types to be versioned.
- dogen will load up both models, and stamp the versions in each
  type. Merger will then be responsible for stamping the versions on
  each property, taking previous and new as input.
- for every field which is in new model but not in previous, add boost
  serialisation code to handle that.
- add unit tests with v1, v2 models.
- in order for dia diagrams with multiple versions to coexist in the
  same directory we will probably need to add the version to the
  diagram name, e.g. =sml_1.dia= or =sml_v1.dia=. We probably need
  some parsing code that looks for the last few characters of the file
  name and if it obeys a simple convention such as =_v= followed by a
  number, it ignores these for the model name and uses it for the
  version.

With this in place, when rebasing we can now do a proper comparison
between expected and actual.

Potential future feature: to put the files of different versions in
separate folders. This would allow the creation of "conversion" apps
which take types for one version and transform them into the next
version.

*** Add support for boost parameter                                   :story:

It would be nice to have boost parameter support. [[http://www.boost.org/doc/libs/1_53_0/libs/parameter/doc/html/index.html#named-function-parameters][Documentation here]].

Ideally one would mark a type with a stereotype such as =named
parameter= and this would result in a full constructor with named
parameters. However since it seems one has to add a lot of boiler
plate code, perhaps its better to have a create function on a separate
header which internally calls the appropriate setters.

*** Build shared objects instead of dynamic libraries                 :story:

With the increase in tests build speeds have started to suffer,
especially on low hardware. One potential way to mitigate this is to
avoid unnecessary linking. The problem we have at present is that
every time something changes in any model we have to relink all the
binaries that use that model as it is consumed as a static library. If
all the static libraries were converted to shared objects this would
no longer be necessary.

We probably need a dogen command line option to determine what to
build so that users are not forced to always build static / shared
libraries. We should make sure one of the tests is using a static
library to make sure this scenario doesn't get borked.

*** Add comments to test model sanitizer                              :story:

We should explain why we decided to create a test model sanitizer
instead of just adding specs to the test models themselves. The
rationale behind it was that it would break the current diffing and
rebaselining logic; we would either have to ignore specs on the diff
or find a way to copy them after code generation. Both options are a
bit of a hack. So instead we created a model with all the specs.

*** Consider renaming dependencies to references in model             :story:

Dependencies is a map of reference; why not call it references?

*** IoC work                                                           :epic:

All stories related to IoC work are tracked here.

new understanding:

in reality, there is really only one place where IoC makes sense: in
the workflows. It would be great if one could pass in something akin
to a IoC container into the workflow's constructor and then use the
container to obtain access to all services via interfaces. Using
sml::workflow as an example, one could have:

- container_interface which returns grapher_interface,
  processor_interface, etc.
- the container could even return references to the these interfaces
  and own the lifetime of the objects.
- this would then allow us to provide mock container interface
  implementations returning mock services.

However:

- it seems like a lot of moving parts just to allow testing the
  workflow in isolation. this is particularly more so in the case of
  the workflows we have, which are fairly trivial. perhaps we should
  consider this approach when dogen is generating the interfaces
  automatically as this would require a lot of manual work for little
  gain.

old understanding:

- add workflow_interface to SML.
- we should be doing a bit more IoC, particularly with inclusion
  manager, location manager etc. In order to do so we could define
  interfaces for these classes and provide mocks for the tests. This
  would make the tests considerably smaller.

*** Refactor node according to composite pattern in dia to sml        :story:

This is not required if we decide to [[*Add%20composite%20stereotype][implement]] the composite
pattern. We should just follow the composite pattern.

*** Create a validator in SML                                         :story:

We need a class responsible for checking the consistency of the SML
model. There are several things we need to check for non-merged
models:

- ensure that we can only define identity once across concepts and
  parents
- concepts must have at least one property (or method).
- refined concepts must not have properties (or methods) with clashing
  names.
- type names, model names, etc must not contain spaces or other
  invalid characters. We should use a identifier parser for this.
- the qname of all keys in pods, etc must be part of the current
  model.
- the qnames of all types as keys are consistent with the values.
- type_name is non-empty
- parent names and original parent names must exist in current model.
- leaves exist in current model.
- entity must have at least one key attribute.
- non entity must not have key attributes (value, service)
- keyed must be entity.
- aggregate root must be entity.
- all properties of types in current model must exist.
- properties of types in other models result in dependencies.
- enumeration must have at least one enumerator
- enumerator name must not be empty
- enumerator name must be unique
- external package path of the model matches all pods, etc in current
  model.
- model name is non-empty.
- documentation does not have non-printable characters.
- number of type arguments is consistent with pod type.
- pod marked as is comparable must follow the [[*Add%20is%20comparable%20to%20SML][comparison rules]].
- pod marked as is parent must have at least one child.
- property can only have a default value if primitive
- property default value must be castable to primitive type.
- property must have non-empty name.
- is versioned pod must have a property called version.
- string table cannot have duplicate entries.
- Issue error when a property is a value of an abstract class: SML
  should fail to merge if the user attempts to create a property of a
  base class. It should allow pointers to the base class though.
- Test relationships between pods and other meta types: We should
  validate that pods are only related to other pods - e.g. they cannot
  inherit from exception or enumeration or vice-versa. Add tests for
  this.
- Its not possible to be immutable and fluent.
- user models cannot have stereotype of primitive.
- We don't support generic types (see [[Supporting%20user%20defined%20generic%20types][Supporting user defined generic
types]]) so we should throw if a user attempts to use them.

For merged models:

- issue error when a property is a value of an abstract class
- properties exist in merged model.

Validator should provide contextual validation error messages:

: error 1: properties must have a non-null name
: in model 'my_model' (Dia ID: O0)
: in pod 'my_pod' (Dia ID: O0)
: property 'my_property' has empty name.

*** Add composite stereotype                                          :story:

It would be nice if one could just mark a pod as =composite= and dogen
automatically created the composite structure. As we only support
boost shared pointer that's what we'd use. We have a few use cases for
this (node, nested qname, etc).

This would be part of the injection framework.

*** Move extractor from C++ model into SML                             :story:

Extractor and relationships should be moved into SML. The C++ specific
bits are the parts where we directly name types such as
=has_std_string=, etc. These should be generalised, such that the user
could pass in a list of types to the extractor and then we'd return
them with a bool for whether we seen them or not.

We should also remove the references to =forward_decls= directly and
instead have something like "pointer only" dependencies or some such
SML level concept and then interpret this dependency as a forward
declaration at the C++ level.

*** Add support for bitsets                                           :story:

We are using a lot of boolean variables to define properties at the
pod level, relationships, etc. In reality, these all could be
implemented with  =std::bitset=, plus an enumeration. One possible
implementation is:

- add =std::bitset= to std model.
- create a new stereotype of bitset.
- classes with stereotype bitset are like enumerations, e.g. users are
  expected to add a list of names to the class.
- dogen will then implement the properties of type bitset as a
  =std::bitset= of the appropriate size, and also generate an
  enumeration which can be used for indexing the bitset. This may need
  to be a C++-03 enumeration, due to type safety in C++-11
  enumerations.
- we should also implement default bitsets with values corresponding
  to the flags.

Example usage:

#+begin_src c++
const unsigned int my_bitset_size(10);
std::bitset<my_bitset_size> bs;

bs[first_flag_index] = 1;
bs = first_flag_value;
#+end_src

Links:

- [[http://www.java2s.com/Tutorial/Cpp/0360__bitset/Usebitsetwithenumtogether.htm][Use bitset with enum together]]
- [[http://stackoverflow.com/questions/9857239/c11-and-17-5-2-1-3-bitmask-types][C++11 and {17.5.2.1.3} Bitmask Types]]

*** Vistor is only supported at the base class level                  :story:

Due to implementation constraints, we only support visitable at the
base class level. Add an exception if users attempt to use visitable
stereotype in a class that has parents.

*** Create an interface for the text reader                           :story:

In order to do performance testing of the dia model we should create
an interface for text reader and implement it as a mock. This will
avoid the overhead of reading stuff from the hard drive.

*** Add string table support                                          :story:

We need a way of creating "tables" of strings such as for example for
listing all the valid values for dia field names, etc. We could
implement this by creating a new stereotype where the name is the
string name and the default value is the string value. All strings
would be static public members of a class.

We should also add a validate method which checks to see if a string
is a valid value according to the string table. We could have a case
insensitive validate too.

*** Tidy-up test models                                               :story:

We have a lot of fine grained test models for historic reasons. A lot
of these could be collapsed into a smaller number of models, focused
on testing a set of well defined features.

**** Models that need changing

Merge the following models into a =basic= or =trivial= model (no
aggregation, no association):

- classes_in_a_package
- classes_inout_package
- classes_without_package
- class_in_a_package
- class_without_attributes
- class_without_package
- stand_alone_class

We should also check the combined model has all the scenarios
described in [[*Cross%20package%20referencing%20tests][Cross package referencing tests]].

Merge the following models into stereotypes:

- enumeration
- exception

Consider deleting the comments model and make sure we have comments in
all models with the same features:

- top-level comment for the model
- package level comment
- notes

These models are at the right level of granularity but need renaming:

- all_primitives: primitives or primitives_model to line up with boost
  and std.
- trivial_association: association
- trivial_inheritance: inheritance

**** Models that do not need changing and why

These models test other models, and we cannot remove the postfix
=_model= to avoid clashes with namespaces:

- boost_model
- std_model

These models test command line options, which means they cannot be
merged:

- disable_cmakelists
- disable_facet_folders
- disable_full_ctor
- dmp
- enable_facet_domain
- enable_facet_hash
- enable_facet_io
- enable_facet_serialization
- split_project

These models test features which have enough scenarios to justify
keeping them in isolation:

- database

These models test dia features and must be kept isolated:

- compressed
- two_layers_with_objects

**** Add pods, enumerations and exceptions to comments model

At present we are only testing packages in comments.

**** Folder structure

We should take this opportunity to reorganise the test model folders,
perhaps with a structure similar to this (in projects):

: test_models
:     |----> cpp_03                 [language, variant]
:              |----> enumeration   [model with tests]
:               ...
:     |----> cpp_11
:              |----> enumeration
:               ...
:     |----> csharp
:      ...

All the tests in sanitizer would then be moved into each individual
model. This would allow compiling the tests on C++ 03 and C++ 11. We
would also have to move this flag from the generic C++ section to each
individual library/binary makefile.

See [[*Add%20C%2B%2B-03%20mode][C++ 03 support]].

*** Enumeration string conversion could be configurable               :story:

It should be possible to pass in one or more string values as implementation
specific parameters that tells dogen what valid values an enumerator
can have. We can then generate a from string method that does the
appropriate conversions.

These should be passed in as implementation specific parameters.

*** Enumeration string dumps could be configurable                    :story:

It should be possible to pass in a string value as an implementation
specific parameter that tells dogen what string to use for debug
dumping.

*** Add is comparable to SML                                          :story:
     CLOCK: [2013-05-10 Fri 07:48]--[2013-05-10 Fri 08:09] =>  0:21

A pod can have a stereotype of comparable. If so, then at least one
property must be marked as comparable. Properties are marked as
comparable if they have an implementation specific parameter called
=comparison_order=. =comparison_order= is a sequence starting at 0 and
incrementing by 1; it determines the order in which properties are
compared between two objects of the same type.

In order for a property to qualify as a comparison candidate its type
must be:

- primitive;
- =std::string=;
- a pod marked as comparable.

Some facts about comparable pods:

- they generate =operator<= as a global operator in the type
  header file.
- they can be keys in =std::map= and =std::set=.

Relation to keys:

- If all properties that are part of a key are also comparable then
  the key will be comparable.
- comparable versioned keys always compare the version after all other
  comparable properties.

If a pod itself is marked as comparable, then it is equivalent to mark
all properties as comparable using their relative position as the
comparison order.

*** Private and public includes                                       :story:

NOTE: We should use the terms =internal= and =external= to avoid
confusion with C++ scopes. This follows Microsoft terminology for C#
assemblies.

At present we are making all headers in a model public. However, for
models such as cpp this doesn't make any sense since only one type
should be available to the outside world. What we really need is a
separation between public and private headers, a functionality similar
to =internal= in C#. In conjunction with [[*Build%20shared%20objects%20instead%20of%20dynamic%20libraries][using shared objects]], this
should improve build times.

 In order to do this:

- add a new config parameter: default visibility to private or default
  visibility to public. This is just so we don't have to mark all
  types manually - instead we just need to mark the exceptions.
- add two new stereotypes: =public= and =private=.
- add enum to sml: =visibility_type= (check with .Net for
  names). Valid values are =public=, =private=. Pods, enumerations,
  etc will have this enum.
- locator will now respect this value when producing an absolute file
  path. If public files go under =include/public=, if private files go
  under =include/private=.
- CMakelists for the component will add to the include path the
  private directory. Same for the spec CMakelists. Need to check that
  this not add to the global include path.
- CMakelists for the include files will only package the public
  headers.
- mark all the types accordingly in all our models. fix all the
  ensuing breakage. we will probably need to move forward on the IoC
  front in order for this to work as we don't want to expose
  implementations - e.g. =workflow_interface= will be public but
  =workflow= will be private; this means we need some kind of factory
  to generate =workflow_interface=.

*** Refactor boost and std helpers and enums                          :story:

We shouldn't really have std and boost enums. These are just a repeat
of the SML models. We should have a find pod by name in a model which
returns the appropriate qname given a type name. Then the helpers bind
to those qnames; given a qname, they return the include information,
etc. In the current implementation, the enums are basically a
duplication of the static models.

In reality we should really load up these models from a file, such
that users can add their own bindings without having to change C++
code. This could be done with a config file using boost property
tree. However, one would need some kind of way of mapping types into
primitives, sequence containers etc - some kind of "concepts".

*** Type framing                                                      :story:

In places such as a cache or a socket, it may be useful to create a
basic "frame" around serialised types. The minimum requirements for a
frame would be a model ID, a type ID, a "format" (i.e. xml, text, etc)
and potentially a size, depending on the medium. The remainder of the
frame would be the payload - i.e. the serialised object.

In order for this to work we probably need the concept of a "model
group"; the type frame would be done for a group of models.

*** Model and type enums                                              :story:

It may be useful to create enumerations for models, types and
properties within pods. This would in the future form the basis of
reflection. One could use implementation specific properties to set
the model ID and pod IDs.

*** Add pimpl support                                                 :story:

It may be useful to mark classes as pimpl and generate a private
implementation. On the public header we could forward declare all
types.

*** Add C++-03 mode                                                   :story:

It shouldn't be too hard to generate C++-03 code in addition to
C++-11. We could follow the gcc/odb convention and have a =-std=
option for this. The only problem would be testing - at present the
language settings comes from PFH scripts, not cmake, and we'd have to
make sure the compiler is not in C++-11 mode when compiling 03.

*** Use dogen models to test dogen                                    :story:

We should really use the dogen models in the dogen unit tests. The
rationale is as follows:

- if somebody changes a diagram but forgets to code generate, we want
  the build to break;
- if somebody changes the code generator but forgets to regenerate all
  the dogen models and verify that the code generator still works, we
  want the build to break.

This will cause some inconvenience during development because it will
mean that some tests will fail until a feature is finished (or that
the developer will have to continuously rebase the dogen models), but
the advantages are important.

*** Add a property for the model name as meta-data                    :story:

It would be nice to be able to generate a model with a name other than
the diagram file. We should have a command line option for this that
overrides the default diagram name.

*** Add camel case option                                             :story:

It would be nice to have a command line option that switches names
from underscores into camel case. The default convention would be that
diagrams are always with underscores and then you can convert them at
generation time. There should be a regex for this conversion.

*** Warn if value or entity has methods                               :story:

We should issue a warning if a user defines methods in value or entity
pods as its most likely by mistake.

*** Add diff support                                                  :story:

New understanding: just create a new facet call diff and make these
classes generate a simple textual representation of differences,
inspired in =diff=. Where the pod is an entity provide its ID. In
general just provide some "path" to the difference,
e.g. model/pod/member variable/etc.

Old understanding:

Dogen should have a =diff= option. When switched on, it would generate
=diff= classes. These are system types like keys and live in a
sub-folder of =types=. They have full serialisation, hashing etc
support like any other model type. The generated classes are:

- =differ=: for each model type a differ gets generated. this is a
  top-level class that diffs two objects of the same type.
- =changeset=: for each model type a changeset gets generated. it has
  a variant called =changeset_types=, made up of all the types of all
  properties in the model. if a model property has a model type then
  it uses the changeset for that type rather than the type itself; for
  all other cases, including containers, it uses the type itself.

In addition, we need set of enumerations in =reflection=. To start off
with all it contains is a list of classes in the model and a list of
fields in each class.

The =changeset= then has a container of =changeset_types= against a
reflection class and field.

Diff support is injected into the model just like keys. It also
requires that reflection support gets injected too.

*** Container details in JSON dump                                    :story:

It would be nice to have the container type and size in the JSON
output.

*** Handling of include cmakelists in split projects is not correct   :story:

At present we are only generating a cmakelists file for include
folders on non-split projects. This means that the header files for
split projects won't be packaged up. It also means that for ODB
projects we won't get the ODB targets.

*** Partial matching of primitives doesn't work for certain types     :story:

We introduced a fix that allows users to create types that partially
match primitive types such as =in= or =integer=. The fix was copied
from the spirit documentation:

[[http://www.boost.org/doc/libs/1_52_0/libs/spirit/repository/doc/html/spirit_repository/qi_components/directives/distinct.html][- Qi Distinct Parser Directive]]
- [[http://www.boost.org/doc/libs/1_52_0/libs/spirit/repository/test/qi/distinct.cpp][distinct.cpp]]

However, we still haven't solved the following cases:

: BOOST_CHECK(test_primitive("longer"));
: BOOST_CHECK(test_primitive("unsigneder"));

As these are not so common they have been left for later.

*** Manual typedef generation                                         :story:

We should be able to create a stereotype of =typedef group=. This is a
pod type with lots of attributes. The code generator will take the
name and type of each attribute and generate a file with the name of
the group and all the typedefs inside.

*** Automatic typedef generation                                      :story:

We should generate typedefs for all smart pointers, containers, etc -
basically anything that has template arguments. This would make
generated code much more readable and could also be used by client
code. In theory all we need is:

1. determine if the property has type arguments;
2. if so, construct the typedef name by adding =_type= to the property
   name, e.g. =attribute_value= becomes =attribute_value_type=, etc;
3. create a typedef section at the top of the class declaring all
   typedefs;
4. add a property to the property view model containing the typedef
   name and use it instead of the fully qualified type name.
5. we should also generate a typedef for the key if the class is an
   entity. See Typedef keys for each type.

We could also always generate a typedef for smart pointers in the
class that uses the smart pointer, with a simple convention such as
=attribute_value_ptr_type= or =shared_attribute_value_type=.

*** Add support for iterable enumerations                             :story:

We should create an additional aspect for each enumerations which
creates a =std::array= with the enumerators (excluding invalid). This
would allow plugging the enumerations into for loops, boost ranges,
etc. The CPP should contain a static array; The HPP contains a method
which returns it, e.g. =my_enumeration_to_array.hpp=:

: std::array<my_enumeration, 5> my_enumeration_to_array();

We could make this slightly more generic by adding the notion of
enumeration groups. Out of the box we have:

- all: includes invalid;
- valid: excludes invalid

Users could then add implementation specific properties to create
other groups if needed.

*** Add support for user supplied test data sets                      :story:

New understanding:

we need to create a test data sets model. it should have an
enumeration for all of the available test data sets, and an
enumeration for the valid file formats. we should be able to pass in a
pair of file formats (input, actual/expected) and out should come a
triplet of directories. This would make maintenance really easy as
we'd only need to ad new strings to a string table. the service would
also handle things like the actual and expected directories, etc.

It should fix the following issues:

- [[*Adding%20new%20engine%20spec%20tests%20is%20hard][Adding new engine spec tests is hard]]
- [[*Naming%20of%20saved%20SML/Dia%20files%20is%20incorrect][Naming of saved SML/Dia files is incorrect]]

Old understanding:

The correct solution for test data and test data sets is as follows:

- the code generated by dogen in the test data directory is one of
  many possible ways of instantiating a model with test data.
- there are two types of instantiations: code and data. code is like
  dogen =test_data=; data is XML, text or binary - or any other
  supported boost archive; it also includes other external formats
  such as dia diagrams.
- a model should have a default enum with all the available test data
  sets: =test_data::sets=. If left to its default state it has only one
  entry (say =dogen=). The use is free to declare an enumeration on a
  diagram with the name test_data_sets and add other values to it.
- there must be a set of folders under test_data which match the
  enumerators of =test_data::sets=. Under each folder there must be an
  entry point such as =ENUMERATOR_generator=. Dogen will automatically
  ignore these folders via regular expressions.
- a factory will be created by dogen which will automatically include
  all such =ENUMERATOR_generator=. It will use static methods on the
  generator to determine what sort of capabilities the generator has
  (file, code, which formats supported, etc.) and throw if the user
  attempts to misuse it.
- all models must have a repository. Perhaps we need a stereotype of
  =repository= to identify it. This is what the factory will create.
- users will instantiate the factory and call =make=:

: my_model::test_data::factory f1;
: auto r = f1.make(my_model::test_data::sets::dogen);
:
: my_model::test_data::factory f2(expected_dir, actual_dir);
: auto r = f2.make(my_model::test_data_sets::some_set,
:   my_model::test_data::file_formats::boost_xml, file_locations::expected);

- if the user requires parsing a non-boost serialisation file then it
  should be make clear on the enum: =std_model, std_model_dia=. The
  second enumerator will read dia files. It will not support any file
  formats. The file must exist on either the expected or actual
  directory as per =file_locations= parameter.

Another topic which is also part of test data is the generation of
data for specific tests. At present we have lots of ad-hoc functions
scattered around different places. They should all live under test
data and be part of a test data set. The test data set should probably
be the spec name.

*** Add test to check if we are writing when file contents haven't changed :story:

We broke the code that detected changes and did not notice because we
don't have any changes around it. A simple test would be to generate
code for a test model, read the timestamp of a file (or even all
files), then regenerate the model and compare the timestamps. If there
are changes, the test would fail.

*** Add support for =std::function= in services                       :story:

At present its not possible to declare an attribute of type
=std::function= anywhere in a diagram. It won't really be possible to
do so for entities and values because boost serialisation will always
be a problem. If this was really a requirement, we could look into
serialising functions:

- [[https://groups.google.com/forum/?fromgroups%3D#!topic/boost-list/sHWRPlpPsf4][how to serialize boost::function]]

However we don't seem to need this quite just yet. What we do need is
a way of having attributes in services and that is slightly easier:

- the parser needs to be able to understand the function template
  syntax (e.g. =void(int)=). It seems this could be hacked easily
  enough into the parser.
- Nested qualified names need to be able to remember that in the case
  of a function, the first argument is a return type (they also need
  to know they represent a function). MC: is this actually necessary?
  all we need is to be able to reconstruct this syntax at format time.
- we need a =void= type in the primitives model. This is a bit more
  complicated since this type can't have values, only pointers, and we
  don't really support raw pointers at the moment. Adding the type
  blindly would open up all sorts of compilation errors.

This should be sufficient for services. At present we have a hack that
allows functions without any template arguments, e.g. =std::function=,
in services.

*** Add support for references to types                               :story:

At present its not possible to create a type that has a reference to
another type. This should be a case of updating the parser to cope
with references and adding reference to property or nested type
name. This would be a good time to inspect our support for raw
pointers, it probably suffers from exactly the same problem and
requires the same solution.

In addition we should also bear in mind moving. Ideally one should be
able to declare moveable attributes and the end result should be a
setter that takes the type by =&&=. The question then is should we
also move on the getter? Sometimes it may not be a copyable type
(e.g. asio's =socket=).

*** Add support for default values                                    :story:

It would be nice to be able to add a default value in dia and have it
set on the default constructor, if the type is a primitive or a =std::string=.

*** Add support for interfaces                                        :story:

This is a very blue-skies story. When dogen starts supporting service
types it would be useful to generate a service interface from
dogen. In order to do this we'd have to parse the method definitions
in dia and use those to construct an abstract base class.

*** shared pointer to vector fails to build                           :story:

If one has a property with type
=boost::shared_ptr<std::vector<std::string>>=, we get the following
error:

: /home/marco/Development/kitanda/output/dogen/stage/bin/demo/demo_20/sprint_20/src/test_data/my_class_td.cpp: In function boost::shared_ptr<std::vector<std::basic_string<char> > > {anonymous}::create_boost_shared_ptr_std_vector_std_string_(unsigned int):
: /home/marco/Development/kitanda/output/dogen/stage/bin/demo/demo_20/sprint_20/src/test_data/my_class_td.cpp:47:50: error: create_std_vector_std_string_ptr was not declared in this scope

This is because the generated code is not creating a method to new
vectors:

: std::vector<std::string> create_std_vector_std_string(unsigned int position) {
:    std::vector<std::string> r;
:    for (unsigned int i(0); i < 10; ++i) {
:        r.push_back(create_std_string(position + i));
:    }
:    return r;
:}
:
:boost::shared_ptr<std::vector<std::string> >
:create_boost_shared_ptr_std_vector_std_string_(unsigned int position) {
:    boost::shared_ptr<std::vector<std::string> > r(
:        create_std_vector_std_string_ptr(position));
:    return r;
:}

*** Strange logging behaviour in tests                                :story:

As reported by JS for some reason if a test has a null pointer
de-reference, the next test will log to both files. This means the
logger is not being switched off properly in the presence of exceptions.

*** Mix-and-match of manual projects                                  :story:

With the ignore by regex feature its now possible to mix and match
projects. However, dogen generates a makefile which does not include
any manually generated projects. We need some intelligent logic in the
src cmakefile that looks for other cmakefiles and adds them
automatically in its =add_subdirectory=. This could be done by the
CMake backend when that exists.

*** Use error codes in exceptions                                     :story:

Avoid breaking tests every time the exception text changes by creating
a error code property in kitanda exceptions.

After some investigation it was found that boost already supports this
approach in =system=, as per [[http://en.highscore.de/cpp/boost/errorhandling.html][boost book]]. We could define a new
category per model and then create an enumeration of all error codes
in dia, for which the values would be the strings to use for the
error. The user could then create an exception and pass in the error
code in the constructor.

We should also make use of string tables to define all the error
messages.

Could we just have an exception factory that handles all of the
machinery of creating an exception with the right code, message etc?
it could also be responsible for appending more content to an existing
exception so that we'd have the tags all in one place.

*** Generation of cache code                                          :story:

New understanding for this story:

- create a cache interface in types;  all types marked as =cacheable=
  have gets, puts  etc.
- create a memcache implementation.
- create a type to string which converts a key made up of primitives
  into a underscore delimited string, used as a key in the cache.

Old text of story:

Some thought on adding caching to dogen:

- we could have "modes" in dogen; instead of the
  relational/procedural/etc approach, it would be more task based:
  domain, cache.
- in cache mode we do not need to a target. we load up all diagrams in
  references and we find all types which have a stereotype of
  versioned. we mark them as generatable.
- if a target is supplied, it can only have objects of stereotype
  =mapping= or =cache= (tbd). These are simply a key-value-pair and
  determine additional caches to create. the attributes must be called
  key and value. the key entity must be versioned, value doesn't have
  to.
- for each versioned type, we create the following "shadow" pods: get,
  put, erase. each has versioned and unversioned. these objects are in
  the namespace cache::type_namespaces,
  e.g. =cache::credit_risk::model_configuration::versioned_get= or
  maybe
  =cache::credit_risk::model_configuration::versioned::get=. they are
  protocol messages to be sent on the wire.
- new formatter: named cache, with unordered maps for an entity with
  key, value. Any additional mappings that were added manually using
  the target are also added to the kvp mapping.
- new formatter: raw named cache, with unordered maps for an entity with
  key, value. value is raw storage, with an indication of the type of
  data being stored (e.g. xml, binary or text).
- new formatter: repository. contains all of the named caches.
- new formatter: dispatcher. given a message of one of the known types
  (get/put/remove) it dispatches it to the correct location in the
  repository and takes appropriate action. we may need one per named
  cache.
- put/get/erase are regular domain objects so they go through the
  usual formatters

Sample flow:

: credit_risk::model_configuration_unversioned_key k(123);
: cache::near near;
: cache::credit_risk::model_configuration::named_cache nc(
:    near.named_cache<credit_risk::model_configuration>());
: std::future v(n.async_get(k));

- we need to re-read the coherence docs to clarify the roles of
  front/back cache, local/remote cache and near cache.

*** Unordered map of user type in package fails                       :story:

We seem to have a strange bug whereby creating a
=std::unordered_map<E1,E2>= fails sanity checks if E1 is in a
package. This appears to be some misunderstanding in namespacing
rules.

*** Architecture refactoring                                           :epic:

Each of these tasks is really a story, but we need to make sure the
entire architecture hangs together before we start refactoring; this
is the purpose of this story. Some of the stories here already have
been captured in the backlog.

- create "modes" of operation: relational, object-oriented and
  procedural. they limit the types available in SML. relational only
  allows primitives plus relational commands (FK and PK; FK is when
  using a model type, PK is a marker on a property). procedural only
  allows primitives plus model types. we will need pointer support for
  this. object oriented is the current mode. the modes are validated
  in the middle end.
- create a front end component that defines the front end inteface,
  has a factory that returns a front end based on an enum.
- create the dia front end which contains the dia to SML code from
  modeling.
- create a middle-end component with the rest of the code in
  modeling. create a factory based on an enum that returns the middle
  end instance. create a mock.
- middle end component will eventually be responsible for the
  intermediate model.
- engine is now a shell that interconnects front, middle and back
  end based on configuration options.
- use inheritance in SML model
- refactor middle end to take advantage of inheritance
- we need to split cmake generation from C++. We can't have backends
  supporting two grammars at the same time. Also, we need to support
  two backends writing to the same directories. This should not be a
  problem since all the housekeeping and writing is done at the
  generator level. Also, we could support a language option to cmake
  such as C++, SQL etc which would trigger different types of
  cmakefiles to come up.

*** Adding new engine spec tests is hard                              :story:

In order to test models at the engine level one needs to first
generate the dia input. This can be done as follows:

: ./dogen_driver-0.0.507 --save-dia-model xml
: --stop-after-merging -t ../../../../dogen/test_data/dia_sml/input/boost_model.dia

From the bin directory. We need to make these steps a bit more
obvious. Why do we even need this?

*** Naming of saved SML/Dia files is incorrect                        :story:

For some random reason when we use dogen to save SML/Dia files the
names look like this:

: test_data/dia_sml/expected/boost_model.xmldia
: test_data/dia_sml/expected/std_model.xmldia

but our tests expect:

: test_data/dia_sml/expected/boost_model.diaxml
: test_data/dia_sml/expected/std_model.diaxml

This must be part of a refactoring that wasn't completed properly.

*** Consider renaming specs to tests                                  :story:

We started using the terminology specs to mean specifications because
our unit tests follow the ideas outlined by Kevlin Henney. However, we
could easily use tests and still carry most of the meaning without
confusing every other developer. This would require:

- rename top-level =spec= folder to =tests=
- rename targets to =_tests=, e.g. =run_sml_tests=
- rename all test suites to =_tests=
- update the automatic detection of boost tests to use the new
  post-fix.
- we should also use =_tests= on the test suite name so we can do
  =using XYZ= without name clashes.

*** Support for components and groups                                 :story:

We recently added support for creating multiple packages from a single
source tree. We need generated models to have a new top-level cmake file:

: add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/src)
: add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/spec)
:
: install(
:     DIRECTORY include/
:     DESTINATION include
:     COMPONENT headers
:     FILES_MATCHING PATTERN "*.hpp")

And the =src= cmake file:

: install(TARGETS dia ARCHIVE DESTINATION lib COMPONENT libraries)

*** Option to diff generated code                                     :story:

It would be useful to have an option that would do everything except
writing the files to disk; instead, it would diff them with the
existing files and report if there are any differences. This would be
useful to make sure the source code matches the latest version of the
diagram.

*** Option to validate diagram                                        :story:

It would be nice if one could just check if a dia diagram is valid for
code generation, e.g. =--validate= or something along those lines.

*** Shared pointers to primitive types                                :story:

At present we do not support shared pointers to primitive types. This
is because they require special handling in serialisation. See:

http://boost.2283326.n4.nabble.com/Serialization-of-boost-shared-ptr-lt-int-gt-td2554242.html

We probably need to iterate through all the nested types and find out
if there is a shared pointer to primitive; if there is, put in:

: // defined a "special kind of integer"
: BOOST_STRONG_TYPEDEF(int, tracked_int)
:
: // define serialization for a tracked int
: template<class Archive>
: void serialize(Archive &ar, tracked_int & ti, const unsigned int version){
:     // serialize the underlying int
:     ar & static_cast<int &>(ti);
: }

*** Full constructor parameter comments                               :story:

We could use the comments in properties to populate the comments for
the full constructor for each parameter. This would require taking the
first line of the documentation of each property and then stitching
them together for the full constructor.

*** Serialisation support for C++-11 specific containers              :story:

We can't add =std::array= or =std::forward_list= because there is no
serialisation support in boost 1.49. A mail was sent to the list to
see if this has changed in latter versions:

http://lists.boost.org/boost-users/2012/11/76458.php

However, it should be pretty trivial to generate serialisation code by
hand at least for =std::array= or to use a solution similar to
=std::unordered_map=.

*** Support for ordered containers                                    :story:

In order to provide support for ordered containers such as maps and
sets we need to define =operator<=. However, it makes no sense to code
generate this operator as its unlikely we'll get it right. We could
assume the user wants to always sort by key, but that seems like a bad
assumption. The alternatives are:

- to expect a user-defined =entity_name_less_than.hpp= in domain. we'd
  automatically ignore any files matching this patter so the user can
  create them and not lose it. The problem with this approach is that
  we may have different sort criteria. This is a good YAGNI start.
- to provide the =Compare= parameter in the template and then expect a
  user-defined =entity_name_Compare.hpp=. The same ignore
  applies. This would allow users to provide any number of comparison
  operations.

Either approach requires [[Ignore%20files%20and%20folders%20based%20on%20regex][Ignore files and folders based on regex]].

*** Rename =inserter_implementation=                                  :story:

We used =inserter_implementation= to provide all sorts of utility
methods for IO. This class should really be named IO utility or
something of the sort.

*** Cross model referencing tests                                     :story:

At present we do not have any tests were a pod in one model makes use
of types defined in another model. This works fine but we should
really have tests at the dogen level.

*** Cross package referencing tests                                   :story:

Scenarios:

- object in root refers to object in package: A => pkg1::B;
- object in root refers to object in package inside of package: A =>
  pkg1::pkg2::B;
- object inside of package refers to object inside of the same
  package: pkg1::A => pkg1::B (must be qualified);
- object in package refers to root object: pkg1::A => B;
- object in package refers to object in other package: pkg1::A =>
  pkg2::B;
- object in package refers to object in package in package: pkg1::A =>
  pkg1::pkg2::B;
- object in package refers to object in other package in package: pkg1::A =>
  pkg2::pkg3::B;
- object in package in package refers to object in package in package:
  pkg1::pkg2::A => pkg3::pkg4::B.

*** Empty directories should be deleted                               :story:

When housekeeper finishes deleting all extra files, it should check
all of the processed directories to see if they are empty. If they
are, it should delete the directory.

*** Header only models shall not generate projects                    :story:

A project with just exceptions does not need a make file, and fails to
compile if a makefile is generated. We need a way to not generate a
makefile if there are no implementation files generated.

*** Empty features should not show up                                 :story:

If there are no files for a feature, we should not generate includers
and folders for that feature.

*** Add support for configurable enumerations types                   :story:

At present our enumerations always use unsigned int as the underlying
type. It should be possible to override that from dia.

*** Add test for disabling XML                                        :story:

At present we are not testing model generation with XML disabled.

*** IO header could depend on domain forward decl                     :story:

At present we are depending on the domain header but it seems we could
depend only on the forward declarations.

*** Format doubles, floats and bools properly                         :story:

At present we are using IO state savers but not actually setting the
formatting on the stream depending on the primitive type.

*** Add support for protected attributes                              :story:

We need to distinguish between public and protected attributes when in
the presence of inheritance. If not, issue a warning.

*** Add tests for invalid types                                       :story:

- type name is blank (or variable name)
- type name does not exist on any model

*** Add tests for disconnected connections                            :story:

We should throw if a diagram has a disconnected inheritance or
composition relationship.

*** Add tests for duplicate identifiers in Dia                        :story:

Detect if a diagram defines the same class or package multiple
times. Should throw an exception.

*** Test model sanity checks fail for enable facet serialisation      :story:

For some reason we are unable to compile the serialisation test for
the test model which focuses only on the serialisation facet. Test is
ignored for the moment.

*** Handle unnamed models properly                                    :story:

The option disable model name was meant to allow the generation of
flat models, without any folders or namespaces for the model
name. However, as a side-effect, this also means the artefacts being
generated do not have any names. This resulted in the creation of a
libSTATIC, purely because the next command in the cmake add_library is
STATIC (e.g. static library). As a quick hack, when an empty model
name is detected, a model named "unnamed_model" is created.

The correct solution for this is to have a flag (or flags) at the SML
level which state whether to use the model name for folders, packages,
etc. The view model generation will then take this into account.

*** Add SQL support to Dogen                                           :epic:
**** Note on formatters                                                :note:

- Use an attribute with the type to determine if we want only the ID of
  the foreign key in C++ code or if we want a whole type.

Formatters:

- File names are: FQN_ENTITY, e.g. kitanda_prototype_currency_table
- create: table, load, save, erase, test data generators, test
- drop: table, load, save, erase, test data generators, test
- domains
- create schema formatter
- create all tables
- create all procs
- drop all tables
- drop all procs
- drop all
- create all

**** Create SQL backend                                               :story:
***** Create new backend                                               :task:
***** Create new location manager                                      :task:
***** Create aspect and facet types                                    :task:
***** Create a view model for table and stored procedure               :task:
***** Create a transformer from SML to view model                      :task:
***** Add SQL command line options                                     :task:
**** Add table support                                                :story:
***** Create table formatter                                           :task:
***** Drop table formatter                                             :task:
***** Test formatters                                                  :task:

**** Add load support                                                 :story:
***** Create load formatter                                            :task:
***** Drop load formatter                                              :task:
***** Test formatters                                                  :task:

**** Add save support                                                 :story:
***** Create save formatter                                            :task:
***** Drop save formatter                                              :task:
***** Test formatters                                                  :task:

**** Add delete support                                               :story:
***** Create delete formatter                                          :task:
***** Drop delete formatter                                            :task:
***** Test formatters                                                  :task:

**** Add test support                                                 :story:
***** Create test formatter                                            :task:
***** Drop test formatter                                              :task:
***** Test formatters                                                  :task:

**** Analyse deployment support on CMake                              :story:

Ideally, get a state of affairs that resebles something like this:

- make deploy_database
- make undeploy_database

***** Review and fix existing targets                                  :task:

- Rename all =currency= targets to =prototype= targets
- Ensure the targets have correct dependencies

***** Add support for multiple databases                               :task:

**** Add database tests for generated code                            :story:
**** Test database deployment

We need to setup a build that deploys all the SQL (tables, procs, etc)
to a clean database, runs all SQL tests and un-deploys all the SQL.

**** Setup a postgres url in cmake file                               :story:

The database password is set to trust. We should really have user
passwords. To make things more secure we should also pass in the
database credentials to the unit tests. One potential approach is to
do so in cmake. Example from VTK:

#+begin_src cmake
IF ( BUILD_TESTING )
   SET ( VTK_PSQL_TEST_URL "" CACHE STRING "A URL for a PostgreSQL server
         of the form psql://[[username[:password]@]hostname[:port]]/[dbname]" )
ENDIF ( BUILD_TESTING )
#+end_src

Suggestion: maybe there's a possibility of using an environment
variable for all the used parameters (username, hostname, etc)

**** Add multiple database support to makefiles

Our makefiles don't cope very well with the test/development database
separation. There is a massive hack required to populate both
databases (changing makefile manually and then reverting the change).

There should be a way of passing in the database name as an
environment variable into the makefile (not into the cmake as we want
to be able to change databases without having to rebuild makefiles).

*** Missing =enable_facet_XYZ= tests                                  :story:

- test data

*** Log should use path for file names                                :story:

At present we are passing the log file name as a string and
concatenating using "/". This is not very good for Windows. We should
use =boost::filesystem::path= throughout and do a =.string= at the
very end if boost log does not support boost filesystem (or use the
path directly if it does).

*** Create model with invalid primitive type                          :story:

At present we are validating that all primitive types work but we
don't check that an invalid type doesn't work.

*** Private properties should be ignored                              :story:

At present we treat private properties as if they were public; we
should ignore them. We need to go through all the models and change
the private ones to public before we do this.

We should also issue a warning.

*** Sanity check packages automatically                               :story:

This work is also covered by tasks in the PFH backlog so update
accordingly. This task only refers to the dogen specific parts of the
task.

- sanity check that package installed correctly, e.g. check for a few
  key files.
- run sanity tests, e.g. create a dogen model and validate the results
- run uninstaller and sanity check that files are gone
  - this should actually be a build agent so we can see that deployment
    is green. We should create a deployment CMake script that does this.
- build package and drop them on a well known location;
- Create a batch script that polls this location for new packages;
  when one is found run package installer.
- we should create a set of VMs that are specific for testing - the
  test environments. One per OS. These are clean builds with nothing
  on them. To start off with they may contain postgres so we can
  connect locally.

*** Check if we've replaced =assert_object= with =assert_file=        :story:

Assert file is now able to do intelligent comparisons based on the
extension of the file. From a cursory look, all the usages we have of
assert object can be replaced by assert file. If that's the case we
can also remove this function.

*** Exception classes should allow inheritance                        :story:

We need to have a form of inheriting from a base exception for a given
model. We also need to be able to inherit from other exceptions in a
model. At present exceptions are not pods so the dependency graph
support is not there.

*** Investigate GDB visualisers for generated models                  :story:

It would be great if the code generator created GDB visualisers for
the types in a generated models such that one could inspect values of
STL containers with types of that model.

- [[http://sourceware.org/gdb/onlinedocs/gdb/Pretty-Printing.html][Pretty printing]]
- [[https://github.com/ruediger/Boost-Pretty-Printer][Boost pretty printer]]
- [[https://groups.google.com/group/boost-list/browse_thread/thread/ff232ac626bf41cf/18fbf516ceb091da?pli%3D1][Example for multi-index]]

*** Generator usage in template tests needs to be cleaned             :story:

At present some template tests in =utility/test= ask for a
generator, other for instances. We should only have one way of doing
this. We should probably always ask for generators as this means less
boiler plate code in tests. It does mean a fixed dependency on
generators.

*** Replace old style for iterations in IO                            :story:

At present we are still doing C++-03 iterations in the STL IO files
such as =vector_io=, =list_io=, etc. We should be using the new =for=
syntax for C++-11.

*** Add an includer for all includers                                 :story:

It would be nice to totally include a model. For that we need an
includer that includes all other includers. This should be as easy as
keeping track of the different includers for each facet in the map
inside of the includer service.

*** Add new equivalence operator to domain types                      :story:

We should have an operator that compares the state of two objects
ignoring the version.

*** Property types are always fully qualified                         :story:

When we code generate non-primitive properties we always fully qualify
them even if they are on the same namespace as the containing type.

*** Support "cross-facet interference"                                :story:

In a few cases its useful to disable bits of a facet when another
facet is switched off because those bits do not belong to the main
facet the formatter is working on. At present this happens in the
following cases:

- Forward declaration of serialisation in domain when serialisation is
  off
- Friend of serialisation in domain when serialisation is
  off
- declaration and implementation of to_stream when IO is off
- declaration and implementation of inserter when IO is off and
  integrated IO is on.

We need a way of accessing the on/off state of all facets from any
formatter so that they can make cross facet decisions. A quick hack
was to add yet another flag: =disable_io= which is disabled when the
IO facet is not present and passed on to the relevant formatters. This
needs to be replaced by a more general approach.

*** Add run spec targets for each test                                :story:

We could piggy back on the ctest functionality and add a target for
each test so one could =make enable_facet_domain= and =make
run_enable_facet_domain=. The targets need to be prefixed with module
name and test suite.

*** Clean up WinSock definition in CMakeLists                         :story:

We did a crude implementation of finding WinSock just to get windows
to build. There should be a FindWinSock somewhere. If not create one.

Do we need this anymore? we probably need it for linking the database
model, but we should check - maybe ODB has some magic around this.

*** Refactor engine's =persister=                                     :story:

- add documentation
- we put the decision on whether to persist on not based on settings
  inside of persister. It should really be up to the person calling
  the persister to decide. Persister should always persist.
- we should have an argument deciding the file format, perhaps an
  enumeration, instead of passing in the extension. The extension
  should be automatically determined.
- persister should support all archive types. At present it always
  outputs in XML; it should respect the archive type requested by the
  user.

*** Add unit test benchmarking                                        :story:

New understanding:

Create a set of performance specific tests. These wont get executed by
regular users (e.g. they are not part of =run_all_specs=) but they do
get executed in the build machine. These are selected tests with big
loops (say 1M times) doing things like reading dia diagrams etc. We
could chose a few key things just to give us some metrics around
performance.

In fact, we could create a set of colossus models: models with really
large number of classes (say 500), maybe 5 of these with
references. We could then use the diagrams to test the individual
workflows: dia, dia_to_sml, cpp and engine with no writing. We should
avoid writing files to filesystem to avoid number jitter caused by the
hard drive. There should be no comparisons between actual and expected
for the same reason.

We need to make sure the benchmark tests won't run on valgrind or else
the nightly builds will take over 24 hours. However, if we had it
running on continuous we'd spot regressions on every check-in. But we
don't want to delay continuous any more than necessary. Perhaps we
need a separate build called performance which is also continuous and
only runs these tests. We could pass in some kind of variable to CMake
so that if performance is on, it ignores all tests other than
performance and vice-versa. We'd also need a performance target that
only builds the performance binary, and a =run_performance= target
that executes it.

Old understanding:

[[https://svn.boost.org/trac/boost/ticket/7082][Raised ticket]]

- nightly builds should run all unit tests in "benchmarking mode";
- for each test we should find the sweet spot for N repetitions;
- when plugged into ctest, make sure the benchmark tests have
  different names from the main tests otherwise the timing history
  will be nonsense.
- [[http://lists.boost.org/boost-users/2011/01/65790.php][sent]] email to boost users mailing list asking for benchmarking
  support.

** Won't fix

Stories which we do not think we are going to work on.

*** Tests for error conditions in libxml

We do not have any errors that check for error conditions directly in
libxml. This is why the coverage of these functions is red.

*** Check that custom targets in CMake have correct dependencies

At present we have a number of custom targets, which create a new Make
target. These are good because they do not require re-running CMake to
manage the files in the output directory; however, we do not have the
correct dependencies between the targets and the target
dependencies. For example, create_scripts should check to see if any
script has changed before re-generating the tarball; it seems to have
no dependencies so it will always regenerate the tarball. We need to:

- check all custom targets and see what their current behaviour is:
  a) change a dependency and rebuild the target and see if the
  change is picked up or not; b) change no dependencies and re-run the
  target and ensure that nothing happens.
- add dependencies as required.

*** Enable doxygen warnings for all undocumented code

At present doxygen only warns about undocumented parameters when a
function already has documented parameters. We should consider
enabling warnings for all undocumented code. We also need to figure
out how to mark code as ignored (for example serialisation helpers,
etc won't require documentation).

*** Add specification comments to tests

We started off by adding a technical specification as a doxygen
comment for a test but forgot to keep on doing it. Example:

: /**
:  * @brief It shall not be possible to create more terms than those
:  * supported by a finite sequence, using std::generate_n.
:  */

This helps make the purpose of the test clearer when the name is not
sufficient.
*** Supporting user defined generic types

At present we have a bit of a hack to support templates. However, all
that is required to allow users to create their own template types is:

- parse dia information for type arguments
- change pod to have type arguments
- change merger to allow variables of the type of the type argument
- change view model to propagate type arguments
- change formatter to create template class if type arguments are
  present

However this would then mean that IO and serialisation would fail
since they are implemented on the cpp. As there is no need for
template types, this seems like an ok limitation.
*** Shared pointers as keys in associative containers

This is not supported; it would require generating the
hashing/comparison infrastructure for shared pointers. Further, as it
has been pointed out, keys should be immutable; having pointers as
keys opens the doors to all sorts of problems. We need to throw an
error at model building time if an user tries to do this.
*** Package names should follow a well-known convention

We need to make sure our package names are consistent with the
platform conventions.

- [[http://pastebin.com/TR17TUy9][Example of platform IFs]]
- [[http://libdivsufsort.googlecode.com/svn-history/r6/trunk/CMakeModules/ProjectCPack.cmake][Example CPack]]
- [[http://cmake.3232098.n2.nabble.com/Automatically-add-a-revision-number-to-the-CPack-installer-name-td7356239.htmlhttp://cmake.3232098.n2.nabble.com/Automatically-add-a-revision-number-to-the-CPack-installer-name-td7356239.html][Automatically add a revision number to the CPack installer name]]
- [[http://www.cmake.org/Wiki/CMake:CPackConfiguration][CPack Configuration]]

There are some known limitations in package naming:

- http://public.kitware.com/Bug/view.php?id=12997
